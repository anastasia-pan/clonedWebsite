<!DOCTYPE html>
<!-- saved from url=(0033)https://www.lesswrong.com/library -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<script type="text/javascript" async="" src="./The Library - LessWrong_files/linkid.js"></script><script type="text/javascript" async="" src="./The Library - LessWrong_files/analytics.js"></script><script type="text/javascript" async="" src="./The Library - LessWrong_files/js"></script><script type="text/javascript" async="" src="./The Library - LessWrong_files/recaptcha__en.js" crossorigin="anonymous" integrity="sha384-yF7E1ktGfbA26NWZZupkIgKSvH2WmFG90KyY3BzFp06blZkjALcng9gGnuW5hlae"></script><script async="" src="./The Library - LessWrong_files/gtm.js"></script><script defer="" src="./The Library - LessWrong_files/bundle.js"></script><title>The Library - LessWrong</title><meta data-react-helmet="true" name="description" content="A community blog devoted to refining the art of rationality"><meta data-react-helmet="true" name="viewport" content="width=device-width, initial-scale=1"><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="og:image" content="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1503704344/sequencesgrid/h6vrwdypijqgsop7xwa0.jpg"><meta data-react-helmet="true" property="og:description" content="A community blog devoted to refining the art of rationality"><meta data-react-helmet="true" name="twitter:card" content="summary"><meta data-react-helmet="true" name="twitter:image:src" content="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1503704344/sequencesgrid/h6vrwdypijqgsop7xwa0.jpg"><meta data-react-helmet="true" name="twitter:description" content="A community blog devoted to refining the art of rationality"><meta data-react-helmet="true" http-equiv="Accept-CH" content="DPR, Viewport-Width, Width"><link data-react-helmet="true" rel="shortcut icon" href="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico"><link data-react-helmet="true" rel="alternate" type="application/rss+xml" href="https://www.lesswrong.com/feed.xml"><link data-react-helmet="true" rel="stylesheet" type="text/css" href="./The Library - LessWrong_files/icon"><link data-react-helmet="true" rel="stylesheet" href="./The Library - LessWrong_files/reset-min.css"><link data-react-helmet="true" rel="stylesheet" href="./The Library - LessWrong_files/css"><link data-react-helmet="true" rel="stylesheet" href="./The Library - LessWrong_files/jvr1gjm.css">
<script>var tabId = "Ycg5ofC2PfKrDF3aS"</script>
<script> var publicSettings = {"siteImage":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1503704344/sequencesgrid/h6vrwdypijqgsop7xwa0.jpg","intercomAppId":"wtb8z7sj","googleTagManager":{"apiKey":"GTM-TRC765W"},"reCaptcha":{"apiKey":"6LfFgqEUAAAAAHKdMgzGO-1BRBhHw1x6_8Ly1cXc"},"googleMaps":{"apiKey":"AIzaSyA3C48rl26gynG3qIuNuS-3Bh_Zz9jFXkY"},"algolia":{"appId":"Z0GR6EXQHD","searchKey":"0b1d20b957917dbb5e1c2f3ad1d04ee2","autoSyncIndexes":false,"indexPrefix":"test_"},"ckEditor":{"uploadUrl":"https://39669.cke-cs.com/easyimage/upload/","webSocketUrl":"39669.cke-cs.com/ws"},"logRocket":{"apiKey":"mtnxzn/lesswrong","sampleDensity":5},"hasEvents":true,"hideUnreviewedAuthorComments":false,"cloudinary":{"cloudName":"lesswrong-2-0","uploadPresetGridImage":"tz0mgw2s","uploadPresetBanner":"navcjwf7"},"forum":{"numberOfDays":10,"numberOfWeeks":4,"numberOfMonths":4,"numberOfYears":4,"postInterval":30,"maxPostsPerDay":5},"locale":"en-US","legacyRouteAcronym":"lw","logoUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1498011194/LessWrong_Logo_skglnw.svg","maxDocumentsPerRequest":5000,"commentInterval":15,"timeDecayFactor":1.15,"mapbox":{"apiKey":"pk.eyJ1IjoiaGFicnlrYSIsImEiOiJjaWxvcnhidzgwOGlodHJrbmJ2bmVmdjRtIn0.inr-_5rWOOslGQxY8iDFOA"},"petrov":{"afterTime":1632754800000,"beforeTime":1632667850000,"petrovServerUrl":"https://forum.effectivealtruism.org/graphql","petrovPostId":"EW8yZYcu3Kff2qShS","petrovGamePostId":"EW8yZYcu3Kff2qShS"},"gatherTownMessage":"Schelling social hours on Tues 1pm and Thurs 6pm PT","gardenOpenToPublic":false,"frontpageScoreBonus":0,"stripe":{"publicKey":"pk_live_51HtKAwA2QvoATZCZiy9f2nc6hA52YS1BE81cFu9FEV1IKar0Bwx6hIpxxxYHnhaxO9KM7kRYofZId3sUUI7Q0NeO00tGni3Wza"},"defaultModeratorComments":[{"label":"Option A","id":"FfMok764BCY6ScqWm"},{"label":"Option B","id":"yMHoNoYZdk5cKa3wQ"}],"gatherTownUserTrackingIsBroken":true}</script><script>window.publicInstanceSettings = {"forumType":"LessWrong","title":"LessWrong","siteNameWithArticle":"LessWrong","sentry":{"url":"https://1ab1949fc8d04608b43132f37bb2a1b0@sentry.io/1301611","environment":"production","release":"69f0f3c5d57b596e8249571383f8a280eff9bb23"},"debug":false,"aboutPostId":"bJ2haLkcGeLtTWaD5","faqPostId":"2rWKkWuPrgTMpLRbp","expectedDatabaseId":"production","tagline":"A community blog devoted to refining the art of rationality","faviconUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico","forumSettings":{"headerTitle":"LESSWRONG","shortForumTitle":"LW","tabTitle":"LessWrong"},"analytics":{"environment":"lesswrong.com"},"testServer":false}</script><style id="jss-insertion-point"></style><style data-jss="" data-meta="MuiSvgIcon">
.MuiSvgIcon-root {
  fill: currentColor;
  width: 1em;
  height: 1em;
  display: inline-block;
  font-size: 24px;
  transition: fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  user-select: none;
  flex-shrink: 0;
}
.MuiSvgIcon-colorPrimary {
  color: #5f9b65;
}
.MuiSvgIcon-colorSecondary {
  color: #5f9b65;
}
.MuiSvgIcon-colorAction {
  color: rgba(0, 0, 0, 0.54);
}
.MuiSvgIcon-colorError {
  color: #bf360c;
}
.MuiSvgIcon-colorDisabled {
  color: rgba(0, 0, 0, 0.26);
}
.MuiSvgIcon-fontSizeInherit {
  font-size: inherit;
}
.MuiSvgIcon-fontSizeSmall {
  font-size: 20px;
}
.MuiSvgIcon-fontSizeLarge {
  font-size: 36px;
}
</style><style data-jss="" data-meta="MuiModal">
.MuiModal-root {
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  z-index: 1300;
  position: fixed;
}
.MuiModal-hidden {
  visibility: hidden;
}
</style><style data-jss="" data-meta="MuiPaper">
.MuiPaper-root {
  background-color: #fff;
}
.MuiPaper-rounded {
  border-radius: 4px;
}
.MuiPaper-elevation0 {
  box-shadow: none;
}
.MuiPaper-elevation1 {
  box-shadow: 0px 1px 3px 0px rgba(0, 0, 0, 0.2),0px 1px 1px 0px rgba(0, 0, 0, 0.14),0px 2px 1px -1px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation2 {
  box-shadow: 0px 1px 5px 0px rgba(0, 0, 0, 0.2),0px 2px 2px 0px rgba(0, 0, 0, 0.14),0px 3px 1px -2px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation3 {
  box-shadow: 0px 1px 8px 0px rgba(0, 0, 0, 0.2),0px 3px 4px 0px rgba(0, 0, 0, 0.14),0px 3px 3px -2px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation4 {
  box-shadow: 0px 2px 4px -1px rgba(0, 0, 0, 0.2),0px 4px 5px 0px rgba(0, 0, 0, 0.14),0px 1px 10px 0px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation5 {
  box-shadow: 0px 3px 5px -1px rgba(0, 0, 0, 0.2),0px 5px 8px 0px rgba(0, 0, 0, 0.14),0px 1px 14px 0px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation6 {
  box-shadow: 0px 3px 5px -1px rgba(0, 0, 0, 0.2),0px 6px 10px 0px rgba(0, 0, 0, 0.14),0px 1px 18px 0px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation7 {
  box-shadow: 0px 4px 5px -2px rgba(0, 0, 0, 0.2),0px 7px 10px 1px rgba(0, 0, 0, 0.14),0px 2px 16px 1px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation8 {
  box-shadow: 0px 5px 5px -3px rgba(0, 0, 0, 0.2),0px 8px 10px 1px rgba(0, 0, 0, 0.14),0px 3px 14px 2px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation9 {
  box-shadow: 0px 5px 6px -3px rgba(0, 0, 0, 0.2),0px 9px 12px 1px rgba(0, 0, 0, 0.14),0px 3px 16px 2px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation10 {
  box-shadow: 0px 6px 6px -3px rgba(0, 0, 0, 0.2),0px 10px 14px 1px rgba(0, 0, 0, 0.14),0px 4px 18px 3px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation11 {
  box-shadow: 0px 6px 7px -4px rgba(0, 0, 0, 0.2),0px 11px 15px 1px rgba(0, 0, 0, 0.14),0px 4px 20px 3px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation12 {
  box-shadow: 0px 7px 8px -4px rgba(0, 0, 0, 0.2),0px 12px 17px 2px rgba(0, 0, 0, 0.14),0px 5px 22px 4px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation13 {
  box-shadow: 0px 7px 8px -4px rgba(0, 0, 0, 0.2),0px 13px 19px 2px rgba(0, 0, 0, 0.14),0px 5px 24px 4px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation14 {
  box-shadow: 0px 7px 9px -4px rgba(0, 0, 0, 0.2),0px 14px 21px 2px rgba(0, 0, 0, 0.14),0px 5px 26px 4px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation15 {
  box-shadow: 0px 8px 9px -5px rgba(0, 0, 0, 0.2),0px 15px 22px 2px rgba(0, 0, 0, 0.14),0px 6px 28px 5px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation16 {
  box-shadow: 0px 8px 10px -5px rgba(0, 0, 0, 0.2),0px 16px 24px 2px rgba(0, 0, 0, 0.14),0px 6px 30px 5px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation17 {
  box-shadow: 0px 8px 11px -5px rgba(0, 0, 0, 0.2),0px 17px 26px 2px rgba(0, 0, 0, 0.14),0px 6px 32px 5px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation18 {
  box-shadow: 0px 9px 11px -5px rgba(0, 0, 0, 0.2),0px 18px 28px 2px rgba(0, 0, 0, 0.14),0px 7px 34px 6px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation19 {
  box-shadow: 0px 9px 12px -6px rgba(0, 0, 0, 0.2),0px 19px 29px 2px rgba(0, 0, 0, 0.14),0px 7px 36px 6px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation20 {
  box-shadow: 0px 10px 13px -6px rgba(0, 0, 0, 0.2),0px 20px 31px 3px rgba(0, 0, 0, 0.14),0px 8px 38px 7px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation21 {
  box-shadow: 0px 10px 13px -6px rgba(0, 0, 0, 0.2),0px 21px 33px 3px rgba(0, 0, 0, 0.14),0px 8px 40px 7px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation22 {
  box-shadow: 0px 10px 14px -6px rgba(0, 0, 0, 0.2),0px 22px 35px 3px rgba(0, 0, 0, 0.14),0px 8px 42px 7px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation23 {
  box-shadow: 0px 11px 14px -7px rgba(0, 0, 0, 0.2),0px 23px 36px 3px rgba(0, 0, 0, 0.14),0px 9px 44px 8px rgba(0, 0, 0, 0.12);
}
.MuiPaper-elevation24 {
  box-shadow: 0px 11px 15px -7px rgba(0, 0, 0, 0.2),0px 24px 38px 3px rgba(0, 0, 0, 0.14),0px 9px 46px 8px rgba(0, 0, 0, 0.12);
}
</style><style data-jss="" data-meta="MuiPopover">
.MuiPopover-paper {
  outline: none;
  position: absolute;
  min-width: 16px;
  max-width: calc(100% - 32px);
  overflow-y: auto;
  overflow-x: hidden;
  min-height: 16px;
  max-height: calc(100% - 32px);
}
</style><style data-jss="" data-meta="MuiTouchRipple">
.MuiTouchRipple-root {
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  display: block;
  z-index: 0;
  position: absolute;
  overflow: hidden;
  border-radius: inherit;
  pointer-events: none;
}
.MuiTouchRipple-ripple {
  top: 0;
  left: 0;
  width: 50px;
  height: 50px;
  opacity: 0;
  position: absolute;
}
.MuiTouchRipple-rippleVisible {
  opacity: 0.3;
  transform: scale(1);
  animation: mui-ripple-enter 550ms cubic-bezier(0.4, 0, 0.2, 1);
}
.MuiTouchRipple-ripplePulsate {
  animation-duration: 200ms;
}
.MuiTouchRipple-child {
  width: 100%;
  height: 100%;
  opacity: 1;
  display: block;
  border-radius: 50%;
  background-color: currentColor;
}
.MuiTouchRipple-childLeaving {
  opacity: 0;
  animation: mui-ripple-exit 550ms cubic-bezier(0.4, 0, 0.2, 1);
}
.MuiTouchRipple-childPulsate {
  top: 0;
  left: 0;
  position: absolute;
  animation: mui-ripple-pulsate 2500ms cubic-bezier(0.4, 0, 0.2, 1) 200ms infinite;
}
@-webkit-keyframes mui-ripple-enter {
  0% {
    opacity: 0.1;
    transform: scale(0);
  }
  100% {
    opacity: 0.3;
    transform: scale(1);
  }
}
@-webkit-keyframes mui-ripple-exit {
  0% {
    opacity: 1;
  }
  100% {
    opacity: 0;
  }
}
@-webkit-keyframes mui-ripple-pulsate {
  0% {
    transform: scale(1);
  }
  50% {
    transform: scale(0.92);
  }
  100% {
    transform: scale(1);
  }
}
</style><style data-jss="" data-meta="MuiButtonBase">
.MuiButtonBase-root {
  color: inherit;
  border: 0;
  margin: 0;
  cursor: pointer;
  display: inline-flex;
  outline: none;
  padding: 0;
  position: relative;
  align-items: center;
  user-select: none;
  border-radius: 0;
  vertical-align: middle;
  justify-content: center;
  -moz-appearance: none;
  text-decoration: none;
  background-color: transparent;
  -webkit-appearance: none;
  -webkit-tap-highlight-color: transparent;
}
.MuiButtonBase-root::-moz-focus-inner {
  border-style: none;
}
.MuiButtonBase-root.MuiButtonBase-disabled {
  cursor: default;
  pointer-events: none;
}
</style><style data-jss="" data-meta="MuiListItem">
.MuiListItem-root {
  width: 100%;
  display: flex;
  position: relative;
  box-sizing: border-box;
  text-align: left;
  align-items: center;
  padding-top: 8px;
  padding-bottom: 8px;
  justify-content: flex-start;
  text-decoration: none;
}
.MuiListItem-root.MuiListItem-selected, .MuiListItem-root.MuiListItem-selected:hover {
  background-color: rgba(0, 0, 0, 0.14);
}
.MuiListItem-container {
  position: relative;
}
.MuiListItem-focusVisible {
  background-color: rgba(0, 0, 0, 0.08);
}
.MuiListItem-dense {
  padding-top: 8px;
  padding-bottom: 8px;
}
.MuiListItem-disabled {
  opacity: 0.5;
}
.MuiListItem-divider {
  border-bottom: 1px solid rgba(0, 0, 0, 0.12);
  background-clip: padding-box;
}
.MuiListItem-gutters {
  padding-left: 16px;
  padding-right: 16px;
}
@media (min-width:600px) {
  .MuiListItem-gutters {
    padding-left: 24px;
    padding-right: 24px;
  }
}
.MuiListItem-button {
  transition: background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
}
.MuiListItem-button:hover {
  text-decoration: none;
  background-color: rgba(0, 0, 0, 0.08);
}
@media (hover: none) {
  .MuiListItem-button:hover {
    background-color: transparent;
  }
}
.MuiListItem-secondaryAction {
  padding-right: 32px;
}
</style><style data-jss="" data-meta="MuiMenuItem">
.MuiMenuItem-root {
  color: #424242;
  width: auto;
  height: 24px;
  overflow: hidden;
  font-size: 1.1rem;
  box-sizing: content-box;
  font-weight: 400;
  font-family: GreekFallback,Calibri,"Gill Sans","Gill Sans MT",Myriad Pro,Myriad,"Liberation Sans","Nimbus Sans L",Tahoma,Geneva,"Helvetica Neue",Helvetica,Arial,sans-serif;
  line-height: 1em;
  white-space: nowrap;
  padding-left: 16px;
  text-overflow: ellipsis;
  padding-right: 16px;
}
</style><style data-jss="" data-meta="MuiButton">
.MuiButton-root {
  color: rgba(0, 0, 0, 0.87);
  padding: 8px 16px;
  font-size: 0.875rem;
  min-width: 64px;
  box-sizing: border-box;
  min-height: 36px;
  transition: background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  font-weight: 500;
  font-family: GreekFallback,Calibri,"Gill Sans","Gill Sans MT",Myriad Pro,Myriad,"Liberation Sans","Nimbus Sans L",Tahoma,Geneva,"Helvetica Neue",Helvetica,Arial,sans-serif;
  line-height: 1.4em;
  border-radius: 4px;
  text-transform: uppercase;
}
.MuiButton-root:hover {
  text-decoration: none;
  background-color: rgba(0, 0, 0, 0.08);
}
.MuiButton-root.MuiButton-disabled {
  color: rgba(0, 0, 0, 0.26);
}
@media (hover: none) {
  .MuiButton-root:hover {
    background-color: transparent;
  }
}
.MuiButton-root:hover.MuiButton-disabled {
  background-color: transparent;
}
.MuiButton-label {
  width: 100%;
  display: inherit;
  align-items: inherit;
  justify-content: inherit;
}
.MuiButton-textPrimary {
  color: #5f9b65;
}
.MuiButton-textPrimary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiButton-textPrimary:hover {
    background-color: transparent;
  }
}
.MuiButton-textSecondary {
  color: #5f9b65;
}
.MuiButton-textSecondary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiButton-textSecondary:hover {
    background-color: transparent;
  }
}
.MuiButton-outlined {
  border: 1px solid rgba(0, 0, 0, 0.23);
}
.MuiButton-outlinedPrimary {
  border: 1px solid rgba(95, 155, 101, 0.5);
}
.MuiButton-outlinedPrimary:hover {
  border: 1px solid #5f9b65;
}
.MuiButton-outlinedPrimary.MuiButton-disabled {
  border: 1px solid rgba(0, 0, 0, 0.26);
}
.MuiButton-outlinedSecondary {
  border: 1px solid rgba(95, 155, 101, 0.5);
}
.MuiButton-outlinedSecondary:hover {
  border: 1px solid #5f9b65;
}
.MuiButton-outlinedSecondary.MuiButton-disabled {
  border: 1px solid rgba(0, 0, 0, 0.26);
}
.MuiButton-contained {
  color: rgba(0, 0, 0, 0.87);
  box-shadow: 0px 1px 5px 0px rgba(0, 0, 0, 0.2),0px 2px 2px 0px rgba(0, 0, 0, 0.14),0px 3px 1px -2px rgba(0, 0, 0, 0.12);
  background-color: #e0e0e0;
}
.MuiButton-contained.MuiButton-focusVisible {
  box-shadow: 0px 3px 5px -1px rgba(0, 0, 0, 0.2),0px 6px 10px 0px rgba(0, 0, 0, 0.14),0px 1px 18px 0px rgba(0, 0, 0, 0.12);
}
.MuiButton-contained:active {
  box-shadow: 0px 5px 5px -3px rgba(0, 0, 0, 0.2),0px 8px 10px 1px rgba(0, 0, 0, 0.14),0px 3px 14px 2px rgba(0, 0, 0, 0.12);
}
.MuiButton-contained.MuiButton-disabled {
  color: rgba(0, 0, 0, 0.26);
  box-shadow: none;
  background-color: rgba(0, 0, 0, 0.12);
}
.MuiButton-contained:hover {
  background-color: #d5d5d5;
}
@media (hover: none) {
  .MuiButton-contained:hover {
    background-color: #e0e0e0;
  }
}
.MuiButton-contained:hover.MuiButton-disabled {
  background-color: rgba(0, 0, 0, 0.12);
}
.MuiButton-containedPrimary {
  color: #fff;
  background-color: #5f9b65;
}
.MuiButton-containedPrimary:hover {
  background-color: rgb(66, 108, 70);
}
@media (hover: none) {
  .MuiButton-containedPrimary:hover {
    background-color: #5f9b65;
  }
}
.MuiButton-containedSecondary {
  color: #fff;
  background-color: #5f9b65;
}
.MuiButton-containedSecondary:hover {
  background-color: rgb(66, 108, 70);
}
@media (hover: none) {
  .MuiButton-containedSecondary:hover {
    background-color: #5f9b65;
  }
}
.MuiButton-fab {
  width: 56px;
  height: 56px;
  padding: 0;
  min-width: 0;
  box-shadow: 0px 3px 5px -1px rgba(0, 0, 0, 0.2),0px 6px 10px 0px rgba(0, 0, 0, 0.14),0px 1px 18px 0px rgba(0, 0, 0, 0.12);
  border-radius: 50%;
}
.MuiButton-fab:active {
  box-shadow: 0px 7px 8px -4px rgba(0, 0, 0, 0.2),0px 12px 17px 2px rgba(0, 0, 0, 0.14),0px 5px 22px 4px rgba(0, 0, 0, 0.12);
}
.MuiButton-extendedFab {
  width: auto;
  height: 48px;
  padding: 0 16px;
  min-width: 48px;
  border-radius: 24px;
}
.MuiButton-colorInherit {
  color: inherit;
}
.MuiButton-mini {
  width: 40px;
  height: 40px;
}
.MuiButton-sizeSmall {
  padding: 7px 8px;
  min-width: 64px;
  font-size: 0.8125rem;
  min-height: 32px;
}
.MuiButton-sizeLarge {
  padding: 8px 24px;
  min-width: 112px;
  font-size: 0.9375rem;
  min-height: 40px;
}
.MuiButton-fullWidth {
  width: 100%;
}
</style><style data-jss="" data-meta="MuiAppBar">
.MuiAppBar-root {
  width: 100%;
  display: flex;
  z-index: 1100;
  box-sizing: border-box;
  flex-shrink: 0;
  flex-direction: column;
}
.MuiAppBar-positionFixed {
  top: 0;
  left: auto;
  right: 0;
  position: fixed;
}
.MuiAppBar-positionAbsolute {
  top: 0;
  left: auto;
  right: 0;
  position: absolute;
}
.MuiAppBar-positionSticky {
  top: 0;
  left: auto;
  right: 0;
  position: sticky;
}
.MuiAppBar-positionStatic {
  position: static;
}
.MuiAppBar-positionRelative {
  position: relative;
}
.MuiAppBar-colorDefault {
  color: rgba(0, 0, 0, 0.87);
  background-color: #fbfbfb;
}
.MuiAppBar-colorPrimary {
  color: #fff;
  background-color: #5f9b65;
}
.MuiAppBar-colorSecondary {
  color: #fff;
  background-color: #5f9b65;
}
</style><style data-jss="" data-meta="MuiToolbar">
.MuiToolbar-root {
  display: flex;
  position: relative;
  align-items: center;
}
.MuiToolbar-gutters {
  padding-left: 16px;
  padding-right: 16px;
}
@media (min-width:600px) {
  .MuiToolbar-gutters {
    padding-left: 24px;
    padding-right: 24px;
  }
}
.MuiToolbar-regular {
  min-height: 56px;
}
@media (min-width:0px) and (orientation: landscape) {
  .MuiToolbar-regular {
    min-height: 48px;
  }
}
@media (min-width:600px) {
  .MuiToolbar-regular {
    min-height: 64px;
  }
}
.MuiToolbar-dense {
  min-height: 48px;
}
</style><style data-jss="" data-meta="MuiIconButton">
.MuiIconButton-root {
  flex: 0 0 auto;
  color: rgba(0, 0, 0, 0.54);
  padding: 12px;
  overflow: visible;
  font-size: 1.5rem;
  text-align: center;
  transition: background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  border-radius: 50%;
}
.MuiIconButton-root:hover {
  background-color: rgba(0, 0, 0, 0.08);
}
.MuiIconButton-root.MuiIconButton-disabled {
  color: rgba(0, 0, 0, 0.26);
}
@media (hover: none) {
  .MuiIconButton-root:hover {
    background-color: transparent;
  }
}
.MuiIconButton-root:hover.MuiIconButton-disabled {
  background-color: transparent;
}
.MuiIconButton-colorInherit {
  color: inherit;
}
.MuiIconButton-colorPrimary {
  color: #5f9b65;
}
.MuiIconButton-colorPrimary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiIconButton-colorPrimary:hover {
    background-color: transparent;
  }
}
.MuiIconButton-colorSecondary {
  color: #5f9b65;
}
.MuiIconButton-colorSecondary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiIconButton-colorSecondary:hover {
    background-color: transparent;
  }
}
.MuiIconButton-label {
  width: 100%;
  display: flex;
  align-items: inherit;
  justify-content: inherit;
}
</style><style data-jss="" data-meta="MuiSnackbar">
.MuiSnackbar-root {
  left: 0;
  right: 0;
  z-index: 1400;
  display: flex;
  position: fixed;
  align-items: center;
  justify-content: center;
}
.MuiSnackbar-anchorOriginTopCenter {
  top: 0;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopCenter {
    left: 50%;
    right: auto;
    transform: translateX(-50%);
  }
}
.MuiSnackbar-anchorOriginBottomCenter {
  bottom: 0;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomCenter {
    left: 50%;
    right: auto;
    transform: translateX(-50%);
  }
}
.MuiSnackbar-anchorOriginTopRight {
  top: 0;
  justify-content: flex-end;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopRight {
    top: 24px;
    left: auto;
    right: 24px;
  }
}
.MuiSnackbar-anchorOriginBottomRight {
  bottom: 0;
  justify-content: flex-end;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomRight {
    left: auto;
    right: 24px;
    bottom: 24px;
  }
}
.MuiSnackbar-anchorOriginTopLeft {
  top: 0;
  justify-content: flex-start;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopLeft {
    top: 24px;
    left: 24px;
    right: auto;
  }
}
.MuiSnackbar-anchorOriginBottomLeft {
  bottom: 0;
  justify-content: flex-start;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomLeft {
    left: 24px;
    right: auto;
    bottom: 24px;
  }
}
</style><style data-jss="" data-meta="MuiDivider">
.MuiDivider-root {
  height: 1px;
  margin: 0;
  border: none;
  flex-shrink: 0;
  background-color: rgba(0, 0, 0, 0.12);
}
.MuiDivider-absolute {
  left: 0;
  width: 100%;
  bottom: 0;
  position: absolute;
}
.MuiDivider-inset {
  margin-left: 72px;
}
.MuiDivider-light {
  background-color: rgba(0, 0, 0, 0.08);
}
</style><style data-jss="" data-meta="MuiDrawer">
.MuiDrawer-docked {
  flex: 0 0 auto;
}
.MuiDrawer-paper {
  top: 0;
  flex: 1 0 auto;
  height: 100%;
  display: flex;
  z-index: 1200;
  outline: none;
  position: fixed;
  overflow-y: auto;
  flex-direction: column;
  -webkit-overflow-scrolling: touch;
}
.MuiDrawer-paperAnchorLeft {
  left: 0;
  right: auto;
}
.MuiDrawer-paperAnchorRight {
  left: auto;
  right: 0;
}
.MuiDrawer-paperAnchorTop {
  top: 0;
  left: 0;
  right: 0;
  bottom: auto;
  height: auto;
  max-height: 100%;
}
.MuiDrawer-paperAnchorBottom {
  top: auto;
  left: 0;
  right: 0;
  bottom: 0;
  height: auto;
  max-height: 100%;
}
.MuiDrawer-paperAnchorDockedLeft {
  border-right: 1px solid rgba(0, 0, 0, 0.12);
}
.MuiDrawer-paperAnchorDockedTop {
  border-bottom: 1px solid rgba(0, 0, 0, 0.12);
}
.MuiDrawer-paperAnchorDockedRight {
  border-left: 1px solid rgba(0, 0, 0, 0.12);
}
.MuiDrawer-paperAnchorDockedBottom {
  border-top: 1px solid rgba(0, 0, 0, 0.12);
}
</style><style data-jss="">
.jss133 {
  top: 0;
  left: 0;
  bottom: 0;
  z-index: 1199;
  position: fixed;
}
.jss134 {
  right: auto;
}
.jss135 {
  left: auto;
  right: 0;
}
.jss136 {
  right: 0;
  bottom: auto;
}
.jss137 {
  top: auto;
  right: 0;
  bottom: 0;
}
</style><style data-jss="" data-meta="MuiCard">
.MuiCard-root {
  overflow: hidden;
  box-shadow: 0 0 10px rgba(0,0,0,.2);
  border-radius: 1px;
}
</style><style data-jss="" data-meta="MuiTooltip">
.MuiTooltip-popper {
  z-index: 1500;
  opacity: 0.9;
}
.MuiTooltip-tooltip {
  color: #fff;
  padding: .7rem;
  z-index: 10000000;
  font-size: 1rem;
  max-width: 300px;
  font-family: GreekFallback,Calibri,"Gill Sans","Gill Sans MT",Myriad Pro,Myriad,"Liberation Sans","Nimbus Sans L",Tahoma,Geneva,"Helvetica Neue",Helvetica,Arial,sans-serif;
  line-height: 1.4em;
  border-radius: 4px;
  background-color: #616161;
}
.MuiTooltip-touch {
  padding: 8px 16px;
  font-size: 0.875rem;
  line-height: 1.14286em;
}
.MuiTooltip-tooltipPlacementLeft {
  margin: 0 24px ;
  transform-origin: right center;
}
@media (min-width:600px) {
  .MuiTooltip-tooltipPlacementLeft {
    margin: 0 14px;
  }
}
.MuiTooltip-tooltipPlacementRight {
  margin: 0 24px;
  transform-origin: left center;
}
@media (min-width:600px) {
  .MuiTooltip-tooltipPlacementRight {
    margin: 0 14px;
  }
}
.MuiTooltip-tooltipPlacementTop {
  margin: 24px 0;
  transform-origin: center bottom;
}
@media (min-width:600px) {
  .MuiTooltip-tooltipPlacementTop {
    margin: 14px 0;
  }
}
.MuiTooltip-tooltipPlacementBottom {
  margin: 24px 0;
  transform-origin: center top;
}
@media (min-width:600px) {
  .MuiTooltip-tooltipPlacementBottom {
    margin: 14px 0;
  }
}
</style><link rel="stylesheet" onerror="window.missingMainStylesheet=true" href="./The Library - LessWrong_files/allStyles"><script async="" src="./The Library - LessWrong_files/wtb8z7sj"></script><link rel="canonical" href="https://www.lesswrong.com/library" data-react-helmet="true"><meta property="og:url" content="https://www.lesswrong.com/library" data-react-helmet="true"></head>
<body class="abTestNoEffect_group1">
<div id="react-app"><div class="wrapper" id="wrapper"><div></div><span></span><div id="intercome-outer-frame"></div><noscript class="noscript-warning"> This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. </noscript><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TRC765W" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div class="Header-root"><div style="height:64px" class="Header-headroom headroom-wrapper"><div class="headroom headroom--unfixed headroom-disable-animation"><header class="MuiPaper-root MuiPaper-elevation4 MuiAppBar-root MuiAppBar-positionStatic MuiAppBar-colorDefault Header-appBar"><div class="MuiToolbar-root MuiToolbar-regular MuiToolbar-gutters"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root MuiIconButton-colorInherit Header-menuButton Header-hideLgUp" type="button" aria-label="Menu"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"></path></svg></span><span class="MuiTouchRipple-root"></span></button><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root MuiIconButton-colorInherit Header-menuButton Header-hideMdDown" type="button" aria-label="Menu"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"></path></svg></span><span class="MuiTouchRipple-root"></span></button><h2 class="Typography-root Typography-title Header-title"><div class="Header-hideSmDown"><div class="Header-titleSubtitleContainer"><a class="Header-titleLink" href="https://www.lesswrong.com/">LESSWRONG</a></div></div><div class="Header-hideMdUp"><a class="Header-titleLink" href="https://www.lesswrong.com/">LW</a></div></h2><div class="Header-rightHeaderItems"><div class="SearchBar-root"><div class="SearchBar-rootChild"><div class="SearchBar-searchInputArea"><div><svg class="MuiSvgIcon-root SearchBar-searchIcon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></div><div></div></div></div></div><div class="UsersAccountMenu-root"><button tabindex="0" class="MuiButtonBase-root MuiButton-root MuiButton-text MuiButton-flat" type="button"><span class="MuiButton-label"><span class="UsersAccountMenu-userButton" style="color:rgba(0, 0, 0, 0.87)">Login</span></span><span class="MuiTouchRipple-root"></span></button></div></div></div></header><div class="jss133 jss134" style="width: 20px;"></div></div></div></div><div class="Layout-gridActivated"><div class="Layout-navSidebar"><div class="NavigationStandalone-root"><div class="NavigationStandalone-sidebar"><div class="TabNavigationMenu-root"><span class="LWTooltip-root"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-navButton" role="menuitem" href="https://www.lesswrong.com/"><span class="TabNavigationItem-icon TabNavigationItem-homeIcon"><svg version="1.1" x="0px" y="0px" viewBox="0 0 100 100"><g><path d="M29.1,29.2l6.4,11.6l4.3-0.8l0.8-4.3L29.1,29.2z M40.7,64.5l-0.8-4.3l-4.3-0.8L29.2,71L40.7,64.5z M70.9,70.9l-6.4-11.6l-4.3,0.8l-0.8,4.3L70.9,70.9z M64.4,40.8l6.4-11.6l-11.6,6.4l0.8,4.3L64.4,40.8z M67.4,58.8l10.8,19.4L58.8,67.4L50,98.8l-8.8-31.4L21.9,78.2l10.8-19.4L1.2,50.1l31.4-8.8L21.9,21.9l19.4,10.8L50,1.3l8.8,31.4l19.4-10.8L67.4,41.3L98.8,50L67.4,58.8zM57.7,57.8L83.5,50L50,50.1l7.7-7.7L50,16.6v33.5l-7.7-7.7l-25.8,7.7H50l-7.7,7.7L50,83.5V50.1L57.7,57.8z"></path></g></svg></span><span class="TabNavigationItem-navText">Home</span><span class="MuiTouchRipple-root"></span></a></span><span class="LWTooltip-root"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-navButton" role="menuitem" href="https://www.lesswrong.com/tags/all"><span class="TabNavigationItem-icon"><svg version="1.1" x="0px" y="0px" viewBox="10 10 90 90"><path d="M62.648,14.41c-7.396-0.624-14.651,2.03-19.906,7.285c-3.807,3.807-6.268,8.75-7.065,14.054  c-5.283,0.785-10.225,3.236-14.085,7.096c-4.19,4.19-6.772,9.755-7.272,15.667c-0.563,6.697,1.512,13.212,5.848,18.346  c4.335,5.136,10.413,8.273,17.106,8.834c7.398,0.628,14.655-2.029,19.91-7.284c3.805-3.805,6.265-8.749,7.062-14.053  c5.283-0.784,10.227-3.235,14.086-7.096c4.189-4.189,6.773-9.754,7.273-15.67C86.77,27.771,76.473,15.578,62.648,14.41z   M55.561,76.783c-4.597,4.596-11.109,7.21-18.092,6.621c-12.582-1.06-21.918-12.119-20.858-24.7  c0.472-5.594,2.923-10.55,6.606-14.232c3.273-3.273,7.529-5.515,12.226-6.336c-0.347,6.424,1.708,12.638,5.875,17.574  c4.333,5.134,10.411,8.272,17.105,8.835c1.166,0.1,2.327,0.106,3.479,0.045C61.069,69.348,58.789,73.555,55.561,76.783z   M62.178,62.248c-1.171,0.082-2.354,0.109-3.561,0.008c-12.482-1.05-21.755-11.945-20.866-24.399  c1.169-0.083,2.353-0.11,3.558-0.008C53.788,38.903,63.064,49.792,62.178,62.248z M83.315,41.397  c-0.474,5.596-2.924,10.554-6.606,14.237c-3.275,3.274-7.531,5.515-12.228,6.336C65.207,48.47,55.063,36.705,41.5,35.559  c-1.164-0.098-2.324-0.106-3.475-0.044c0.832-4.758,3.113-8.964,6.341-12.193c4.596-4.596,11.109-7.211,18.09-6.621  C75.037,17.763,84.375,28.817,83.315,41.397z"></path><path d="M49.384,64.735c-1.677-0.739-3.272-1.645-4.772-2.708c-0.927-0.657-1.816-1.369-2.662-2.144  c-0.861-0.788-1.692-1.613-2.459-2.517c-0.019-0.022-0.042-0.043-0.061-0.065c-0.542-0.641-1.042-1.309-1.52-1.99  c-0.549-0.786-1.045-1.602-1.508-2.434c-0.364-0.656-0.699-1.324-1.008-2.006c-0.354-0.782-0.671-1.578-0.95-2.39  c-0.223-0.648-0.419-1.305-0.593-1.97c-0.203-0.773-0.373-1.557-0.507-2.349c-0.11-0.644-0.194-1.292-0.257-1.946  c-0.031-0.311-0.077-0.62-0.097-0.933c-0.668,0.218-1.318,0.476-1.956,0.76c-1.053,0.47-2.062,1.028-3.019,1.67  c-0.922,0.618-1.794,1.315-2.611,2.085c-0.147,0.139-0.298,0.273-0.442,0.417c-0.436,0.436-0.848,0.891-1.24,1.361  c-0.574,0.689-1.085,1.423-1.562,2.178c-0.375,0.594-0.72,1.204-1.031,1.833c-0.359,0.724-0.683,1.464-0.953,2.227  c-0.218,0.613-0.401,1.24-0.56,1.875c-0.186,0.746-0.323,1.506-0.424,2.273c-0.041,0.315-0.095,0.628-0.122,0.946  c-0.027,0.321-0.022,0.641-0.034,0.961c-0.03,0.775-0.018,1.545,0.04,2.31c0.049,0.652,0.128,1.3,0.239,1.94  c0.138,0.796,0.312,1.581,0.544,2.353c0.201,0.672,0.433,1.335,0.704,1.984c0.345,0.827,0.752,1.628,1.207,2.408  c0.411,0.703,0.871,1.38,1.37,2.038c0.222,0.293,0.431,0.594,0.67,0.877c0.483,0.572,0.999,1.106,1.534,1.617  c0.834,0.796,1.73,1.51,2.675,2.146c1.964,1.324,4.146,2.282,6.464,2.853c1.042,0.257,2.103,0.454,3.192,0.546  c1.064,0.09,2.12,0.066,3.168-0.009c2.392-0.17,4.716-0.755,6.883-1.729c1.045-0.47,2.054-1.022,3.013-1.668  c0.919-0.616,1.788-1.315,2.608-2.085c0.151-0.144,0.316-0.269,0.464-0.416c0.435-0.435,0.826-0.899,1.216-1.366  c0.581-0.692,1.121-1.412,1.6-2.169c0.375-0.593,0.709-1.209,1.02-1.836c0.358-0.723,0.675-1.464,0.943-2.228  c0.048-0.134,0.111-0.26,0.156-0.394c-0.179-0.012-0.356-0.025-0.532-0.04C55.116,66.745,52.149,65.953,49.384,64.735z"></path><path d="M43.815,51.052L54.95,47.54c-0.607-0.724-1.259-1.412-1.96-2.046l-10.529,3.321C42.864,49.591,43.318,50.336,43.815,51.052z  "></path><path d="M47.913,42.134l-7.13,2.249c0.208,0.827,0.469,1.632,0.776,2.419l9.346-2.948C49.961,43.201,48.963,42.623,47.913,42.134z"></path><path d="M41.102,40.309c-0.299-0.025-0.605-0.042-0.924-0.05c0.025,0.662,0.086,1.316,0.175,1.963l4.163-1.313  C43.412,40.619,42.274,40.409,41.102,40.309z"></path><path d="M58.824,59.795c0.301,0.025,0.607,0.042,0.926,0.051c-0.02-0.525-0.073-1.043-0.133-1.559l-3.442,1.086  C57.04,59.562,57.919,59.719,58.824,59.795z"></path><path d="M52.566,58.213l6.684-2.108c-0.191-0.831-0.45-1.637-0.742-2.43l-9.067,2.86C50.426,57.181,51.47,57.742,52.566,58.213z"></path><path d="M47.283,54.918l10.356-3.267c-0.386-0.777-0.806-1.537-1.283-2.259l-11.098,3.501C45.888,53.612,46.56,54.294,47.283,54.918  z"></path></svg></span><span class="TabNavigationItem-navText">Concepts</span><span class="MuiTouchRipple-root"></span></a></span><span class="LWTooltip-root"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-navButton TabNavigationItem-selected" role="menuitem" href="https://www.lesswrong.com/library"><span class="TabNavigationItem-icon"><img width="28" height="28" src="data:image/png;base64,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"></span><span class="TabNavigationItem-navText">Library</span><span class="MuiTouchRipple-root"></span></a></span><span class="LWTooltip-root"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-subItemOverride" role="menuitem" href="https://www.lesswrong.com/rationality"><div class="TabNavigationSubItem-root">Rationality: A-Z</div><span class="MuiTouchRipple-root"></span></a></span><span class="LWTooltip-root"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-subItemOverride" role="menuitem" href="https://www.lesswrong.com/codex"><div class="TabNavigationSubItem-root">The Codex</div><span class="MuiTouchRipple-root"></span></a></span><span class="LWTooltip-root"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-subItemOverride" role="menuitem" href="https://www.lesswrong.com/hpmor"><div class="TabNavigationSubItem-root">HPMOR</div><span class="MuiTouchRipple-root"></span></a></span><span class="LWTooltip-root"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-navButton" role="menuitem" href="https://www.lesswrong.com/community"><span class="TabNavigationItem-icon"><svg width="28" height="34" viewBox="0 0 28 34" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M14.042 0.653442C21.3573 0.653442 27.3273 6.45284 27.3273 13.6408C27.3273 20.7471 21.3573 26.5465 14.042 26.5465C6.64258 26.5465 0.672607 20.7471 0.672607 13.6408C0.672607 6.45284 6.64258 0.653442 14.042 0.653442ZM11.4354 13.2324C11.4354 13.2324 10.9309 13.1507 10.8468 13.1507C10.0059 13.3141 10.0059 13.1507 10.7627 13.6408C11.2672 13.9676 11.099 13.9676 11.6035 13.8859C11.7717 13.9676 11.9399 13.9676 12.108 14.0492C12.108 14.1309 12.108 14.2943 12.108 14.376C12.108 14.376 12.5285 14.621 12.6125 14.621H13.2852C13.3693 14.621 14.042 14.2126 12.8648 13.8859C12.6966 13.8859 12.4444 13.8859 12.1921 13.9676C12.108 13.8042 12.024 13.6408 11.8558 13.4775C11.8558 13.4775 11.3513 13.2324 11.4354 13.2324ZM24.3843 7.18798C25.5615 9.06666 26.3183 11.2721 26.3183 13.6408C26.3183 14.2943 26.2342 15.0294 26.1501 15.6829C25.5615 15.1928 24.9729 14.7844 24.8888 14.7027C24.6366 14.4576 24.6366 14.8661 24.4684 15.3561C24.3843 15.9279 23.7116 15.4378 23.2071 15.4378C22.7026 15.4378 22.3663 14.7844 22.3663 14.7844C21.4414 14.0492 21.6936 13.6408 21.6936 12.4973C21.6936 12.1706 21.8618 11.7622 22.114 11.5988C22.7026 10.9453 22.1981 10.5369 22.8708 10.0468C23.1231 9.88347 24.048 9.63843 24.048 9.63843C24.5525 8.98497 24.8047 8.82161 23.5435 9.06666C23.4594 9.14834 22.9549 9.06666 22.7026 8.90329C22.3663 8.65825 23.1231 8.49488 23.1231 8.49488C23.4594 8.08648 23.7957 7.75975 24.1321 7.43302C24.2162 7.35134 24.3002 7.26966 24.3843 7.18798ZM14.042 1.7153C15.2192 1.7153 16.3122 1.87867 17.4053 2.12371C17.6576 2.45044 18.078 2.94053 18.1621 3.02221C18.2462 3.10389 18.4984 3.75735 18.4984 3.75735C17.9939 4.49248 17.8258 4.90089 16.7327 4.4108C16.3963 4.32912 15.8077 3.5123 15.8077 3.5123C15.8077 3.5123 14.8828 2.53212 14.7146 2.45044C14.3783 2.20539 13.8738 2.36876 13.6216 2.77717C13.7897 3.02221 13.8738 3.18557 14.042 3.43062C14.7987 3.43062 14.7987 3.26726 15.051 3.83903C14.7987 3.92071 14.5465 4.00239 14.2101 4.08407C13.4534 4.57416 13.7056 4.57416 12.8648 4.00239C12.8648 4.00239 12.3603 3.43062 12.2762 3.34894C12.1921 3.26726 11.8558 2.53212 11.6876 2.28708C11.6876 2.20539 11.6035 2.04203 11.6876 1.87867C12.4444 1.79699 13.2011 1.7153 14.042 1.7153ZM14.4624 25.5664C13.6216 25.5664 12.7807 25.4847 11.8558 25.403C11.9399 24.8312 11.9399 24.3411 11.9399 23.851C11.9399 22.5441 12.2762 22.2991 11.1831 21.564C10.9309 21.1555 10.5945 20.6655 10.2582 20.257C9.50144 19.5219 9.75369 19.6036 10.1741 18.6234C10.2582 18.215 10.3423 17.8066 10.4264 17.4799C10.2582 17.0715 10.1741 16.6631 10.0059 16.2546C9.6696 15.9279 9.33327 15.5195 8.99693 15.1928C7.14708 14.7027 7.23117 14.9477 5.88582 13.5591C5.63357 13.1507 5.38132 12.7423 5.04498 12.3339C4.12005 11.2721 4.28822 11.4354 3.95189 10.1285C3.8678 9.55675 3.78372 8.98497 3.69963 8.49488C3.61555 8.16816 3.53147 7.84143 3.44738 7.59639C5.12906 4.81921 7.90384 2.77717 11.1831 2.04203C11.099 2.45044 11.015 2.85885 10.9309 3.34894C8.91285 4.90089 7.90384 5.3093 10.3423 6.2078C10.9309 7.1063 10.7627 7.5147 11.5195 6.94293C11.5195 6.45284 11.4354 5.96275 11.3513 5.47266C12.8648 4.49248 12.4444 4.65584 14.2101 5.55434C14.4624 5.79939 14.7146 6.04443 14.9669 6.28948C16.1441 6.77957 16.2282 6.53452 15.2192 7.26966C14.9669 7.18798 14.6306 7.18798 14.2942 7.1063C14.1261 7.26966 13.9579 7.43302 13.7897 7.59639C14.2101 8.49488 14.4624 8.4132 13.5375 8.65825C13.2852 8.82161 13.033 9.06666 12.7807 9.23002C12.4444 9.23002 12.108 9.23002 11.7717 9.23002C11.7717 9.23002 11.7717 10.2102 11.7717 10.3736C11.7717 10.6186 11.015 11.2721 11.015 11.2721C11.015 11.2721 10.5945 11.8438 10.8468 12.1706C11.015 12.4973 10.5945 12.7423 10.5945 12.7423C10.3423 12.4973 10.1741 12.1706 9.92186 11.9255C9.58552 11.9255 9.1651 12.0072 8.74468 12.0889C8.49243 12.2522 8.24018 12.3339 7.98792 12.4973C7.90384 12.7423 7.81975 13.0691 7.81975 13.3141C7.90384 13.7225 7.98792 14.1309 8.15609 14.5393C8.32426 14.5393 8.57651 14.5393 8.82876 14.4576C8.82876 13.2324 8.57651 13.2324 9.58552 14.0492C9.6696 14.2943 9.6696 14.5393 9.6696 14.8661C10.0059 14.9477 10.2582 15.0294 10.5104 15.1111C10.5945 15.3561 10.5945 15.6829 10.5945 15.9279C11.015 16.2546 11.4354 16.4997 11.8558 16.7447C12.7807 16.9081 13.7897 16.9081 14.5465 17.4799C15.1351 17.8066 15.7237 18.0516 16.3963 18.2967C16.3963 18.5417 16.4804 18.7868 16.5645 19.0318C16.9008 19.1135 17.3213 19.1135 17.6576 19.1135C18.078 19.1952 18.4984 19.1952 18.9189 19.1952C18.9189 19.4402 18.9189 19.6853 18.9189 19.9303C18.7507 21.3189 18.6666 21.0739 17.6576 21.9724C17.3213 22.2174 16.9849 22.4625 16.6486 22.7892C15.8077 23.9327 16.06 23.7694 14.7146 24.2594C14.6306 24.6679 14.5465 25.1579 14.4624 25.5664Z" fill="black" fill-opacity="0.7"></path></svg></span><span class="TabNavigationItem-navText">Community Events</span><span class="MuiTouchRipple-root"></span></a></span><span><div><span class="LWTooltip-root"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-gutters MuiListItem-button MuiMenuItem-root TabNavigationEventsList-subItemOverride" role="menuitem" href="https://www.lesswrong.com/events/uhrvYft2RYnhYbFmz/effective-altruism-virtual-programs-oct-nov-2021"><div class="TabNavigationSubItem-root TabNavigationEventsList-event"><span class="TabNavigationEventsList-title">Effective Altruism Virtual Programs Oct-Nov 2021
</span></div><span class="MuiTouchRipple-root"></span></a></span><span class="LWTooltip-root"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-gutters MuiListItem-button MuiMenuItem-root TabNavigationEventsList-subItemOverride" role="menuitem" href="https://www.lesswrong.com/events/87D8yZAS53rNKoRXW/effective-altruism-virtual-programs-nov-dec-2021"><div class="TabNavigationSubItem-root TabNavigationEventsList-event"><span class="TabNavigationEventsList-title">Effective Altruism Virtual Programs Nov-Dec 2021</span></div><span class="MuiTouchRipple-root"></span></a></span><span class="LWTooltip-root"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-gutters MuiListItem-button MuiMenuItem-root TabNavigationEventsList-subItemOverride" role="menuitem" href="https://www.lesswrong.com/events/rjQLfbMYYu4mSL9Co/effective-altruism-virtual-programs-dec-jan-2022"><div class="TabNavigationSubItem-root TabNavigationEventsList-event"><span class="TabNavigationEventsList-title">Effective Altruism Virtual Programs Dec-Jan 2022</span></div><span class="MuiTouchRipple-root"></span></a></span></div><div><span class="LWTooltip-root"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-gutters MuiListItem-button MuiMenuItem-root TabNavigationEventsList-subItemOverride" role="menuitem" href="https://www.lesswrong.com/events/SKkR7Hp6JJPnKH8xJ/monthly-mailer-for-november"><div class="TabNavigationSubItem-root TabNavigationEventsList-event"><span class="TabNavigationEventsList-title">Monthly Mailer for November</span></div><span class="MuiTouchRipple-root"></span></a></span><span class="LWTooltip-root"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-gutters MuiListItem-button MuiMenuItem-root TabNavigationEventsList-subItemOverride" role="menuitem" href="https://www.lesswrong.com/events/dCtiP8MstaYXro6A9/acx-montreal-meetup-dec-4-2021"><div class="TabNavigationSubItem-root TabNavigationEventsList-event"><span class="TabNavigationEventsList-title">ACX Montreal Meetup Dec 4 2021</span></div><span class="MuiTouchRipple-root"></span></a></span><span class="LWTooltip-root"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-gutters MuiListItem-button MuiMenuItem-root TabNavigationEventsList-subItemOverride" role="menuitem" href="https://www.lesswrong.com/events/zgAaFcyrHn3PbxGh7/south-bay-acx-lw-meetup"><div class="TabNavigationSubItem-root TabNavigationEventsList-event"><span class="TabNavigationEventsList-title">South Bay ACX/LW Meetup</span></div><span class="MuiTouchRipple-root"></span></a></span></div></span><span class="LWTooltip-root"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-navButton" role="menuitem" href="https://www.lesswrong.com/allPosts"><span class="TabNavigationItem-icon"><svg xmlns="http://www.w3.org/2000/svg" version="1.1" x="0px" y="0px" viewBox="0 0 100 125"><g transform="translate(0,-952.36218)"><path style="text-indent:0;text-transform:none;direction:ltr;baseline-shift:baseline;color:#000000" d="m 12.80945,964.36661 a 1.9989971,2.0020794 0 1 0 0.187201,3.99977 l 17.97124,0 a 1.9970041,2.0000833 0 1 0 0,-3.99977 l -17.97124,0 a 1.9970041,2.0000833 0 0 0 -0.187201,0 z m 25.958459,0 a 1.9989971,2.0020794 0 1 0 0.1872,3.99977 l 47.923308,0 a 1.9970041,2.0000833 0 1 0 0,-3.99977 l -47.923308,0 a 1.9970041,2.0000833 0 0 0 -0.1872,0 z m -25.958459,23.9986 a 1.9989971,2.0020794 0 1 0 0.187201,3.99977 l 57.90733,0 a 1.9970041,2.0000833 0 1 0 0,-3.99977 l -57.90733,0 a 1.9970041,2.0000833 0 0 0 -0.187201,0 z m 0,23.99859 a 1.9989971,2.0020794 0 1 0 0.187201,3.9998 l 57.90733,0 a 1.9970041,2.0000833 0 1 0 0,-3.9998 l -57.90733,0 a 1.9970041,2.0000833 0 0 0 -0.187201,0 z m 0,23.9986 a 1.9989971,2.0020794 0 1 0 0.187201,3.9998 l 57.90733,0 a 1.9970041,2.0000833 0 1 0 0,-3.9998 l -57.90733,0 a 1.9970041,2.0000833 0 0 0 -0.187201,0 z" stroke="none" visibility="visible" display="inline" overflow="visible"></path></g></svg></span><span class="TabNavigationItem-navText">All Posts</span><span class="MuiTouchRipple-root"></span></a></span><div class="TabNavigationMenu-divider"></div><div><a><div class="TabNavigationSubItem-root">Subscribe (RSS<!-- -->/Email<!-- -->)</div></a></div><span class="LWTooltip-root"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-subItemOverride" role="menuitem" href="https://www.lesswrong.com/questions"><div class="TabNavigationSubItem-root">Open Questions</div><span class="MuiTouchRipple-root"></span></a></span><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-subItemOverride" role="menuitem" href="https://www.lesswrong.com/contact"><div class="TabNavigationSubItem-root">Contact Us</div><span class="MuiTouchRipple-root"></span></a><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-subItemOverride" role="menuitem" href="https://www.lesswrong.com/about"><div class="TabNavigationSubItem-root">About</div><span class="MuiTouchRipple-root"></span></a><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-subItemOverride" role="menuitem" href="https://www.lesswrong.com/faq"><div class="TabNavigationSubItem-root">FAQ</div><span class="MuiTouchRipple-root"></span></a><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-subItemOverride" role="menuitem" href="https://www.lesswrong.com/donate"><div class="TabNavigationSubItem-root">Donate</div><span class="MuiTouchRipple-root"></span></a><div class="MuiPaper-root MuiPaper-elevation1 MuiPaper-rounded MuiCard-root FeaturedResourceBanner-card"><button tabindex="0" class="MuiButtonBase-root MuiButton-root MuiButton-text MuiButton-flat FeaturedResourceBanner-closeButton" type="button" title="Hide this for the next month"><span class="MuiButton-label"><svg class="MuiSvgIcon-root FeaturedResourceBanner-closeIcon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span><span class="MuiTouchRipple-root"></span></button><h2 class="Typography-root Typography-title FeaturedResourceBanner-title">We're hiring!!</h2><hr class="MuiDivider-root FeaturedResourceBanner-divider"><aside class="Typography-root Typography-body2 FeaturedResourceBanner-body">LessWrong is innovating technology for intellectual progress so that we can figure how to make the upcoming billions of years turn out good. We need help. Berkeley-based, salaries start at 150k.</aside><a href="https://www.lightconeinfrastructure.com/lesswrong-software.html" target="_blank" rel="noopener noreferrer"><button tabindex="0" class="MuiButtonBase-root MuiButton-root MuiButton-text MuiButton-textPrimary MuiButton-flat MuiButton-flatPrimary FeaturedResourceBanner-ctaButton" type="button"><span class="MuiButton-label">Apply Now</span><span class="MuiTouchRipple-root"></span></button></a></div></div></div><div class="NavigationStandalone-footerBar"><div class="TabNavigationMenuFooter-root"><a class="TabNavigationFooterItem-navButton" title="Latest posts, comments and curated content." href="https://www.lesswrong.com/"><span class="TabNavigationFooterItem-icon TabNavigationFooterItem-homeIcon"><svg version="1.1" x="0px" y="0px" viewBox="0 0 100 100"><g><path d="M29.1,29.2l6.4,11.6l4.3-0.8l0.8-4.3L29.1,29.2z M40.7,64.5l-0.8-4.3l-4.3-0.8L29.2,71L40.7,64.5z M70.9,70.9l-6.4-11.6l-4.3,0.8l-0.8,4.3L70.9,70.9z M64.4,40.8l6.4-11.6l-11.6,6.4l0.8,4.3L64.4,40.8z M67.4,58.8l10.8,19.4L58.8,67.4L50,98.8l-8.8-31.4L21.9,78.2l10.8-19.4L1.2,50.1l31.4-8.8L21.9,21.9l19.4,10.8L50,1.3l8.8,31.4l19.4-10.8L67.4,41.3L98.8,50L67.4,58.8zM57.7,57.8L83.5,50L50,50.1l7.7-7.7L50,16.6v33.5l-7.7-7.7l-25.8,7.7H50l-7.7,7.7L50,83.5V50.1L57.7,57.8z"></path></g></svg></span><span class="TabNavigationFooterItem-navText">Home</span></a><a class="TabNavigationFooterItem-navButton" href="https://www.lesswrong.com/tags/all"><span class="TabNavigationFooterItem-icon"><svg version="1.1" x="0px" y="0px" viewBox="10 10 90 90"><path d="M62.648,14.41c-7.396-0.624-14.651,2.03-19.906,7.285c-3.807,3.807-6.268,8.75-7.065,14.054  c-5.283,0.785-10.225,3.236-14.085,7.096c-4.19,4.19-6.772,9.755-7.272,15.667c-0.563,6.697,1.512,13.212,5.848,18.346  c4.335,5.136,10.413,8.273,17.106,8.834c7.398,0.628,14.655-2.029,19.91-7.284c3.805-3.805,6.265-8.749,7.062-14.053  c5.283-0.784,10.227-3.235,14.086-7.096c4.189-4.189,6.773-9.754,7.273-15.67C86.77,27.771,76.473,15.578,62.648,14.41z   M55.561,76.783c-4.597,4.596-11.109,7.21-18.092,6.621c-12.582-1.06-21.918-12.119-20.858-24.7  c0.472-5.594,2.923-10.55,6.606-14.232c3.273-3.273,7.529-5.515,12.226-6.336c-0.347,6.424,1.708,12.638,5.875,17.574  c4.333,5.134,10.411,8.272,17.105,8.835c1.166,0.1,2.327,0.106,3.479,0.045C61.069,69.348,58.789,73.555,55.561,76.783z   M62.178,62.248c-1.171,0.082-2.354,0.109-3.561,0.008c-12.482-1.05-21.755-11.945-20.866-24.399  c1.169-0.083,2.353-0.11,3.558-0.008C53.788,38.903,63.064,49.792,62.178,62.248z M83.315,41.397  c-0.474,5.596-2.924,10.554-6.606,14.237c-3.275,3.274-7.531,5.515-12.228,6.336C65.207,48.47,55.063,36.705,41.5,35.559  c-1.164-0.098-2.324-0.106-3.475-0.044c0.832-4.758,3.113-8.964,6.341-12.193c4.596-4.596,11.109-7.211,18.09-6.621  C75.037,17.763,84.375,28.817,83.315,41.397z"></path><path d="M49.384,64.735c-1.677-0.739-3.272-1.645-4.772-2.708c-0.927-0.657-1.816-1.369-2.662-2.144  c-0.861-0.788-1.692-1.613-2.459-2.517c-0.019-0.022-0.042-0.043-0.061-0.065c-0.542-0.641-1.042-1.309-1.52-1.99  c-0.549-0.786-1.045-1.602-1.508-2.434c-0.364-0.656-0.699-1.324-1.008-2.006c-0.354-0.782-0.671-1.578-0.95-2.39  c-0.223-0.648-0.419-1.305-0.593-1.97c-0.203-0.773-0.373-1.557-0.507-2.349c-0.11-0.644-0.194-1.292-0.257-1.946  c-0.031-0.311-0.077-0.62-0.097-0.933c-0.668,0.218-1.318,0.476-1.956,0.76c-1.053,0.47-2.062,1.028-3.019,1.67  c-0.922,0.618-1.794,1.315-2.611,2.085c-0.147,0.139-0.298,0.273-0.442,0.417c-0.436,0.436-0.848,0.891-1.24,1.361  c-0.574,0.689-1.085,1.423-1.562,2.178c-0.375,0.594-0.72,1.204-1.031,1.833c-0.359,0.724-0.683,1.464-0.953,2.227  c-0.218,0.613-0.401,1.24-0.56,1.875c-0.186,0.746-0.323,1.506-0.424,2.273c-0.041,0.315-0.095,0.628-0.122,0.946  c-0.027,0.321-0.022,0.641-0.034,0.961c-0.03,0.775-0.018,1.545,0.04,2.31c0.049,0.652,0.128,1.3,0.239,1.94  c0.138,0.796,0.312,1.581,0.544,2.353c0.201,0.672,0.433,1.335,0.704,1.984c0.345,0.827,0.752,1.628,1.207,2.408  c0.411,0.703,0.871,1.38,1.37,2.038c0.222,0.293,0.431,0.594,0.67,0.877c0.483,0.572,0.999,1.106,1.534,1.617  c0.834,0.796,1.73,1.51,2.675,2.146c1.964,1.324,4.146,2.282,6.464,2.853c1.042,0.257,2.103,0.454,3.192,0.546  c1.064,0.09,2.12,0.066,3.168-0.009c2.392-0.17,4.716-0.755,6.883-1.729c1.045-0.47,2.054-1.022,3.013-1.668  c0.919-0.616,1.788-1.315,2.608-2.085c0.151-0.144,0.316-0.269,0.464-0.416c0.435-0.435,0.826-0.899,1.216-1.366  c0.581-0.692,1.121-1.412,1.6-2.169c0.375-0.593,0.709-1.209,1.02-1.836c0.358-0.723,0.675-1.464,0.943-2.228  c0.048-0.134,0.111-0.26,0.156-0.394c-0.179-0.012-0.356-0.025-0.532-0.04C55.116,66.745,52.149,65.953,49.384,64.735z"></path><path d="M43.815,51.052L54.95,47.54c-0.607-0.724-1.259-1.412-1.96-2.046l-10.529,3.321C42.864,49.591,43.318,50.336,43.815,51.052z  "></path><path d="M47.913,42.134l-7.13,2.249c0.208,0.827,0.469,1.632,0.776,2.419l9.346-2.948C49.961,43.201,48.963,42.623,47.913,42.134z"></path><path d="M41.102,40.309c-0.299-0.025-0.605-0.042-0.924-0.05c0.025,0.662,0.086,1.316,0.175,1.963l4.163-1.313  C43.412,40.619,42.274,40.409,41.102,40.309z"></path><path d="M58.824,59.795c0.301,0.025,0.607,0.042,0.926,0.051c-0.02-0.525-0.073-1.043-0.133-1.559l-3.442,1.086  C57.04,59.562,57.919,59.719,58.824,59.795z"></path><path d="M52.566,58.213l6.684-2.108c-0.191-0.831-0.45-1.637-0.742-2.43l-9.067,2.86C50.426,57.181,51.47,57.742,52.566,58.213z"></path><path d="M47.283,54.918l10.356-3.267c-0.386-0.777-0.806-1.537-1.283-2.259l-11.098,3.501C45.888,53.612,46.56,54.294,47.283,54.918  z"></path></svg></span><span class="TabNavigationFooterItem-navText">Concepts</span></a><a class="TabNavigationFooterItem-navButton TabNavigationFooterItem-selected" href="https://www.lesswrong.com/library" title="Curated collections of LessWrong&#39;s best writing."><span class="TabNavigationFooterItem-icon"><img width="28" height="28" src="data:image/png;base64,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"></span><span class="TabNavigationFooterItem-navText">Library</span></a><a class="TabNavigationFooterItem-navButton" href="https://www.lesswrong.com/community" title="Find a meetup near you."><span class="TabNavigationFooterItem-icon"><svg width="28" height="34" viewBox="0 0 28 34" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M14.042 0.653442C21.3573 0.653442 27.3273 6.45284 27.3273 13.6408C27.3273 20.7471 21.3573 26.5465 14.042 26.5465C6.64258 26.5465 0.672607 20.7471 0.672607 13.6408C0.672607 6.45284 6.64258 0.653442 14.042 0.653442ZM11.4354 13.2324C11.4354 13.2324 10.9309 13.1507 10.8468 13.1507C10.0059 13.3141 10.0059 13.1507 10.7627 13.6408C11.2672 13.9676 11.099 13.9676 11.6035 13.8859C11.7717 13.9676 11.9399 13.9676 12.108 14.0492C12.108 14.1309 12.108 14.2943 12.108 14.376C12.108 14.376 12.5285 14.621 12.6125 14.621H13.2852C13.3693 14.621 14.042 14.2126 12.8648 13.8859C12.6966 13.8859 12.4444 13.8859 12.1921 13.9676C12.108 13.8042 12.024 13.6408 11.8558 13.4775C11.8558 13.4775 11.3513 13.2324 11.4354 13.2324ZM24.3843 7.18798C25.5615 9.06666 26.3183 11.2721 26.3183 13.6408C26.3183 14.2943 26.2342 15.0294 26.1501 15.6829C25.5615 15.1928 24.9729 14.7844 24.8888 14.7027C24.6366 14.4576 24.6366 14.8661 24.4684 15.3561C24.3843 15.9279 23.7116 15.4378 23.2071 15.4378C22.7026 15.4378 22.3663 14.7844 22.3663 14.7844C21.4414 14.0492 21.6936 13.6408 21.6936 12.4973C21.6936 12.1706 21.8618 11.7622 22.114 11.5988C22.7026 10.9453 22.1981 10.5369 22.8708 10.0468C23.1231 9.88347 24.048 9.63843 24.048 9.63843C24.5525 8.98497 24.8047 8.82161 23.5435 9.06666C23.4594 9.14834 22.9549 9.06666 22.7026 8.90329C22.3663 8.65825 23.1231 8.49488 23.1231 8.49488C23.4594 8.08648 23.7957 7.75975 24.1321 7.43302C24.2162 7.35134 24.3002 7.26966 24.3843 7.18798ZM14.042 1.7153C15.2192 1.7153 16.3122 1.87867 17.4053 2.12371C17.6576 2.45044 18.078 2.94053 18.1621 3.02221C18.2462 3.10389 18.4984 3.75735 18.4984 3.75735C17.9939 4.49248 17.8258 4.90089 16.7327 4.4108C16.3963 4.32912 15.8077 3.5123 15.8077 3.5123C15.8077 3.5123 14.8828 2.53212 14.7146 2.45044C14.3783 2.20539 13.8738 2.36876 13.6216 2.77717C13.7897 3.02221 13.8738 3.18557 14.042 3.43062C14.7987 3.43062 14.7987 3.26726 15.051 3.83903C14.7987 3.92071 14.5465 4.00239 14.2101 4.08407C13.4534 4.57416 13.7056 4.57416 12.8648 4.00239C12.8648 4.00239 12.3603 3.43062 12.2762 3.34894C12.1921 3.26726 11.8558 2.53212 11.6876 2.28708C11.6876 2.20539 11.6035 2.04203 11.6876 1.87867C12.4444 1.79699 13.2011 1.7153 14.042 1.7153ZM14.4624 25.5664C13.6216 25.5664 12.7807 25.4847 11.8558 25.403C11.9399 24.8312 11.9399 24.3411 11.9399 23.851C11.9399 22.5441 12.2762 22.2991 11.1831 21.564C10.9309 21.1555 10.5945 20.6655 10.2582 20.257C9.50144 19.5219 9.75369 19.6036 10.1741 18.6234C10.2582 18.215 10.3423 17.8066 10.4264 17.4799C10.2582 17.0715 10.1741 16.6631 10.0059 16.2546C9.6696 15.9279 9.33327 15.5195 8.99693 15.1928C7.14708 14.7027 7.23117 14.9477 5.88582 13.5591C5.63357 13.1507 5.38132 12.7423 5.04498 12.3339C4.12005 11.2721 4.28822 11.4354 3.95189 10.1285C3.8678 9.55675 3.78372 8.98497 3.69963 8.49488C3.61555 8.16816 3.53147 7.84143 3.44738 7.59639C5.12906 4.81921 7.90384 2.77717 11.1831 2.04203C11.099 2.45044 11.015 2.85885 10.9309 3.34894C8.91285 4.90089 7.90384 5.3093 10.3423 6.2078C10.9309 7.1063 10.7627 7.5147 11.5195 6.94293C11.5195 6.45284 11.4354 5.96275 11.3513 5.47266C12.8648 4.49248 12.4444 4.65584 14.2101 5.55434C14.4624 5.79939 14.7146 6.04443 14.9669 6.28948C16.1441 6.77957 16.2282 6.53452 15.2192 7.26966C14.9669 7.18798 14.6306 7.18798 14.2942 7.1063C14.1261 7.26966 13.9579 7.43302 13.7897 7.59639C14.2101 8.49488 14.4624 8.4132 13.5375 8.65825C13.2852 8.82161 13.033 9.06666 12.7807 9.23002C12.4444 9.23002 12.108 9.23002 11.7717 9.23002C11.7717 9.23002 11.7717 10.2102 11.7717 10.3736C11.7717 10.6186 11.015 11.2721 11.015 11.2721C11.015 11.2721 10.5945 11.8438 10.8468 12.1706C11.015 12.4973 10.5945 12.7423 10.5945 12.7423C10.3423 12.4973 10.1741 12.1706 9.92186 11.9255C9.58552 11.9255 9.1651 12.0072 8.74468 12.0889C8.49243 12.2522 8.24018 12.3339 7.98792 12.4973C7.90384 12.7423 7.81975 13.0691 7.81975 13.3141C7.90384 13.7225 7.98792 14.1309 8.15609 14.5393C8.32426 14.5393 8.57651 14.5393 8.82876 14.4576C8.82876 13.2324 8.57651 13.2324 9.58552 14.0492C9.6696 14.2943 9.6696 14.5393 9.6696 14.8661C10.0059 14.9477 10.2582 15.0294 10.5104 15.1111C10.5945 15.3561 10.5945 15.6829 10.5945 15.9279C11.015 16.2546 11.4354 16.4997 11.8558 16.7447C12.7807 16.9081 13.7897 16.9081 14.5465 17.4799C15.1351 17.8066 15.7237 18.0516 16.3963 18.2967C16.3963 18.5417 16.4804 18.7868 16.5645 19.0318C16.9008 19.1135 17.3213 19.1135 17.6576 19.1135C18.078 19.1952 18.4984 19.1952 18.9189 19.1952C18.9189 19.4402 18.9189 19.6853 18.9189 19.9303C18.7507 21.3189 18.6666 21.0739 17.6576 21.9724C17.3213 22.2174 16.9849 22.4625 16.6486 22.7892C15.8077 23.9327 16.06 23.7694 14.7146 24.2594C14.6306 24.6679 14.5465 25.1579 14.4624 25.5664Z" fill="black" fill-opacity="0.7"></path></svg></span><span class="TabNavigationFooterItem-navText">Community</span></a><a class="TabNavigationFooterItem-navButton" href="https://www.lesswrong.com/allPosts" title="See all posts, filtered and sorted however you like."><span class="TabNavigationFooterItem-icon"><svg xmlns="http://www.w3.org/2000/svg" version="1.1" x="0px" y="0px" viewBox="0 0 100 125"><g transform="translate(0,-952.36218)"><path style="text-indent:0;text-transform:none;direction:ltr;baseline-shift:baseline;color:#000000" d="m 12.80945,964.36661 a 1.9989971,2.0020794 0 1 0 0.187201,3.99977 l 17.97124,0 a 1.9970041,2.0000833 0 1 0 0,-3.99977 l -17.97124,0 a 1.9970041,2.0000833 0 0 0 -0.187201,0 z m 25.958459,0 a 1.9989971,2.0020794 0 1 0 0.1872,3.99977 l 47.923308,0 a 1.9970041,2.0000833 0 1 0 0,-3.99977 l -47.923308,0 a 1.9970041,2.0000833 0 0 0 -0.1872,0 z m -25.958459,23.9986 a 1.9989971,2.0020794 0 1 0 0.187201,3.99977 l 57.90733,0 a 1.9970041,2.0000833 0 1 0 0,-3.99977 l -57.90733,0 a 1.9970041,2.0000833 0 0 0 -0.187201,0 z m 0,23.99859 a 1.9989971,2.0020794 0 1 0 0.187201,3.9998 l 57.90733,0 a 1.9970041,2.0000833 0 1 0 0,-3.9998 l -57.90733,0 a 1.9970041,2.0000833 0 0 0 -0.187201,0 z m 0,23.9986 a 1.9989971,2.0020794 0 1 0 0.187201,3.9998 l 57.90733,0 a 1.9970041,2.0000833 0 1 0 0,-3.9998 l -57.90733,0 a 1.9970041,2.0000833 0 0 0 -0.187201,0 z" stroke="none" visibility="visible" display="inline" overflow="visible"></path></g></svg></span><span class="TabNavigationFooterItem-navText">All Posts</span></a></div></div></div></div><div class="Layout-searchResultsArea"></div><div class="Layout-main"><div class="flash-messages"></div><div class="SingleColumnSection-root"><div class="SectionTitle-root"><h1 class="Typography-root Typography-display1 SectionTitle-title">Core Reading</h1><div class="SectionTitle-children"></div></div><div class="CollectionsCardContainer-root"><div class="CoreReading-razLargeVersion"><div class="BigCollectionsCard-root LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality"></a></div><div class="BigCollectionsCard-card"><div class="BigCollectionsCard-media"><img width="326" height="280" src="./The Library - LessWrong_files/dVXiZtw_xrmvpm.png"></div><div class="BigCollectionsCard-content" style="border-top-color: rgb(177, 212, 180);"><h2 class="Typography-root Typography-title BigCollectionsCard-title"><a href="https://www.lesswrong.com/rationality">Rationality: A-Z</a></h2><h3 class="Typography-root Typography-subheading BigCollectionsCard-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></h3><aside class="Typography-root Typography-body2 BigCollectionsCard-text">A set of essays by Eliezer Yudkowsky that serve as a long-form introduction to formative ideas behind Less Wrong, the Machine Intelligence Research Institute, the Center for Applied Rationality, and substantial parts of the effective altruism community.</aside></div></div></div></div><div class="CoreReading-razSmallVersion"><div class="CollectionsCard-root LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality"></a></div><div class="CollectionsCard-card"><div class="CollectionsCard-content" style="border-top-color: rgb(177, 212, 180);"><div class="CollectionsCard-thumbnailImage"><img width="50" height="41" src="./The Library - LessWrong_files/dVXiZtw_xrmvpm(1).png"></div><h2 class="Typography-root Typography-title CollectionsCard-title"><a href="https://www.lesswrong.com/rationality">Rationality: A-Z</a></h2><h3 class="Typography-root Typography-subheading CollectionsCard-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></h3><aside class="Typography-root Typography-body2 CollectionsCard-text">A set of essays by Eliezer Yudkowsky that serve as a long-form introduction to formative ideas behind Less Wrong, the Machine Intelligence Research Institute, the Center for Applied Rationality, and substantial parts of the effective altruism community.</aside></div><div class="CollectionsCard-media"><img width="307" height="86" src="./The Library - LessWrong_files/dVXiZtw_xrmvpm(2).png"></div></div></div></div><div class="CollectionsCard-root LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/codex"></a></div><div class="CollectionsCard-card"><div class="CollectionsCard-content" style="border-top-color: rgb(136, 172, 184);"><div class="CollectionsCard-thumbnailImage"><img width="50" height="41" src="./The Library - LessWrong_files/ItFKgn4_rrr58y.png"></div><h2 class="Typography-root Typography-title CollectionsCard-title"><a href="https://www.lesswrong.com/codex">The Codex</a></h2><h3 class="Typography-root Typography-subheading CollectionsCard-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/scottalexander">Scott Alexander</a></span></span></h3><aside class="Typography-root Typography-body2 CollectionsCard-text">The Codex contains essays about science, medicine, philosophy, politics, and futurism. (There’s also one post about hallucinatory cactus-people, but it’s not representative)</aside></div><div class="CollectionsCard-media"><img width="307" height="86" src="./The Library - LessWrong_files/ItFKgn4_rrr58y(1).png"></div></div></div><div class="CollectionsCard-root LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/hpmor"></a></div><div class="CollectionsCard-card"><div class="CollectionsCard-content" style="border-top-color: rgb(117, 122, 167);"><div class="CollectionsCard-thumbnailImage"><img width="50" height="41" src="./The Library - LessWrong_files/uu4fJ5R_zeefim.png"></div><h2 class="Typography-root Typography-title CollectionsCard-title CollectionsCard-mergeTitle"><a href="https://www.lesswrong.com/hpmor">Harry Potter and the Methods of Rationality</a></h2><h3 class="Typography-root Typography-subheading CollectionsCard-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></h3><aside class="Typography-root Typography-body2 CollectionsCard-text">What if Harry Potter was a scientist? What would you do if the universe had magic in it? A story that illustrates many rationality concepts.</aside></div><div class="CollectionsCard-media"><img width="307" height="86" src="./The Library - LessWrong_files/uu4fJ5R_zeefim(1).png"></div></div></div></div></div><div class="Divider-root"><div class="Divider-divider"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" x="0px" y="0px" viewBox="0 0 100 125" enable-background="new 0 0 100 100" xml:space="preserve"><g><g><polygon fill="none" points="6.256,50.245 10.108,51.512 10.727,50.274 9.255,48.746   "></polygon><polygon fill="none" points="89.273,50.274 89.892,51.512 93.744,50.245 90.745,48.746   "></polygon><path d="M11.396,49.969l-1.818-1.888c-0.105-0.109-0.269-0.138-0.405-0.07l-3.981,1.99c-0.126,0.063-0.201,0.195-0.191,0.336    c0.01,0.14,0.104,0.26,0.238,0.304l4.937,1.624c0.036,0.012,0.072,0.017,0.108,0.017c0.128,0,0.25-0.071,0.31-0.192l0.863-1.725    C11.522,50.233,11.498,50.075,11.396,49.969z M10.108,51.512l-3.852-1.267l2.999-1.499l1.472,1.528L10.108,51.512z"></path><path d="M94.808,50.001l-3.981-1.99c-0.136-0.068-0.3-0.04-0.405,0.07l-1.818,1.888c-0.102,0.106-0.126,0.264-0.06,0.396    l0.863,1.725c0.06,0.12,0.182,0.192,0.31,0.192c0.036,0,0.072-0.005,0.108-0.017l4.937-1.624c0.133-0.044,0.227-0.164,0.238-0.304    C95.009,50.196,94.934,50.064,94.808,50.001z M89.892,51.512l-0.619-1.238l1.472-1.528l2.999,1.499L89.892,51.512z"></path><path d="M87.916,50.231l1.543-2.1c0.113-0.154,0.08-0.371-0.074-0.485c-0.155-0.113-0.372-0.08-0.485,0.074l-1.611,2.193h-32.22    l-1.515-1.665c-0.129-0.142-0.348-0.152-0.49-0.023c-0.142,0.129-0.152,0.348-0.023,0.49l1.366,1.502    c-0.6,0.598-1.205,1.194-1.311,1.285c-0.137,0.097-0.187,0.283-0.109,0.438c0.061,0.121,0.183,0.191,0.31,0.191    c0.052,0,0.105-0.012,0.155-0.037c0.06-0.03,0.116-0.06,1.545-1.488h32.334l0.965,1.644c0.065,0.11,0.181,0.171,0.299,0.171    c0.06,0,0.12-0.015,0.175-0.048c0.165-0.097,0.22-0.31,0.123-0.475L87.916,50.231z"></path><path d="M48.835,48.225c-0.141-0.129-0.361-0.118-0.49,0.023l-1.589,1.746c-0.125,0.137-0.12,0.348,0.011,0.479    c1.564,1.564,1.617,1.59,1.679,1.621c0.05,0.025,0.103,0.037,0.155,0.037c0.127,0,0.25-0.07,0.31-0.191    c0.078-0.155,0.028-0.34-0.109-0.438c-0.106-0.091-0.711-0.688-1.311-1.285l1.366-1.502    C48.987,48.574,48.977,48.354,48.835,48.225z"></path><path d="M53.244,49.995l-1.589-1.746c-0.129-0.142-0.348-0.152-0.49-0.023c-0.142,0.129-0.152,0.348-0.023,0.49l1.366,1.502    c-0.6,0.598-1.205,1.194-1.311,1.285c-0.137,0.098-0.187,0.283-0.109,0.438c0.061,0.121,0.183,0.191,0.31,0.191    c0.052,0,0.105-0.012,0.155-0.037c0.062-0.031,0.115-0.058,1.679-1.621C53.363,50.343,53.368,50.132,53.244,49.995z"></path><path d="M45.593,50.217l1.366-1.502c0.129-0.142,0.119-0.361-0.023-0.49c-0.142-0.129-0.361-0.118-0.49,0.023l-1.515,1.665h-32.22    L11.1,47.72c-0.113-0.154-0.33-0.188-0.485-0.074c-0.154,0.113-0.188,0.331-0.074,0.485l1.543,2.1l-0.98,1.668    c-0.097,0.165-0.042,0.378,0.124,0.475c0.055,0.032,0.116,0.048,0.175,0.048c0.119,0,0.235-0.061,0.299-0.171l0.965-1.644h32.334    c1.429,1.427,1.485,1.458,1.545,1.488c0.05,0.025,0.103,0.037,0.155,0.037c0.127,0,0.25-0.07,0.31-0.191    c0.078-0.155,0.028-0.341-0.109-0.438C46.798,51.411,46.192,50.815,45.593,50.217z"></path></g></g></svg></div><div class="Divider-compass"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" x="0px" y="0px" viewBox="0 0 100 125" enable-background="new 0 0 100 100" xml:space="preserve"><path d="M69.948,30.052l-13.739,7.632L50,4.574l-6.208,33.111l-13.74-7.633l7.633,13.739L4.574,50l33.111,6.208l-7.632,13.739  l13.739-7.633L50,95.426l6.208-33.112l13.74,7.634l-7.634-13.74L95.426,50l-33.111-6.208L69.948,30.052z M64.8,35.2l-4.558,8.203  l-3.07-0.576l-0.576-3.07L64.8,35.2z M35.2,35.2l8.203,4.557l-0.576,3.07l-3.07,0.576L35.2,35.2z M35.2,64.8l4.557-8.203l3.07,0.576  l0.576,3.07L35.2,64.8z M64.8,64.8l-8.203-4.557l0.576-3.07l3.07-0.576L64.8,64.8z M55.459,55.459L50,50v34.574l-5.459-29.115L50,50  H15.426l29.115-5.459L50,50V15.426l5.459,29.115L50,50h34.574L55.459,55.459z"></path></svg></div><div class="Divider-divider"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" x="0px" y="0px" viewBox="0 0 100 125" enable-background="new 0 0 100 100" xml:space="preserve"><g><g><polygon fill="none" points="6.256,50.245 10.108,51.512 10.727,50.274 9.255,48.746   "></polygon><polygon fill="none" points="89.273,50.274 89.892,51.512 93.744,50.245 90.745,48.746   "></polygon><path d="M11.396,49.969l-1.818-1.888c-0.105-0.109-0.269-0.138-0.405-0.07l-3.981,1.99c-0.126,0.063-0.201,0.195-0.191,0.336    c0.01,0.14,0.104,0.26,0.238,0.304l4.937,1.624c0.036,0.012,0.072,0.017,0.108,0.017c0.128,0,0.25-0.071,0.31-0.192l0.863-1.725    C11.522,50.233,11.498,50.075,11.396,49.969z M10.108,51.512l-3.852-1.267l2.999-1.499l1.472,1.528L10.108,51.512z"></path><path d="M94.808,50.001l-3.981-1.99c-0.136-0.068-0.3-0.04-0.405,0.07l-1.818,1.888c-0.102,0.106-0.126,0.264-0.06,0.396    l0.863,1.725c0.06,0.12,0.182,0.192,0.31,0.192c0.036,0,0.072-0.005,0.108-0.017l4.937-1.624c0.133-0.044,0.227-0.164,0.238-0.304    C95.009,50.196,94.934,50.064,94.808,50.001z M89.892,51.512l-0.619-1.238l1.472-1.528l2.999,1.499L89.892,51.512z"></path><path d="M87.916,50.231l1.543-2.1c0.113-0.154,0.08-0.371-0.074-0.485c-0.155-0.113-0.372-0.08-0.485,0.074l-1.611,2.193h-32.22    l-1.515-1.665c-0.129-0.142-0.348-0.152-0.49-0.023c-0.142,0.129-0.152,0.348-0.023,0.49l1.366,1.502    c-0.6,0.598-1.205,1.194-1.311,1.285c-0.137,0.097-0.187,0.283-0.109,0.438c0.061,0.121,0.183,0.191,0.31,0.191    c0.052,0,0.105-0.012,0.155-0.037c0.06-0.03,0.116-0.06,1.545-1.488h32.334l0.965,1.644c0.065,0.11,0.181,0.171,0.299,0.171    c0.06,0,0.12-0.015,0.175-0.048c0.165-0.097,0.22-0.31,0.123-0.475L87.916,50.231z"></path><path d="M48.835,48.225c-0.141-0.129-0.361-0.118-0.49,0.023l-1.589,1.746c-0.125,0.137-0.12,0.348,0.011,0.479    c1.564,1.564,1.617,1.59,1.679,1.621c0.05,0.025,0.103,0.037,0.155,0.037c0.127,0,0.25-0.07,0.31-0.191    c0.078-0.155,0.028-0.34-0.109-0.438c-0.106-0.091-0.711-0.688-1.311-1.285l1.366-1.502    C48.987,48.574,48.977,48.354,48.835,48.225z"></path><path d="M53.244,49.995l-1.589-1.746c-0.129-0.142-0.348-0.152-0.49-0.023c-0.142,0.129-0.152,0.348-0.023,0.49l1.366,1.502    c-0.6,0.598-1.205,1.194-1.311,1.285c-0.137,0.098-0.187,0.283-0.109,0.438c0.061,0.121,0.183,0.191,0.31,0.191    c0.052,0,0.105-0.012,0.155-0.037c0.062-0.031,0.115-0.058,1.679-1.621C53.363,50.343,53.368,50.132,53.244,49.995z"></path><path d="M45.593,50.217l1.366-1.502c0.129-0.142,0.119-0.361-0.023-0.49c-0.142-0.129-0.361-0.118-0.49,0.023l-1.515,1.665h-32.22    L11.1,47.72c-0.113-0.154-0.33-0.188-0.485-0.074c-0.154,0.113-0.188,0.331-0.074,0.485l1.543,2.1l-0.98,1.668    c-0.097,0.165-0.042,0.378,0.124,0.475c0.055,0.032,0.116,0.048,0.175,0.048c0.119,0,0.235-0.061,0.299-0.171l0.965-1.644h32.334    c1.429,1.427,1.485,1.458,1.545,1.488c0.05,0.025,0.103,0.037,0.155,0.037c0.127,0,0.25-0.07,0.31-0.191    c0.078-0.155,0.028-0.341-0.109-0.438C46.798,51.411,46.192,50.815,45.593,50.217z"></path></g></g></svg></div></div><div class="SingleColumnSection-root"><div class="SectionTitle-root"><h1 class="Typography-root Typography-display1 SectionTitle-title">Curated Sequences</h1><div class="SectionTitle-children"></div></div><div class="SequencesHome-sequencesGridWrapperWrapper"><div class="SequencesGridWrapper-gridWrapper"><div class="SequencesGrid-grid"><div class="SequencesGrid-gridContent"><div class="SequencesGridItem-root LinkCard-root" title="This, the first book of &quot;Rationality: AI to Zombies&quot; (also known as &quot;The
Sequences&quot;), begins with cognitive bias. The rest of the book won’t stick to
just this topic; bad habits and bad ideas matter, even when they arise from our
minds’ contents as opposed to our minds’ structure.

It is cognitive bias, however, that provides the clearest and most direct
glimpse into the stuff of our psychology, into the shape of our heuristics and
the logic of our limitations. It is with bias that we will begin."><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/5g5TkQTe9rmPS5vvM"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/wwkkaskmbcajjogyv1hu"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Predictably Wrong</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="A sequence of essays by Scott Alexander on how arguments work, how to use them,
and how to misuse them."><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/rfpef83ejiwbsi1pmroz"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Argument and Analysis</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/scottalexander">Scott Alexander</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="Harry: You can&#39;t DO that! 

Minerva McGonagall: It&#39;s only a transfiguration; an animagus transformation, to
be exact— 

Harry: You turned into a cat! A SMALL cat! You violated Conservation of Energy!
That&#39;s not just an arbitrary rule, it&#39;s implied by the form of the quantum
Hamiltonian! Rejecting it destroys unitarity and then you get FTL signaling! And
cats are COMPLICATED! A human mind can&#39;t just visualize a whole cat&#39;s anatomy
and, and all the cat biochemistry, and what about the neurology? How can you go
on thinking using a cat-sized brain? 

Minerva: Magic. 

Harry: Magic isn&#39;t enough to do that! You&#39;d have to be a god! 

Minerva: ... that&#39;s the first time I&#39;ve been called that.

—Harry&#39;s first encounter with magic"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/PtgH6ALi5CoJnPmGS"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/i9dkgkhw14vwar63i4xn"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The Methods of Rationality</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="This is a sequence by Scott Garrabrant and Abram Demski on one current way of
thinking about alignment: Embedded Agency."><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/Rm6oQRJJmhGCcLvxh"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/mxpqfzoorr921qviypmq"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Embedded Agency</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/abramdemski">abramdemski</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="In this report (also available here as a PDF) I have attempted to put together
the most compelling case for why the development of artificial general
intelligence (AGI) might pose an existential threat. It stems from my
dissatisfaction with existing arguments about the potential risks from AGI.
Early work tends to be less relevant in the context of modern machine learning;
more recent work is scattered and brief. I originally intended to just summarise
other people&#39;s arguments, but as this report has grown, it&#39;s become more
representative of my own views and less representative of anyone else&#39;s. So
while it covers the standard ideas, I also think that it provides a new
perspective on how to think about AGI - one which doesn&#39;t take any previ"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/mzgtmmTKKn5MuCzFJ"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/r68kkaexxymt3ckkc6pp"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">AGI safety from first principles</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/ricraz">Richard_Ngo</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/TF77XsD5PbucbJsG3"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/whqbkvzjopvlh7paq73r"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Luna Lovegood and the Chamber of Secrets</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/lsusr">lsusr</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="This is a sequence curated by Paul Christiano on one current approach to
alignment: Iterated Amplification."><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/EmDuGeRw749sD3GKd"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/prcccqtc5w7ytolilruu"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Iterated Amplification</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/paulfchristiano">paulfchristiano</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="This is a sequence investigating the feasibility of one approach to AI
alignment: value learning."><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/4dHMdK5TLN6xcqtyc"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/x0pxuhnauzakdnrqijhe"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Value Learning</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/rohinmshah">rohinmshah</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="This is a sequence version of the paper “Risks from Learned Optimization in
Advanced Machine Learning Systems” by Evan Hubinger, Chris van Merwijk, Vladimir
Mikulik, Joar Skalse, and Scott Garrabrant. Each post in the sequence
corresponds to a different section of the paper. Evan Hubinger, Chris van
Merwijk, Vladimir Mikulik, and Joar Skalse contributed equally to this sequence.

The goal of this sequence is to analyze the type of learned optimization that
occurs when a learned model (such as a neural network) is itself an optimizer—a
situation we refer to as mesa-optimization, a neologism we introduce in this
sequence. We believe that the possibility of mesa-optimization raises two
important questions for the safety and transparency of adv"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/r9tYkB2a8Fp4DN8yB"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/rzdw9faewnetbmumls9y"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Risks from Learned Optimization</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/evhub">evhub</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="&quot;The kind of classic fifties-era first-contact story that Jonathan Swift might
have written, if Jonathan Swift had had a background in game theory.&quot;
-- (Hugo nominee) Peter Watts, &quot;In Praise of Baby-Eating&quot;

Three Worlds Collide is a story I wrote to illustrate some points on
naturalistic metaethics and diverse other issues of rational conduct. It grew,
as such things do, into a small novella. On publication, it proved widely
popular and widely criticized. Be warned that the story, as it wrote itself,
ended up containing some profanity and PG-13 content.

(PDF is here. Old contents post with comments is here.)"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/qWoFR4ytMpQ5vw3FT"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/sio9b8jw1apesuispocg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Three Worlds Collide</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="A series of meditations on freedom to do the things you care about.

Some things are fundamentally Out to Get You.They seek resources at your
expense. Fees are hidden. Extra options are foisted upon you. Things are made
intentionally worse, forcing you to pay to make it less worse. Everything is
data to sell you something, rather than an opportunity to help you.When
something is out to get you, if you aren&#39;t careful, it can take all your
resources - your time, you money, your attention.This matters, more deeply than
you might realize. It&#39;s not just that you need your resources. You need enough
resources to have slack: freedom from constraints that might bind you. Slack
means margin of error. You can relax. You can explore and pursue opportu"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/HXkpm9b8o964jbQ89"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/rqnuxewffasun6tvdkng"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Slack and the Sabbath </div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/zvi">Zvi</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="This sequence of posts is a primer on game theory intended at an introductory
level. Because it is introductory, Less Wrong veterans may find some parts
boring, obvious, or simplistic - although hopefully nothing is so simplistic as
to be outright wrong.

Parts of this sequence draw heavily upon material from The Art of Strategy by
Avinash Dixit and Barry Nalebuff, and it may in part be considered a (very
favorable) review of the book accompanied by an exploration of its content. I
have tried to include enough material to be useful, but not so much material
that it becomes a plagiarism rather than a review (it&#39;s probably a bad idea to
pick a legal fight with people who write books called The Art of Strategy.)
Therefore, for the most complet"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/ZNNi2uNx9E6iwGKKG"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/vitugifyyh2upm9ucjzh"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Introduction to Game Theory</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/scottalexander">Scott Alexander</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="A sequence on models of the human mind, drawing on psychology and neuroscience
to discuss motivation, learning and behaviour."><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/G2GDw3m4MJ5ixSM92"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/djfksyoldrjt4ef5jts3"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The Blue-Minimizing Robot</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/scottalexander">Scott Alexander</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="How do babies learn language? How did Moses compute the ten Commandments? How
did Shakespeare write Hamlet?

Babble and Prune is an ancient mythological story, a psychological model, a new
religion for a post-religion age, that answers all these questions and more.

Two Gods - Babble and Prune, Artist and Critic, Generator and Discriminator -
are locked in eternal conflict over your mind. Babble creates a constant stream
of coarse material, while Prune cuts these ideas harshly without the slightest
hint of remorse. Only you, chosen hero, can restore the balance between these
two ancient deities, and in doing so maximize your creative output.

It is time to reclaim your birthright, hero: go forth and babble!"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/pC6DYFLPMTCbEwH8W"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/nhvoi5fvxxzthqhu2ctt"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Babble and Prune</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/alkjash">alkjash</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="These essays include a discussion of truth, formal logic, causality, and
metaethics, and are a good way for more ambitious readers to quickly get up to
speed."><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/SqFbMbtxGybdS2gRs"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/i2ogsvmipbdolntkew4a"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Highly Advanced Epistemology 101 for Beginners</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/yFvZa9wkv5JoqhM8F"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/yxlirutmux2fjqnnjhoc"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Rationality and Philosophy</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/lukeprog">lukeprog</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="Decisions need to be modeled with some structure in order to be scrutinized and
systematically improved; simply &quot;intuiting&quot; the answers to decision problems by
ad-hoc methods is not conducive to thorough analysis. 

For this, we formulate decision theories. This sequence, themed with an analysis
of Newcomb&#39;s problem, is a consolidated summary and context for the many
decision theory discussions found on LessWrong at the time of writing."><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/XipJ7DMjYyriAm7fr"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/qpreo6bc9vxwyf2l1dzo"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Decision Theory: Newcomb's Problem</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/annasalamon">AnnaSalamon</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="A sequence summarizing scientifically-backed advice for &quot;winning&quot; at everyday
life: in one&#39;s productivity, in one&#39;s relationships, in one&#39;s emotions, etc.
Each post concludes with footnotes and a long list of references from the
academic literature."><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/oi873FWi6pHWxswSa"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/yp01lueog8rjaybsizux"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The Science of Winning at Life</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/lukeprog">lukeprog</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="Years ago, I wrote an unfinished sequence of posts called &quot;No-Nonsense
Metaethics.&quot; My last post, Pluralistic Moral Reductionism, said I would next
explore &quot;empathic metaethics,&quot; but I never got around to writing those posts.
Recently, I wrote a high-level summary of some initial thoughts on &quot;empathic
metaethics&quot; in section 6.1.2 of a report prepared for my employer, the Open
Philanthropy Project. With my employer&#39;s permission, I&#39;ve adapted that section
for publication here, so that it can serve as the long-overdue concluding post
in my sequence on metaethics."><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/bQgRsy23biR52poMf"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/kvoeqrfluqd0jv5fvwez"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">No-Nonsense Metaethics</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/lukeprog">lukeprog</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="Inadequate Equilibria is a book about a generalized notion of efficient markets,
and how we can use this notion to guess where society will or won’t be effective
at pursuing some widely desired goal."><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/oLGCcbnvabyibnG9d"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/vbhv0s06jdmonk6garvf"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Inadequate Equilibria</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="Cartesian frames are a way to add a first-person perspective (with choices,
uncertainty, and so on) on top of a set of possible worlds. This sequence
introduces Cartesian frames and basic operations on frames."><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/2A7rrZ4ySx6R8mfoT"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/a9iwqgsxkqznfrtskanw"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Cartesian Frames</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/scott-garrabrant">Scott Garrabrant</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="Luminosity, as used here, is self-awareness. A luminous mental state is one that
you have and know that you have. It could be an emotion, a belief or alief, a
disposition, a quale, a memory - anything that might happen or be stored in your
brain. What&#39;s going on in your head?"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/ynMFrq9K5iNMfSZNg"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/ozdf0thhtehmpmbf9dys"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Living Luminously</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/alicorn">Alicorn</a></span></span></div></div></div></div></div></div></div></div><div class="Divider-root"><div class="Divider-divider"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" x="0px" y="0px" viewBox="0 0 100 125" enable-background="new 0 0 100 100" xml:space="preserve"><g><g><polygon fill="none" points="6.256,50.245 10.108,51.512 10.727,50.274 9.255,48.746   "></polygon><polygon fill="none" points="89.273,50.274 89.892,51.512 93.744,50.245 90.745,48.746   "></polygon><path d="M11.396,49.969l-1.818-1.888c-0.105-0.109-0.269-0.138-0.405-0.07l-3.981,1.99c-0.126,0.063-0.201,0.195-0.191,0.336    c0.01,0.14,0.104,0.26,0.238,0.304l4.937,1.624c0.036,0.012,0.072,0.017,0.108,0.017c0.128,0,0.25-0.071,0.31-0.192l0.863-1.725    C11.522,50.233,11.498,50.075,11.396,49.969z M10.108,51.512l-3.852-1.267l2.999-1.499l1.472,1.528L10.108,51.512z"></path><path d="M94.808,50.001l-3.981-1.99c-0.136-0.068-0.3-0.04-0.405,0.07l-1.818,1.888c-0.102,0.106-0.126,0.264-0.06,0.396    l0.863,1.725c0.06,0.12,0.182,0.192,0.31,0.192c0.036,0,0.072-0.005,0.108-0.017l4.937-1.624c0.133-0.044,0.227-0.164,0.238-0.304    C95.009,50.196,94.934,50.064,94.808,50.001z M89.892,51.512l-0.619-1.238l1.472-1.528l2.999,1.499L89.892,51.512z"></path><path d="M87.916,50.231l1.543-2.1c0.113-0.154,0.08-0.371-0.074-0.485c-0.155-0.113-0.372-0.08-0.485,0.074l-1.611,2.193h-32.22    l-1.515-1.665c-0.129-0.142-0.348-0.152-0.49-0.023c-0.142,0.129-0.152,0.348-0.023,0.49l1.366,1.502    c-0.6,0.598-1.205,1.194-1.311,1.285c-0.137,0.097-0.187,0.283-0.109,0.438c0.061,0.121,0.183,0.191,0.31,0.191    c0.052,0,0.105-0.012,0.155-0.037c0.06-0.03,0.116-0.06,1.545-1.488h32.334l0.965,1.644c0.065,0.11,0.181,0.171,0.299,0.171    c0.06,0,0.12-0.015,0.175-0.048c0.165-0.097,0.22-0.31,0.123-0.475L87.916,50.231z"></path><path d="M48.835,48.225c-0.141-0.129-0.361-0.118-0.49,0.023l-1.589,1.746c-0.125,0.137-0.12,0.348,0.011,0.479    c1.564,1.564,1.617,1.59,1.679,1.621c0.05,0.025,0.103,0.037,0.155,0.037c0.127,0,0.25-0.07,0.31-0.191    c0.078-0.155,0.028-0.34-0.109-0.438c-0.106-0.091-0.711-0.688-1.311-1.285l1.366-1.502    C48.987,48.574,48.977,48.354,48.835,48.225z"></path><path d="M53.244,49.995l-1.589-1.746c-0.129-0.142-0.348-0.152-0.49-0.023c-0.142,0.129-0.152,0.348-0.023,0.49l1.366,1.502    c-0.6,0.598-1.205,1.194-1.311,1.285c-0.137,0.098-0.187,0.283-0.109,0.438c0.061,0.121,0.183,0.191,0.31,0.191    c0.052,0,0.105-0.012,0.155-0.037c0.062-0.031,0.115-0.058,1.679-1.621C53.363,50.343,53.368,50.132,53.244,49.995z"></path><path d="M45.593,50.217l1.366-1.502c0.129-0.142,0.119-0.361-0.023-0.49c-0.142-0.129-0.361-0.118-0.49,0.023l-1.515,1.665h-32.22    L11.1,47.72c-0.113-0.154-0.33-0.188-0.485-0.074c-0.154,0.113-0.188,0.331-0.074,0.485l1.543,2.1l-0.98,1.668    c-0.097,0.165-0.042,0.378,0.124,0.475c0.055,0.032,0.116,0.048,0.175,0.048c0.119,0,0.235-0.061,0.299-0.171l0.965-1.644h32.334    c1.429,1.427,1.485,1.458,1.545,1.488c0.05,0.025,0.103,0.037,0.155,0.037c0.127,0,0.25-0.07,0.31-0.191    c0.078-0.155,0.028-0.341-0.109-0.438C46.798,51.411,46.192,50.815,45.593,50.217z"></path></g></g></svg></div><div class="Divider-compass"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" x="0px" y="0px" viewBox="0 0 100 125" enable-background="new 0 0 100 100" xml:space="preserve"><path d="M69.948,30.052l-13.739,7.632L50,4.574l-6.208,33.111l-13.74-7.633l7.633,13.739L4.574,50l33.111,6.208l-7.632,13.739  l13.739-7.633L50,95.426l6.208-33.112l13.74,7.634l-7.634-13.74L95.426,50l-33.111-6.208L69.948,30.052z M64.8,35.2l-4.558,8.203  l-3.07-0.576l-0.576-3.07L64.8,35.2z M35.2,35.2l8.203,4.557l-0.576,3.07l-3.07,0.576L35.2,35.2z M35.2,64.8l4.557-8.203l3.07,0.576  l0.576,3.07L35.2,64.8z M64.8,64.8l-8.203-4.557l0.576-3.07l3.07-0.576L64.8,64.8z M55.459,55.459L50,50v34.574l-5.459-29.115L50,50  H15.426l29.115-5.459L50,50V15.426l5.459,29.115L50,50h34.574L55.459,55.459z"></path></svg></div><div class="Divider-divider"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" x="0px" y="0px" viewBox="0 0 100 125" enable-background="new 0 0 100 100" xml:space="preserve"><g><g><polygon fill="none" points="6.256,50.245 10.108,51.512 10.727,50.274 9.255,48.746   "></polygon><polygon fill="none" points="89.273,50.274 89.892,51.512 93.744,50.245 90.745,48.746   "></polygon><path d="M11.396,49.969l-1.818-1.888c-0.105-0.109-0.269-0.138-0.405-0.07l-3.981,1.99c-0.126,0.063-0.201,0.195-0.191,0.336    c0.01,0.14,0.104,0.26,0.238,0.304l4.937,1.624c0.036,0.012,0.072,0.017,0.108,0.017c0.128,0,0.25-0.071,0.31-0.192l0.863-1.725    C11.522,50.233,11.498,50.075,11.396,49.969z M10.108,51.512l-3.852-1.267l2.999-1.499l1.472,1.528L10.108,51.512z"></path><path d="M94.808,50.001l-3.981-1.99c-0.136-0.068-0.3-0.04-0.405,0.07l-1.818,1.888c-0.102,0.106-0.126,0.264-0.06,0.396    l0.863,1.725c0.06,0.12,0.182,0.192,0.31,0.192c0.036,0,0.072-0.005,0.108-0.017l4.937-1.624c0.133-0.044,0.227-0.164,0.238-0.304    C95.009,50.196,94.934,50.064,94.808,50.001z M89.892,51.512l-0.619-1.238l1.472-1.528l2.999,1.499L89.892,51.512z"></path><path d="M87.916,50.231l1.543-2.1c0.113-0.154,0.08-0.371-0.074-0.485c-0.155-0.113-0.372-0.08-0.485,0.074l-1.611,2.193h-32.22    l-1.515-1.665c-0.129-0.142-0.348-0.152-0.49-0.023c-0.142,0.129-0.152,0.348-0.023,0.49l1.366,1.502    c-0.6,0.598-1.205,1.194-1.311,1.285c-0.137,0.097-0.187,0.283-0.109,0.438c0.061,0.121,0.183,0.191,0.31,0.191    c0.052,0,0.105-0.012,0.155-0.037c0.06-0.03,0.116-0.06,1.545-1.488h32.334l0.965,1.644c0.065,0.11,0.181,0.171,0.299,0.171    c0.06,0,0.12-0.015,0.175-0.048c0.165-0.097,0.22-0.31,0.123-0.475L87.916,50.231z"></path><path d="M48.835,48.225c-0.141-0.129-0.361-0.118-0.49,0.023l-1.589,1.746c-0.125,0.137-0.12,0.348,0.011,0.479    c1.564,1.564,1.617,1.59,1.679,1.621c0.05,0.025,0.103,0.037,0.155,0.037c0.127,0,0.25-0.07,0.31-0.191    c0.078-0.155,0.028-0.34-0.109-0.438c-0.106-0.091-0.711-0.688-1.311-1.285l1.366-1.502    C48.987,48.574,48.977,48.354,48.835,48.225z"></path><path d="M53.244,49.995l-1.589-1.746c-0.129-0.142-0.348-0.152-0.49-0.023c-0.142,0.129-0.152,0.348-0.023,0.49l1.366,1.502    c-0.6,0.598-1.205,1.194-1.311,1.285c-0.137,0.098-0.187,0.283-0.109,0.438c0.061,0.121,0.183,0.191,0.31,0.191    c0.052,0,0.105-0.012,0.155-0.037c0.062-0.031,0.115-0.058,1.679-1.621C53.363,50.343,53.368,50.132,53.244,49.995z"></path><path d="M45.593,50.217l1.366-1.502c0.129-0.142,0.119-0.361-0.023-0.49c-0.142-0.129-0.361-0.118-0.49,0.023l-1.515,1.665h-32.22    L11.1,47.72c-0.113-0.154-0.33-0.188-0.485-0.074c-0.154,0.113-0.188,0.331-0.074,0.485l1.543,2.1l-0.98,1.668    c-0.097,0.165-0.042,0.378,0.124,0.475c0.055,0.032,0.116,0.048,0.175,0.048c0.119,0,0.235-0.061,0.299-0.171l0.965-1.644h32.334    c1.429,1.427,1.485,1.458,1.545,1.488c0.05,0.025,0.103,0.037,0.155,0.037c0.127,0,0.25-0.07,0.31-0.191    c0.078-0.155,0.028-0.341-0.109-0.438C46.798,51.411,46.192,50.815,45.593,50.217z"></path></g></g></svg></div></div><div class="SingleColumnSection-root"><div class="SectionTitle-root"><h1 class="Typography-root Typography-display1 SectionTitle-title">Community Sequences</h1><div class="SectionTitle-children"><a href="https://www.lesswrong.com/sequencesnew"><span class="Typography-root Typography-body2 SectionButton-root"><svg class="MuiSvgIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M4 6H2v14c0 1.1.9 2 2 2h14v-2H4V6zm16-4H8c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h12c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zm-1 9h-4v4h-2v-4H9V9h4V5h2v4h4v2z"></path></svg>Create New Sequence</span></a></div></div><div class="SequencesHome-sequencesGridWrapperWrapper"><div class="SequencesGridWrapper-gridWrapper"><div class="SequencesGrid-grid"><div class="SequencesGrid-gridContent"><div class="SequencesGridItem-root LinkCard-root" title="This sequence is a (chronological) series of chatroom conversation logs about
artificial general intelligence (AGI). A large number of topics are covered,
beginning with conversations related to alignment difficulty.

Rob Bensinger edited and posted this sequence, and Matthew Graves helped with
much of the formatting."><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/n945eovrA3oDueqtq"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/gpk2pxurl1yymecllfoo"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Late 2021 MIRI Conversations</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/robbbb">Rob Bensinger</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/skRvz2mmvhLwhHbaN"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/ok0a9errlxdskjjt9clx"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Curiosity</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/raemon">Raemon</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/JdAfXBx4gS3DjN5s6"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/jfe2adg6svmk60w9mrno"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Coordination</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/raemon">Raemon</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/bjewXnagXTjeGPtHx"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/dtmq79bnplqvs2hwu8bz"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Agency</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/raemon">Raemon</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/Pavm47mqgjDAF7XYT"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/g93xchw441hctqffduzf"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Epistemology</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/raemon">Raemon</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/QyQcBpSur9SFyRuvB"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/xrcvu7vroxuzezgy06xu"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Alignment</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/raemon">Raemon</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="Sequence of post analyzing the epistemic strategies of specific alignment
research results."><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/LLEJJoaYpCoS5JYSY"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/j3kqlrz4cpyilodutaz0"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Epistemic Cookbook for Alignment</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/adamshimi">adamShimi</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="Modern progress in AI systems has been driven and enabled mainly by acquiring
more computational resources. AI systems rely on computation-intensive training
runs — they require massive amounts of compute.

Learning about the compute requirements for training existing AI systems and
their capabilities allows us to get a more nuanced understanding and take
appropriate action within the technical and governance domain to enable a safe
development of potential transformative AI systems.

To understand the role of compute, I decided to (a) do a literature review, (b)
update existing work with new data, (c) investigate the role of compute for
timelines, and lastly, (d) explore concepts to enhance our analysis and
forecasting efforts.

In this se"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/bJi3hd8E8qjBeHz9Z"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/urllfotmjrjlirssmxvb"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Transformative AI and Compute</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/lennart">lennart</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="There are the AI safety subprojects designed for elucidating &quot;model splintering&quot;
and &quot;learning the preferences of irrational agents&quot;."><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/xujLGRKFLKsPCTimd"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/kxuwii95ftf9rqlhh8u4"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">AI Safety Subprojects</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/stuart_armstrong">Stuart_Armstrong</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="A series of Data Science and Analysis challenges, presented as decision problems
in a fantasy setting.

Note: This sequence collects all D&amp;D.Sci scenarios I made which both can and
should be replayed. It doesn&#39;t include Return of the Gray Swan (because that was
created by someone else), Interdimensional Monster Carcass Auction (because that
was a one-time event), or Mancer Matchups (because that wasn&#39;t up to my
standards)."><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/gDiScDuMrWNpzwNSJ"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/mckwcocoomsz3kav1rhe"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">D&amp;D.Sci</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/abstractapplic">abstractapplic</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="I think we have good reason to believe that the 21st century could be the most
important century ever for humanity. I think the most likely way this would
happen would be via the development of advanced AI systems that lead to
explosive growth and scientific advancement, getting us more quickly than most
people imagine to a deeply unfamiliar future.

A bit more specifically,1 I think there is a good chance that:

 1. During the century we&#39;re in right now, we will develop technologies that
    cause us to transition to a state in which humans as we know them are no
    longer the main force in world events. This is our last chance to shape how
    that transition happens.
 2. Whatever the main force in world events is (perhaps digital people"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/yYxggfHYRrqnJXuRx"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/nsphhanrutzgofgj5xvu"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The Most Important Century</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/holdenkarnofsky">HoldenKarnofsky</a></span></span></div></div></div><div class="SequencesGridItem-root LinkCard-root" title="Much of the value I get from math is not from detailed calculations or elaborate
models, but rather from framing tools: tools which suggest useful questions to
ask, approximations to make, what to pay attention to and what to ignore.

Each of these posts is meant to train/practice one mathematical framing tool.

The structure is like a trigger-action pattern: the hard part is to notice a
pattern, a place where a particular tool can apply (the “trigger”). Once we
notice the pattern, it suggests certain questions or approximations (the
“action”). Each of these posts contains a Challenge to ingrain the abstract
trigger-pattern, and a Bonus Exercise to practice applying the actions.

The hope is that practicing these tools will help us notice u"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/Fu7Euu3F96rKhFRWH"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="./The Library - LessWrong_files/sulofl6pfuwna4z1kelm"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Framing Practicum</div><div class="SequencesGridItem-author">by <span><span class=""><a class="UsersNameDisplay-userName" href="https://www.lesswrong.com/users/johnswentworth">johnswentworth</a></span></span></div></div></div></div></div><a class="LoadMore-root" href="https://www.lesswrong.com/library#">Load More (12/108)</a></div></div></div><div class="Footer-root"></div></div></div></div></div>
<script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","currentUser":null,"featuredResources({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":10,\"view\":\"activeResources\"}}})":{"__typename":"MultiFeaturedResourceOutput","results":[{"__ref":"FeaturedResource:61844abcd8e4de355775049c"}],"totalCount":null},"user({\"input\":{\"selector\":{\"documentId\":\"nmk3nLpQE89dMRzzN\"}}})":{"__typename":"SingleUserOutput","result":{"__ref":"User:nmk3nLpQE89dMRzzN"}},"user({\"input\":{\"selector\":{\"documentId\":\"XgYW5s8njaYrtyP7q\"}}})":{"__typename":"SingleUserOutput","result":{"__ref":"User:XgYW5s8njaYrtyP7q"}},"sequences({\"input\":{\"enableCache\":false,\"enableTotal\":true,\"terms\":{\"limit\":100,\"view\":\"curatedSequences\"}}})":{"__typename":"MultiSequenceOutput","results":[{"__ref":"Sequence:5g5TkQTe9rmPS5vvM"},{"__ref":"Sequence:XsMTxdQ6fprAQMoKi"},{"__ref":"Sequence:PtgH6ALi5CoJnPmGS"},{"__ref":"Sequence:Rm6oQRJJmhGCcLvxh"},{"__ref":"Sequence:mzgtmmTKKn5MuCzFJ"},{"__ref":"Sequence:TF77XsD5PbucbJsG3"},{"__ref":"Sequence:EmDuGeRw749sD3GKd"},{"__ref":"Sequence:4dHMdK5TLN6xcqtyc"},{"__ref":"Sequence:r9tYkB2a8Fp4DN8yB"},{"__ref":"Sequence:qWoFR4ytMpQ5vw3FT"},{"__ref":"Sequence:HXkpm9b8o964jbQ89"},{"__ref":"Sequence:ZNNi2uNx9E6iwGKKG"},{"__ref":"Sequence:G2GDw3m4MJ5ixSM92"},{"__ref":"Sequence:pC6DYFLPMTCbEwH8W"},{"__ref":"Sequence:SqFbMbtxGybdS2gRs"},{"__ref":"Sequence:yFvZa9wkv5JoqhM8F"},{"__ref":"Sequence:XipJ7DMjYyriAm7fr"},{"__ref":"Sequence:oi873FWi6pHWxswSa"},{"__ref":"Sequence:bQgRsy23biR52poMf"},{"__ref":"Sequence:oLGCcbnvabyibnG9d"},{"__ref":"Sequence:2A7rrZ4ySx6R8mfoT"},{"__ref":"Sequence:ynMFrq9K5iNMfSZNg"}],"totalCount":22},"posts({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":4,\"view\":\"onlineEvents\"}}})":{"__typename":"MultiPostOutput","results":[{"__ref":"Post:uhrvYft2RYnhYbFmz"},{"__ref":"Post:87D8yZAS53rNKoRXW"},{"__ref":"Post:rjQLfbMYYu4mSL9Co"}],"totalCount":null},"posts({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":3,\"onlineEvent\":false,\"view\":\"events\"}}})":{"__typename":"MultiPostOutput","results":[{"__ref":"Post:SKkR7Hp6JJPnKH8xJ"},{"__ref":"Post:dCtiP8MstaYXro6A9"},{"__ref":"Post:zgAaFcyrHn3PbxGh7"}],"totalCount":null},"sequences({\"input\":{\"enableCache\":false,\"enableTotal\":true,\"terms\":{\"limit\":12,\"view\":\"communitySequences\"}}})":{"__typename":"MultiSequenceOutput","results":[{"__ref":"Sequence:n945eovrA3oDueqtq"},{"__ref":"Sequence:skRvz2mmvhLwhHbaN"},{"__ref":"Sequence:JdAfXBx4gS3DjN5s6"},{"__ref":"Sequence:bjewXnagXTjeGPtHx"},{"__ref":"Sequence:Pavm47mqgjDAF7XYT"},{"__ref":"Sequence:QyQcBpSur9SFyRuvB"},{"__ref":"Sequence:LLEJJoaYpCoS5JYSY"},{"__ref":"Sequence:bJi3hd8E8qjBeHz9Z"},{"__ref":"Sequence:xujLGRKFLKsPCTimd"},{"__ref":"Sequence:gDiScDuMrWNpzwNSJ"},{"__ref":"Sequence:yYxggfHYRrqnJXuRx"},{"__ref":"Sequence:Fu7Euu3F96rKhFRWH"}],"totalCount":108}},"FeaturedResource:61844abcd8e4de355775049c":{"_id":"61844abcd8e4de355775049c","__typename":"FeaturedResource","title":"We're hiring!!","body":"LessWrong is innovating technology for intellectual progress so that we can figure how to make the upcoming billions of years turn out good. We need help. Berkeley-based, salaries start at 150k.","ctaText":"Apply Now","ctaUrl":"https://www.lightconeinfrastructure.com/lesswrong-software.html","expiresAt":"2022-11-04T21:04:17.000Z"},"User:nmk3nLpQE89dMRzzN":{"_id":"nmk3nLpQE89dMRzzN","__typename":"User","slug":"eliezer_yudkowsky","createdAt":"2009-02-23T21:58:56.739Z","username":"Eliezer_Yudkowsky","displayName":"Eliezer Yudkowsky","fullName":null,"karma":109776,"afKarma":616,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":929,"commentCount":7310,"sequenceCount":36,"afPostCount":7,"afCommentCount":33,"spamRiskScore":1,"tagRevisionCount":324},"User:XgYW5s8njaYrtyP7q":{"_id":"XgYW5s8njaYrtyP7q","__typename":"User","slug":"scottalexander","createdAt":"2009-02-28T15:53:46.032Z","username":"Yvain","displayName":"Scott Alexander","fullName":null,"karma":36790,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":210,"commentCount":1541,"sequenceCount":13,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":19},"Revision:5g5TkQTe9rmPS5vvM_":{"_id":"5g5TkQTe9rmPS5vvM_","__typename":"Revision","version":"1.9.0","updateType":"minor","editedAt":"2020-07-01T21:50:13.355Z","userId":"XtphY3uYHwruKqDyG","html":"<html><head><\/head><body><p>This, the first book of \"Rationality: AI to Zombies\" (also known as \"The Sequences\"), begins with cognitive bias. The rest of the book won’t stick to just this topic; bad habits and bad ideas matter, even when they arise from our minds’ contents as opposed to our minds’ structure.<\/p><p>It is cognitive bias, however, that provides the clearest and most direct glimpse into the stuff of our psychology, into the shape of our heuristics and the logic of our limitations. It is with bias that we will begin.<\/p><\/body><\/html>","wordCount":87,"htmlHighlight":"<html><head><\/head><body><p>This, the first book of \"Rationality: AI to Zombies\" (also known as \"The Sequences\"), begins with cognitive bias. The rest of the book won’t stick to just this topic; bad habits and bad ideas matter, even when they arise from our minds’ contents as opposed to our minds’ structure.<\/p><p>It is cognitive bias, however, that provides the clearest and most direct glimpse into the stuff of our psychology, into the shape of our heuristics and the logic of our limitations. It is with bias that we will begin.<\/p><\/body><\/html>","plaintextDescription":"This, the first book of \"Rationality: AI to Zombies\" (also known as \"The\nSequences\"), begins with cognitive bias. The rest of the book won’t stick to\njust this topic; bad habits and bad ideas matter, even when they arise from our\nminds’ contents as opposed to our minds’ structure.\n\nIt is cognitive bias, however, that provides the clearest and most direct\nglimpse into the stuff of our psychology, into the shape of our heuristics and\nthe logic of our limitations. It is with bias that we will begin."},"Sequence:5g5TkQTe9rmPS5vvM":{"_id":"5g5TkQTe9rmPS5vvM","__typename":"Sequence","createdAt":"2017-08-24T01:49:39.814Z","userId":"nmk3nLpQE89dMRzzN","user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"contents":{"__ref":"Revision:5g5TkQTe9rmPS5vvM_"},"gridImageId":"sequencesgrid/wwkkaskmbcajjogyv1hu","bannerImageId":"sequences/bkywjoighcyelqiphpom","canonicalCollectionSlug":"rationality","draft":false,"isDeleted":false,"hidden":false,"curatedOrder":504,"userProfileOrder":null,"af":null,"title":"Predictably Wrong"},"Revision:XsMTxdQ6fprAQMoKi_":{"_id":"XsMTxdQ6fprAQMoKi_","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2020-07-01T21:46:04.937Z","userId":"XtphY3uYHwruKqDyG","html":"<html><head><\/head><body><p>A sequence of essays by Scott Alexander on how arguments work, how to use them, and how to misuse them.<\/p><\/body><\/html>","wordCount":20,"htmlHighlight":"<html><head><\/head><body><p>A sequence of essays by Scott Alexander on how arguments work, how to use them, and how to misuse them.<\/p><\/body><\/html>","plaintextDescription":"A sequence of essays by Scott Alexander on how arguments work, how to use them,\nand how to misuse them."},"Sequence:XsMTxdQ6fprAQMoKi":{"_id":"XsMTxdQ6fprAQMoKi","__typename":"Sequence","createdAt":"2017-08-24T01:21:12.377Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:XsMTxdQ6fprAQMoKi_"},"gridImageId":"sequencesgrid/rfpef83ejiwbsi1pmroz","bannerImageId":"sequences/i345prxcdiiwgczlrsya","canonicalCollectionSlug":"codex","draft":false,"isDeleted":false,"hidden":false,"curatedOrder":503,"userProfileOrder":null,"af":null,"title":"Argument and Analysis"},"Revision:PtgH6ALi5CoJnPmGS_":{"_id":"PtgH6ALi5CoJnPmGS_","__typename":"Revision","version":"1.4.0","updateType":"minor","editedAt":"2020-05-16T01:21:07.290Z","userId":"XtphY3uYHwruKqDyG","html":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>Harry: You can&#x27;t DO that! <\/p><p>Minerva McGonagall: It&#x27;s only a transfiguration; an animagus transformation, to be exact— <\/p><p>Harry: You turned into a cat! A SMALL cat! You violated Conservation of Energy! That&#x27;s not just an arbitrary rule, it&#x27;s implied by the form of the quantum Hamiltonian! Rejecting it destroys unitarity and then you get FTL signaling! And cats are COMPLICATED! A human mind can&#x27;t just visualize a whole cat&#x27;s anatomy and, and all the cat biochemistry, and what about the neurology? How can you go on thinking using a cat-sized brain? <\/p><p>Minerva: Magic. <\/p><p>Harry: Magic isn&#x27;t enough to do that! You&#x27;d have to be a god! <\/p><p>Minerva: ... that&#x27;s the first time I&#x27;ve been called that.<\/p><p style=\"text-align:right;\">—Harry&#x27;s first encounter with magic<\/p><\/div><\/div><\/div><\/div>","wordCount":115,"htmlHighlight":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>Harry: You can&#x27;t DO that! <\/p><p>Minerva McGonagall: It&#x27;s only a transfiguration; an animagus transformation, to be exact— <\/p><p>Harry: You turned into a cat! A SMALL cat! You violated Conservation of Energy! That&#x27;s not just an arbitrary rule, it&#x27;s implied by the form of the quantum Hamiltonian! Rejecting it destroys unitarity and then you get FTL signaling! And cats are COMPLICATED! A human mind can&#x27;t just visualize a whole cat&#x27;s anatomy and, and all the cat biochemistry, and what about the neurology? How can you go on thinking using a cat-sized brain? <\/p><p>Minerva: Magic. <\/p><p>Harry: Magic isn&#x27;t enough to do that! You&#x27;d have to be a god! <\/p><p>Minerva: ... that&#x27;s the first time I&#x27;ve been called that.<\/p><p style=\"text-align:right;\">—Harry&#x27;s first encounter with magic<\/p><\/div><\/div><\/div><\/div>","plaintextDescription":"Harry: You can't DO that! \n\nMinerva McGonagall: It's only a transfiguration; an animagus transformation, to\nbe exact— \n\nHarry: You turned into a cat! A SMALL cat! You violated Conservation of Energy!\nThat's not just an arbitrary rule, it's implied by the form of the quantum\nHamiltonian! Rejecting it destroys unitarity and then you get FTL signaling! And\ncats are COMPLICATED! A human mind can't just visualize a whole cat's anatomy\nand, and all the cat biochemistry, and what about the neurology? How can you go\non thinking using a cat-sized brain? \n\nMinerva: Magic. \n\nHarry: Magic isn't enough to do that! You'd have to be a god! \n\nMinerva: ... that's the first time I've been called that.\n\n—Harry's first encounter with magic"},"Sequence:PtgH6ALi5CoJnPmGS":{"_id":"PtgH6ALi5CoJnPmGS","__typename":"Sequence","createdAt":"2017-08-23T21:44:40.795Z","userId":"nmk3nLpQE89dMRzzN","user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"contents":{"__ref":"Revision:PtgH6ALi5CoJnPmGS_"},"gridImageId":"sequences/i9dkgkhw14vwar63i4xn","bannerImageId":"sequences/cjcnbiwocxsxp1qnoywt","canonicalCollectionSlug":"hpmor","draft":false,"isDeleted":false,"hidden":false,"curatedOrder":501,"userProfileOrder":null,"af":null,"title":"The Methods of Rationality"},"User:Q7NW4XaWQmfPfdcFj":{"_id":"Q7NW4XaWQmfPfdcFj","__typename":"User","slug":"abramdemski","createdAt":"2009-03-12T06:07:25.510Z","username":"abramdemski","displayName":"abramdemski","fullName":"Abram Demski","karma":12722,"afKarma":2292,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":184,"commentCount":1534,"sequenceCount":9,"afPostCount":90,"afCommentCount":477,"spamRiskScore":1,"tagRevisionCount":68},"Revision:Rm6oQRJJmhGCcLvxh_":{"_id":"Rm6oQRJJmhGCcLvxh_","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2019-11-28T08:22:39.871Z","userId":"EQNTWXLKMeWMp2FQS","html":"<p>This is a sequence by Scott Garrabrant and Abram Demski on one current way of thinking about alignment: Embedded Agency.<\/p>","wordCount":20,"htmlHighlight":"<p>This is a sequence by Scott Garrabrant and Abram Demski on one current way of thinking about alignment: Embedded Agency.<\/p>","plaintextDescription":"This is a sequence by Scott Garrabrant and Abram Demski on one current way of\nthinking about alignment: Embedded Agency."},"Sequence:Rm6oQRJJmhGCcLvxh":{"_id":"Rm6oQRJJmhGCcLvxh","__typename":"Sequence","createdAt":"2018-10-29T13:26:42.043Z","userId":"Q7NW4XaWQmfPfdcFj","user":{"__ref":"User:Q7NW4XaWQmfPfdcFj"},"contents":{"__ref":"Revision:Rm6oQRJJmhGCcLvxh_"},"gridImageId":"sequencesgrid/mxpqfzoorr921qviypmq","bannerImageId":"sequences/eoxmiqgdxndzkbhsws1z","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":14,"userProfileOrder":null,"af":true,"title":"Embedded Agency"},"User:BCmzFRdQhqLPREvat":{"_id":"BCmzFRdQhqLPREvat","__typename":"User","slug":"ricraz","createdAt":"2013-07-14T15:42:06.397Z","username":"ricraz","displayName":"Richard_Ngo","fullName":"Richard Ngo","karma":5320,"afKarma":1156,"deleted":false,"isAdmin":false,"htmlBio":"<p>Former AI safety research engineer, now AI governance researcher at OpenAI. Blog: <a href=\"http://thinkingcomplete.blogspot.com\">thinkingcomplete.blogspot.com<\/a><\/p>\n","postCount":78,"commentCount":511,"sequenceCount":2,"afPostCount":34,"afCommentCount":219,"spamRiskScore":1,"tagRevisionCount":0},"Revision:mzgtmmTKKn5MuCzFJ_":{"_id":"mzgtmmTKKn5MuCzFJ_","__typename":"Revision","version":"1.4.0","updateType":"minor","editedAt":"2021-02-12T00:33:50.580Z","userId":"BCmzFRdQhqLPREvat","html":"<p>In this report (also <a href=\"https://drive.google.com/file/d/1uK7NhdSKprQKZnRjU58X7NLA1auXlWHt/view?usp=sharing\">available here as a PDF<\/a>) I have attempted to put together the most compelling case for why the development of artificial general intelligence (AGI) might pose an existential threat. It stems from my dissatisfaction with existing arguments about the potential risks from AGI. Early work tends to be less relevant in the context of modern machine learning; more recent work is scattered and brief. I originally intended to just summarise other people's arguments, but as this report has grown, it's become more representative of my own views and less representative of anyone else's. So while it covers the standard ideas, I also think that it provides a new perspective on how to think about AGI - one which doesn't take any previous claims for granted, but attempts to work them out from first principles.<\/p>","wordCount":138,"htmlHighlight":"<p>In this report (also <a href=\"https://drive.google.com/file/d/1uK7NhdSKprQKZnRjU58X7NLA1auXlWHt/view?usp=sharing\">available here as a PDF<\/a>) I have attempted to put together the most compelling case for why the development of artificial general intelligence (AGI) might pose an existential threat. It stems from my dissatisfaction with existing arguments about the potential risks from AGI. Early work tends to be less relevant in the context of modern machine learning; more recent work is scattered and brief. I originally intended to just summarise other people's arguments, but as this report has grown, it's become more representative of my own views and less representative of anyone else's. So while it covers the standard ideas, I also think that it provides a new perspective on how to think about AGI - one which doesn't take any previous claims for granted, but attempts to work them out from first principles.<\/p>","plaintextDescription":"In this report (also available here as a PDF) I have attempted to put together\nthe most compelling case for why the development of artificial general\nintelligence (AGI) might pose an existential threat. It stems from my\ndissatisfaction with existing arguments about the potential risks from AGI.\nEarly work tends to be less relevant in the context of modern machine learning;\nmore recent work is scattered and brief. I originally intended to just summarise\nother people's arguments, but as this report has grown, it's become more\nrepresentative of my own views and less representative of anyone else's. So\nwhile it covers the standard ideas, I also think that it provides a new\nperspective on how to think about AGI - one which doesn't take any previous\nclaims for granted, but attempts to work them out from first principles."},"Sequence:mzgtmmTKKn5MuCzFJ":{"_id":"mzgtmmTKKn5MuCzFJ","__typename":"Sequence","createdAt":"2020-09-28T13:58:47.550Z","userId":"BCmzFRdQhqLPREvat","user":{"__ref":"User:BCmzFRdQhqLPREvat"},"contents":{"__ref":"Revision:mzgtmmTKKn5MuCzFJ_"},"gridImageId":"sequencesgrid/r68kkaexxymt3ckkc6pp","bannerImageId":"sequences/zxck6do8omxqiussiz5k","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":13,"userProfileOrder":1,"af":true,"title":"AGI safety from first principles"},"User:n6LYNw2uGfYnD4pX2":{"_id":"n6LYNw2uGfYnD4pX2","__typename":"User","slug":"lsusr","createdAt":"2019-08-03T22:27:09.960Z","username":"lsusr","displayName":"lsusr","fullName":"Lsusr","karma":10125,"afKarma":20,"deleted":null,"isAdmin":false,"htmlBio":"<p>Most (but not all) of my writings are published here on Less Wrong. You can find links to everything I write by visiting my blog <a href=\"https://www.lsusr.com/\">lsusr.com<\/a>. You can subscribe to my posts <a href=\"https://www.lsusr.com/rss.xml\">via RSS<\/a>.<\/p>\n","postCount":205,"commentCount":994,"sequenceCount":10,"afPostCount":null,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0},"Revision:TF77XsD5PbucbJsG3_":{"_id":"TF77XsD5PbucbJsG3_","__typename":"Revision","version":null,"updateType":null,"editedAt":"2021-11-24T14:28:57.565Z","userId":null,"html":null,"wordCount":null,"htmlHighlight":"","plaintextDescription":null},"Sequence:TF77XsD5PbucbJsG3":{"_id":"TF77XsD5PbucbJsG3","__typename":"Sequence","createdAt":"2020-11-30T08:12:20.977Z","userId":"n6LYNw2uGfYnD4pX2","user":{"__ref":"User:n6LYNw2uGfYnD4pX2"},"contents":{"__ref":"Revision:TF77XsD5PbucbJsG3_"},"gridImageId":"sequencesgrid/whqbkvzjopvlh7paq73r","bannerImageId":"sequences/wt6zrk3cpnvpdv7pxnar","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":10,"userProfileOrder":null,"af":null,"title":"Luna Lovegood and the Chamber of Secrets"},"User:gb44edJjXhte8DA3A":{"_id":"gb44edJjXhte8DA3A","__typename":"User","slug":"paulfchristiano","createdAt":"2010-07-28T17:04:08.586Z","username":"paulfchristiano","displayName":"paulfchristiano","fullName":"Paul Christiano","karma":13619,"afKarma":2719,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":130,"commentCount":1630,"sequenceCount":1,"afPostCount":62,"afCommentCount":569,"spamRiskScore":1,"tagRevisionCount":0},"Revision:EmDuGeRw749sD3GKd_":{"_id":"EmDuGeRw749sD3GKd_","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2019-05-26T04:28:48.055Z","userId":"EQNTWXLKMeWMp2FQS","html":"<p>This is a sequence curated by Paul Christiano on one current approach to alignment: Iterated Amplification.<\/p>","wordCount":16,"htmlHighlight":"<p>This is a sequence curated by Paul Christiano on one current approach to alignment: Iterated Amplification.<\/p>","plaintextDescription":"This is a sequence curated by Paul Christiano on one current approach to\nalignment: Iterated Amplification."},"Sequence:EmDuGeRw749sD3GKd":{"_id":"EmDuGeRw749sD3GKd","__typename":"Sequence","createdAt":"2018-10-29T13:26:36.619Z","userId":"gb44edJjXhte8DA3A","user":{"__ref":"User:gb44edJjXhte8DA3A"},"contents":{"__ref":"Revision:EmDuGeRw749sD3GKd_"},"gridImageId":"sequencesgrid/prcccqtc5w7ytolilruu","bannerImageId":"sequences/bamysbymxal5tqccjawg","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":3,"userProfileOrder":null,"af":true,"title":"Iterated Amplification"},"User:du6SPHKnnPrPmxWNT":{"_id":"du6SPHKnnPrPmxWNT","__typename":"User","slug":"rohinmshah","createdAt":"2015-05-26T23:46:04.336Z","username":"rohinmshah","displayName":"rohinmshah","fullName":"Rohin Shah","karma":9892,"afKarma":3976,"deleted":false,"isAdmin":false,"htmlBio":"<p>Research Scientist at DeepMind. Creator of the Alignment Newsletter. <a href=\"http://rohinshah.com/\">http://rohinshah.com/<\/a><\/p>\n","postCount":195,"commentCount":1718,"sequenceCount":2,"afPostCount":100,"afCommentCount":1118,"spamRiskScore":1,"tagRevisionCount":1},"Revision:4dHMdK5TLN6xcqtyc_":{"_id":"4dHMdK5TLN6xcqtyc_","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2020-09-23T04:25:25.157Z","userId":"XtphY3uYHwruKqDyG","html":"<p>This is a sequence investigating the feasibility of one approach to AI alignment: value learning.<\/p>","wordCount":15,"htmlHighlight":"<p>This is a sequence investigating the feasibility of one approach to AI alignment: value learning.<\/p>","plaintextDescription":"This is a sequence investigating the feasibility of one approach to AI\nalignment: value learning."},"Sequence:4dHMdK5TLN6xcqtyc":{"_id":"4dHMdK5TLN6xcqtyc","__typename":"Sequence","createdAt":"2018-10-29T18:23:24.873Z","userId":"du6SPHKnnPrPmxWNT","user":{"__ref":"User:du6SPHKnnPrPmxWNT"},"contents":{"__ref":"Revision:4dHMdK5TLN6xcqtyc_"},"gridImageId":"sequencesgrid/x0pxuhnauzakdnrqijhe","bannerImageId":"sequences/x4nn0v3suj8bbf0tr9b3","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":2,"userProfileOrder":null,"af":true,"title":"Value Learning"},"User:AThTtkDufXp3rmMDa":{"_id":"AThTtkDufXp3rmMDa","__typename":"User","slug":"evhub","createdAt":"2017-01-17T06:05:22.405Z","username":"evhub","displayName":"evhub","fullName":"Evan Hubinger","karma":4094,"afKarma":1704,"deleted":false,"isAdmin":false,"htmlBio":"<p>I (Evan Hubinger) am a <a href=\"https://intelligence.org/team\">Research Fellow at MIRI<\/a>. Broadly, I work on <a href=\"https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB\">inner alignment<\/a> for <a href=\"https://www.alignmentforum.org/posts/YTq4X6inEudiHkHDF/prosaic-ai-alignment\">prosaic machine learning<\/a>.<\/p>\n<p>See: \"<a href=\"https://www.alignmentforum.org/posts/ptmmK9PWgYTuWToaZ/what-i-ll-be-doing-at-miri\">What I'll doing at MIRI<\/a>.\"<\/p>\n<p>Pronouns: he/him/his<\/p>\n<p>Email: <a href=\"mailto:evanjhub@gmail.com\">evanjhub@gmail.com<\/a><\/p>\n<p>Selected work:<\/p>\n<ul>\n<li>“<a href=\"https://www.alignmentforum.org/posts/FDJnZt8Ks2djouQTZ/how-do-we-become-confident-in-the-safety-of-a-machine\">How do we become confident in the safety of a machine learning system?<\/a>”<\/li>\n<li>“<a href=\"https://www.alignmentforum.org/posts/fRsjBseRuvRhMPPE5/an-overview-of-11-proposals-for-building-safe-advanced-ai\">An overview of 11 proposals for building safe advanced AI<\/a>”<\/li>\n<li>“<a href=\"https://www.alignmentforum.org/posts/9Dy5YRaoCxH9zuJqa/relaxed-adversarial-training-for-inner-alignment\">Relaxed adversarial training for inner alignment<\/a>”<\/li>\n<li>“<a href=\"https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB\">Risks from Learned Optimization<\/a>” (coauthor)<\/li>\n<\/ul>\n","postCount":38,"commentCount":412,"sequenceCount":null,"afPostCount":35,"afCommentCount":323,"spamRiskScore":1,"tagRevisionCount":0},"Revision:r9tYkB2a8Fp4DN8yB_":{"_id":"r9tYkB2a8Fp4DN8yB_","__typename":"Revision","version":"1.8.0","updateType":"minor","editedAt":"2021-07-23T06:12:38.425Z","userId":"AThTtkDufXp3rmMDa","html":"<p><em>This is a sequence version of the paper “<a href=\"https://arxiv.org/abs/1906.01820\">Risks from Learned Optimization in Advanced Machine Learning Systems<\/a>” by Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, Joar Skalse, and Scott Garrabrant. Each post in the sequence corresponds to a different section of the paper. Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, and Joar Skalse contributed equally to this sequence.<\/em><\/p>\n<p>The goal of this sequence is to analyze the type of learned optimization that occurs when a learned model (such as a neural network) is itself an optimizer—a situation we refer to as <em>mesa-optimization,<\/em> a neologism we introduce in this sequence. We believe that the possibility of mesa-optimization raises two important questions for the safety and transparency of advanced machine learning systems. First, under what circumstances will learned models be optimizers, including when they should not be? Second, when a learned model is an optimizer, what will its objective be—how will it differ from the loss function it was trained under—and how can it be aligned?<\/p>\n","wordCount":163,"htmlHighlight":"<p><em>This is a sequence version of the paper “<a href=\"https://arxiv.org/abs/1906.01820\">Risks from Learned Optimization in Advanced Machine Learning Systems<\/a>” by Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, Joar Skalse, and Scott Garrabrant. Each post in the sequence corresponds to a different section of the paper. Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, and Joar Skalse contributed equally to this sequence.<\/em><\/p>\n<p>The goal of this sequence is to analyze the type of learned optimization that occurs when a learned model (such as a neural network) is itself an optimizer—a situation we refer to as <em>mesa-optimization,<\/em> a neologism we introduce in this sequence. We believe that the possibility of mesa-optimization raises two important questions for the safety and transparency of advanced machine learning systems. First, under what circumstances will learned models be optimizers, including when they should not be? Second, when a learned model is an optimizer, what will its objective be—how will it differ from the loss function it was trained under—and how can it be aligned?<\/p>","plaintextDescription":"This is a sequence version of the paper “Risks from Learned Optimization in\nAdvanced Machine Learning Systems” by Evan Hubinger, Chris van Merwijk, Vladimir\nMikulik, Joar Skalse, and Scott Garrabrant. Each post in the sequence\ncorresponds to a different section of the paper. Evan Hubinger, Chris van\nMerwijk, Vladimir Mikulik, and Joar Skalse contributed equally to this sequence.\n\nThe goal of this sequence is to analyze the type of learned optimization that\noccurs when a learned model (such as a neural network) is itself an optimizer—a\nsituation we refer to as mesa-optimization, a neologism we introduce in this\nsequence. We believe that the possibility of mesa-optimization raises two\nimportant questions for the safety and transparency of advanced machine learning\nsystems. First, under what circumstances will learned models be optimizers,\nincluding when they should not be? Second, when a learned model is an optimizer,\nwhat will its objective be—how will it differ from the loss function it was\ntrained under—and how can it be aligned?"},"Sequence:r9tYkB2a8Fp4DN8yB":{"_id":"r9tYkB2a8Fp4DN8yB","__typename":"Sequence","createdAt":"2019-05-31T02:18:02.737Z","userId":"AThTtkDufXp3rmMDa","user":{"__ref":"User:AThTtkDufXp3rmMDa"},"contents":{"__ref":"Revision:r9tYkB2a8Fp4DN8yB_"},"gridImageId":"sequencesgrid/rzdw9faewnetbmumls9y","bannerImageId":"sequences/ahlmdailzfoxjcczzbub","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":1,"userProfileOrder":null,"af":true,"title":"Risks from Learned Optimization"},"Revision:qWoFR4ytMpQ5vw3FT_":{"_id":"qWoFR4ytMpQ5vw3FT_","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2018-07-06T20:02:30.941Z","userId":"nmk3nLpQE89dMRzzN","html":"<blockquote>&quot;The kind of classic fifties-era first-contact story that Jonathan Swift might have written, if Jonathan Swift had had a background in game theory.&quot;<br/>      -- (Hugo nominee) Peter Watts, &quot;<a href=\"http://www.rifters.com/crawl/?p=266\">In Praise of Baby-Eating<\/a>&quot;<\/blockquote><p><\/p><p><em>Three Worlds Collide<\/em> is a story I wrote to illustrate some points on naturalistic metaethics and diverse other issues of rational conduct.  It grew, as such things do, into a small novella.  On publication, it proved widely popular and widely criticized.  Be warned that the story, as it wrote itself, ended up containing some profanity and PG-13 content.<\/p><p>(PDF is <a href=\"http://robinhanson.typepad.com/files/three-worlds-collide.pdf\">here<\/a>. Old contents post with comments is <a href=\"https://www.lesswrong.com/posts/HawFh7RvDM4RyoJ2d/three-worlds-collide-0-8\">here<\/a>.)<\/p>","wordCount":102,"htmlHighlight":"<blockquote>&quot;The kind of classic fifties-era first-contact story that Jonathan Swift might have written, if Jonathan Swift had had a background in game theory.&quot;<br/>      -- (Hugo nominee) Peter Watts, &quot;<a href=\"http://www.rifters.com/crawl/?p=266\">In Praise of Baby-Eating<\/a>&quot;<\/blockquote><p><\/p><p><em>Three Worlds Collide<\/em> is a story I wrote to illustrate some points on naturalistic metaethics and diverse other issues of rational conduct.  It grew, as such things do, into a small novella.  On publication, it proved widely popular and widely criticized.  Be warned that the story, as it wrote itself, ended up containing some profanity and PG-13 content.<\/p><p>(PDF is <a href=\"http://robinhanson.typepad.com/files/three-worlds-collide.pdf\">here<\/a>. Old contents post with comments is <a href=\"https://www.lesswrong.com/posts/HawFh7RvDM4RyoJ2d/three-worlds-collide-0-8\">here<\/a>.)<\/p>","plaintextDescription":"\"The kind of classic fifties-era first-contact story that Jonathan Swift might\nhave written, if Jonathan Swift had had a background in game theory.\"\n-- (Hugo nominee) Peter Watts, \"In Praise of Baby-Eating\"\n\nThree Worlds Collide is a story I wrote to illustrate some points on\nnaturalistic metaethics and diverse other issues of rational conduct. It grew,\nas such things do, into a small novella. On publication, it proved widely\npopular and widely criticized. Be warned that the story, as it wrote itself,\nended up containing some profanity and PG-13 content.\n\n(PDF is here. Old contents post with comments is here.)"},"Sequence:qWoFR4ytMpQ5vw3FT":{"_id":"qWoFR4ytMpQ5vw3FT","__typename":"Sequence","createdAt":"2018-07-06T20:02:30.941Z","userId":"nmk3nLpQE89dMRzzN","user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"contents":{"__ref":"Revision:qWoFR4ytMpQ5vw3FT_"},"gridImageId":"sequencesgrid/sio9b8jw1apesuispocg","bannerImageId":"sequences/evlaa0fe6nysqqhhqwyd","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":1,"userProfileOrder":null,"af":null,"title":"Three Worlds Collide"},"User:N9zj5qpTfqmbn9dro":{"_id":"N9zj5qpTfqmbn9dro","__typename":"User","slug":"zvi","createdAt":"2009-03-31T20:54:54.077Z","username":"Zvi","displayName":"Zvi","fullName":null,"karma":19024,"afKarma":62,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":348,"commentCount":1089,"sequenceCount":3,"afPostCount":1,"afCommentCount":1,"spamRiskScore":1,"tagRevisionCount":0},"Revision:HXkpm9b8o964jbQ89_":{"_id":"HXkpm9b8o964jbQ89_","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2018-04-09T22:33:08.727Z","userId":"N9zj5qpTfqmbn9dro","html":"<p>A series of meditations on freedom to do the things you care about.<\/p><blockquote>Some things are fundamentally Out to Get You.<\/blockquote><blockquote>They seek resources at your expense. Fees are hidden. Extra options are foisted upon you. Things are made intentionally worse, forcing you to pay to make it less worse. Everything is data to sell you something, rather than an opportunity to help you.<\/blockquote><blockquote>When something is out to get you, if you aren&#x27;t careful, it can take all your resources - your time, you money, your attention.<\/blockquote><blockquote>This matters, more deeply than you might realize. It&#x27;s not just that you need your resources. You need enough resources to have slack: freedom from constraints that might bind you. <\/blockquote><blockquote>Slack means margin of error. You can relax. You can explore and pursue opportunities. You can plan for the long term. You can stick to principles and do the right thing.<\/blockquote><p><\/p>","wordCount":146,"htmlHighlight":"<p>A series of meditations on freedom to do the things you care about.<\/p><blockquote>Some things are fundamentally Out to Get You.<\/blockquote><blockquote>They seek resources at your expense. Fees are hidden. Extra options are foisted upon you. Things are made intentionally worse, forcing you to pay to make it less worse. Everything is data to sell you something, rather than an opportunity to help you.<\/blockquote><blockquote>When something is out to get you, if you aren&#x27;t careful, it can take all your resources - your time, you money, your attention.<\/blockquote><blockquote>This matters, more deeply than you might realize. It&#x27;s not just that you need your resources. You need enough resources to have slack: freedom from constraints that might bind you. <\/blockquote><blockquote>Slack means margin of error. You can relax. You can explore and pursue opportunities. You can plan for the long term. You can stick to principles and do the right thing.<\/blockquote><p><\/p>","plaintextDescription":"A series of meditations on freedom to do the things you care about.\n\nSome things are fundamentally Out to Get You.They seek resources at your\nexpense. Fees are hidden. Extra options are foisted upon you. Things are made\nintentionally worse, forcing you to pay to make it less worse. Everything is\ndata to sell you something, rather than an opportunity to help you.When\nsomething is out to get you, if you aren't careful, it can take all your\nresources - your time, you money, your attention.This matters, more deeply than\nyou might realize. It's not just that you need your resources. You need enough\nresources to have slack: freedom from constraints that might bind you. Slack\nmeans margin of error. You can relax. You can explore and pursue opportunities.\nYou can plan for the long term. You can stick to principles and do the right\nthing."},"Sequence:HXkpm9b8o964jbQ89":{"_id":"HXkpm9b8o964jbQ89","__typename":"Sequence","createdAt":"2018-04-09T22:33:08.727Z","userId":"N9zj5qpTfqmbn9dro","user":{"__ref":"User:N9zj5qpTfqmbn9dro"},"contents":{"__ref":"Revision:HXkpm9b8o964jbQ89_"},"gridImageId":"sequencesgrid/rqnuxewffasun6tvdkng","bannerImageId":"sequences/ecwup5jjh2nq00uf0mi0","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":1,"userProfileOrder":null,"af":null,"title":"Slack and the Sabbath "},"Revision:ZNNi2uNx9E6iwGKKG_":{"_id":"ZNNi2uNx9E6iwGKKG_","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2018-04-08T21:50:10.329Z","userId":"XgYW5s8njaYrtyP7q","html":"<p>This sequence of posts is a primer on game theory intended at an introductory level. Because it is introductory, Less Wrong veterans may find some parts boring, obvious, or simplistic - although hopefully nothing is so simplistic as to be outright wrong.<\/p><p>Parts of this sequence draw heavily upon material from <em><u><a href=\"http://www.amazon.com/The-Art-Strategy-Theorists-Business/dp/0393062430\">The Art of Strategy<\/a><\/u><\/em> by Avinash Dixit and Barry Nalebuff, and it may in part be considered a (very favorable) review of the book accompanied by an exploration of its content. I have tried to include enough material to be useful, but not so much material that it becomes a plagiarism rather than a review (it&#x27;s probably a bad idea to pick a legal fight with people who write books called <em>The Art of Strategy<\/em>.) Therefore, for the most complete and engaging presentation of this material, I highly recommend the original book.<\/p><p>Special thanks to Luke for his book recommendation and his strong encouragement to write this.<\/p>","wordCount":156,"htmlHighlight":"<p>This sequence of posts is a primer on game theory intended at an introductory level. Because it is introductory, Less Wrong veterans may find some parts boring, obvious, or simplistic - although hopefully nothing is so simplistic as to be outright wrong.<\/p><p>Parts of this sequence draw heavily upon material from <em><u><a href=\"http://www.amazon.com/The-Art-Strategy-Theorists-Business/dp/0393062430\">The Art of Strategy<\/a><\/u><\/em> by Avinash Dixit and Barry Nalebuff, and it may in part be considered a (very favorable) review of the book accompanied by an exploration of its content. I have tried to include enough material to be useful, but not so much material that it becomes a plagiarism rather than a review (it&#x27;s probably a bad idea to pick a legal fight with people who write books called <em>The Art of Strategy<\/em>.) Therefore, for the most complete and engaging presentation of this material, I highly recommend the original book.<\/p><p>Special thanks to Luke for his book recommendation and his strong encouragement to write this.<\/p>","plaintextDescription":"This sequence of posts is a primer on game theory intended at an introductory\nlevel. Because it is introductory, Less Wrong veterans may find some parts\nboring, obvious, or simplistic - although hopefully nothing is so simplistic as\nto be outright wrong.\n\nParts of this sequence draw heavily upon material from The Art of Strategy by\nAvinash Dixit and Barry Nalebuff, and it may in part be considered a (very\nfavorable) review of the book accompanied by an exploration of its content. I\nhave tried to include enough material to be useful, but not so much material\nthat it becomes a plagiarism rather than a review (it's probably a bad idea to\npick a legal fight with people who write books called The Art of Strategy.)\nTherefore, for the most complete and engaging presentation of this material, I\nhighly recommend the original book.\n\nSpecial thanks to Luke for his book recommendation and his strong encouragement\nto write this."},"Sequence:ZNNi2uNx9E6iwGKKG":{"_id":"ZNNi2uNx9E6iwGKKG","__typename":"Sequence","createdAt":"2018-04-08T21:50:10.329Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:ZNNi2uNx9E6iwGKKG_"},"gridImageId":"sequencesgrid/vitugifyyh2upm9ucjzh","bannerImageId":"sequences/zvybkycf2vyasr4zwptr","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":1,"userProfileOrder":null,"af":null,"title":"Introduction to Game Theory"},"Revision:G2GDw3m4MJ5ixSM92_":{"_id":"G2GDw3m4MJ5ixSM92_","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2019-08-26T19:33:04.677Z","userId":"EQNTWXLKMeWMp2FQS","html":"<p>A sequence on models of the human mind, drawing on psychology and neuroscience to discuss motivation, learning and behaviour.<\/p>","wordCount":19,"htmlHighlight":"<p>A sequence on models of the human mind, drawing on psychology and neuroscience to discuss motivation, learning and behaviour.<\/p>","plaintextDescription":"A sequence on models of the human mind, drawing on psychology and neuroscience\nto discuss motivation, learning and behaviour."},"Sequence:G2GDw3m4MJ5ixSM92":{"_id":"G2GDw3m4MJ5ixSM92","__typename":"Sequence","createdAt":"2018-02-22T18:10:39.949Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:G2GDw3m4MJ5ixSM92_"},"gridImageId":"sequencesgrid/djfksyoldrjt4ef5jts3","bannerImageId":"sequences/ad7shnab6qq5v6cqxpme","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":1,"userProfileOrder":null,"af":null,"title":"The Blue-Minimizing Robot"},"User:c8gC5wARE3fPwu94u":{"_id":"c8gC5wARE3fPwu94u","__typename":"User","slug":"alkjash","createdAt":"2017-10-06T20:42:59.929Z","username":"alkjash","displayName":"alkjash","fullName":null,"karma":4057,"afKarma":4,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":80,"commentCount":259,"sequenceCount":4,"afPostCount":0,"afCommentCount":null,"spamRiskScore":1,"tagRevisionCount":0},"Revision:pC6DYFLPMTCbEwH8W_":{"_id":"pC6DYFLPMTCbEwH8W_","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2018-02-22T16:02:57.918Z","userId":"c8gC5wARE3fPwu94u","html":"<p>How do babies learn language? How did Moses compute the ten Commandments? How did Shakespeare write <em>Hamlet<\/em>?<\/p><p>Babble and Prune is an ancient mythological story, a psychological model, a new religion for a post-religion age, that answers all these questions and more.<\/p><p>Two Gods - Babble and Prune, Artist and Critic, Generator and Discriminator - are locked in eternal conflict over your mind. Babble creates a constant stream of coarse material, while Prune cuts these ideas harshly without the slightest hint of remorse. Only you, chosen hero, can restore the balance between these two ancient deities, and in doing so maximize your creative output.<\/p><p>It is time to reclaim your birthright, hero: go forth and babble!<\/p>","wordCount":113,"htmlHighlight":"<p>How do babies learn language? How did Moses compute the ten Commandments? How did Shakespeare write <em>Hamlet<\/em>?<\/p><p>Babble and Prune is an ancient mythological story, a psychological model, a new religion for a post-religion age, that answers all these questions and more.<\/p><p>Two Gods - Babble and Prune, Artist and Critic, Generator and Discriminator - are locked in eternal conflict over your mind. Babble creates a constant stream of coarse material, while Prune cuts these ideas harshly without the slightest hint of remorse. Only you, chosen hero, can restore the balance between these two ancient deities, and in doing so maximize your creative output.<\/p><p>It is time to reclaim your birthright, hero: go forth and babble!<\/p>","plaintextDescription":"How do babies learn language? How did Moses compute the ten Commandments? How\ndid Shakespeare write Hamlet?\n\nBabble and Prune is an ancient mythological story, a psychological model, a new\nreligion for a post-religion age, that answers all these questions and more.\n\nTwo Gods - Babble and Prune, Artist and Critic, Generator and Discriminator -\nare locked in eternal conflict over your mind. Babble creates a constant stream\nof coarse material, while Prune cuts these ideas harshly without the slightest\nhint of remorse. Only you, chosen hero, can restore the balance between these\ntwo ancient deities, and in doing so maximize your creative output.\n\nIt is time to reclaim your birthright, hero: go forth and babble!"},"Sequence:pC6DYFLPMTCbEwH8W":{"_id":"pC6DYFLPMTCbEwH8W","__typename":"Sequence","createdAt":"2018-02-22T16:02:57.918Z","userId":"c8gC5wARE3fPwu94u","user":{"__ref":"User:c8gC5wARE3fPwu94u"},"contents":{"__ref":"Revision:pC6DYFLPMTCbEwH8W_"},"gridImageId":"sequencesgrid/nhvoi5fvxxzthqhu2ctt","bannerImageId":"sequences/dncaedgak01s1ssja5nf","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":1,"userProfileOrder":null,"af":null,"title":"Babble and Prune"},"Revision:SqFbMbtxGybdS2gRs_":{"_id":"SqFbMbtxGybdS2gRs_","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2020-04-19T19:13:02.750Z","userId":"XtphY3uYHwruKqDyG","html":"<p>These essays include a discussion of truth, formal logic, causality, and metaethics, and are a good way for more ambitious readers to quickly get up to speed.<\/p>","wordCount":27,"htmlHighlight":"<p>These essays include a discussion of truth, formal logic, causality, and metaethics, and are a good way for more ambitious readers to quickly get up to speed.<\/p>","plaintextDescription":"These essays include a discussion of truth, formal logic, causality, and\nmetaethics, and are a good way for more ambitious readers to quickly get up to\nspeed."},"Sequence:SqFbMbtxGybdS2gRs":{"_id":"SqFbMbtxGybdS2gRs","__typename":"Sequence","createdAt":"2018-01-22T08:55:37.700Z","userId":"nmk3nLpQE89dMRzzN","user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"contents":{"__ref":"Revision:SqFbMbtxGybdS2gRs_"},"gridImageId":"sequencesgrid/i2ogsvmipbdolntkew4a","bannerImageId":"sequences/kx9ydblgnzt7f16remz3","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":1,"userProfileOrder":null,"af":null,"title":"Highly Advanced Epistemology 101 for Beginners"},"User:SdZmP36R37riQrHAw":{"_id":"SdZmP36R37riQrHAw","__typename":"User","slug":"lukeprog","createdAt":"2009-03-19T08:07:34.230Z","username":"lukeprog","displayName":"lukeprog","fullName":"Luke Muehlhauser","karma":35296,"afKarma":3,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":458,"commentCount":4074,"sequenceCount":3,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":58},"Revision:yFvZa9wkv5JoqhM8F_":{"_id":"yFvZa9wkv5JoqhM8F_","__typename":"Revision","version":null,"updateType":"minor","editedAt":"2021-11-24T14:28:57.566Z","userId":null,"html":null,"wordCount":null,"htmlHighlight":"","plaintextDescription":null},"Sequence:yFvZa9wkv5JoqhM8F":{"_id":"yFvZa9wkv5JoqhM8F","__typename":"Sequence","createdAt":"2017-11-25T22:42:52.100Z","userId":"SdZmP36R37riQrHAw","user":{"__ref":"User:SdZmP36R37riQrHAw"},"contents":{"__ref":"Revision:yFvZa9wkv5JoqhM8F_"},"gridImageId":"sequencesgrid/yxlirutmux2fjqnnjhoc","bannerImageId":"sequences/q1spaabxeuy2wkgpafwa","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":1,"userProfileOrder":null,"af":null,"title":"Rationality and Philosophy"},"User:pnFbJAtNHGDK8PHQx":{"_id":"pnFbJAtNHGDK8PHQx","__typename":"User","slug":"annasalamon","createdAt":"2009-02-27T04:25:14.013Z","username":"AnnaSalamon","displayName":"AnnaSalamon","fullName":null,"karma":13303,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":82,"commentCount":821,"sequenceCount":1,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":18},"Revision:XipJ7DMjYyriAm7fr_":{"_id":"XipJ7DMjYyriAm7fr_","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-11-25T21:06:47.500Z","userId":"pnFbJAtNHGDK8PHQx","html":"<p>Decisions need to be modeled with some structure in order to be scrutinized and systematically improved; simply &quot;intuiting&quot; the answers to decision problems by ad-hoc methods is not conducive to thorough analysis. <\/p><p>For this, we formulate decision theories. This sequence, themed with an analysis of Newcomb&#x27;s problem, is a consolidated summary and context for the many decision theory discussions found on LessWrong at the time of writing.<\/p>","wordCount":66,"htmlHighlight":"<p>Decisions need to be modeled with some structure in order to be scrutinized and systematically improved; simply &quot;intuiting&quot; the answers to decision problems by ad-hoc methods is not conducive to thorough analysis. <\/p><p>For this, we formulate decision theories. This sequence, themed with an analysis of Newcomb&#x27;s problem, is a consolidated summary and context for the many decision theory discussions found on LessWrong at the time of writing.<\/p>","plaintextDescription":"Decisions need to be modeled with some structure in order to be scrutinized and\nsystematically improved; simply \"intuiting\" the answers to decision problems by\nad-hoc methods is not conducive to thorough analysis. \n\nFor this, we formulate decision theories. This sequence, themed with an analysis\nof Newcomb's problem, is a consolidated summary and context for the many\ndecision theory discussions found on LessWrong at the time of writing."},"Sequence:XipJ7DMjYyriAm7fr":{"_id":"XipJ7DMjYyriAm7fr","__typename":"Sequence","createdAt":"2017-11-25T21:06:47.500Z","userId":"pnFbJAtNHGDK8PHQx","user":{"__ref":"User:pnFbJAtNHGDK8PHQx"},"contents":{"__ref":"Revision:XipJ7DMjYyriAm7fr_"},"gridImageId":"sequencesgrid/qpreo6bc9vxwyf2l1dzo","bannerImageId":"sequences/nrxkrnabxv7q0szgjjcr","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":1,"userProfileOrder":null,"af":null,"title":"Decision Theory: Newcomb's Problem"},"Revision:oi873FWi6pHWxswSa_":{"_id":"oi873FWi6pHWxswSa_","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-11-24T03:37:56.045Z","userId":"SdZmP36R37riQrHAw","html":"<p>A <u><a href=\"https://wiki.lesswrong.com/wiki/Sequence\">sequence<\/a><\/u> summarizing scientifically-backed advice for &quot;<u><a href=\"https://wiki.lesswrong.com/wiki/Winning\">winning<\/a><\/u>&quot; at everyday life: in one&#x27;s productivity, in one&#x27;s relationships, in one&#x27;s emotions, etc. Each post concludes with footnotes and a long list of references from the academic literature.<\/p>","wordCount":35,"htmlHighlight":"<p>A <u><a href=\"https://wiki.lesswrong.com/wiki/Sequence\">sequence<\/a><\/u> summarizing scientifically-backed advice for &quot;<u><a href=\"https://wiki.lesswrong.com/wiki/Winning\">winning<\/a><\/u>&quot; at everyday life: in one&#x27;s productivity, in one&#x27;s relationships, in one&#x27;s emotions, etc. Each post concludes with footnotes and a long list of references from the academic literature.<\/p>","plaintextDescription":"A sequence summarizing scientifically-backed advice for \"winning\" at everyday\nlife: in one's productivity, in one's relationships, in one's emotions, etc.\nEach post concludes with footnotes and a long list of references from the\nacademic literature."},"Sequence:oi873FWi6pHWxswSa":{"_id":"oi873FWi6pHWxswSa","__typename":"Sequence","createdAt":"2017-11-24T03:37:56.045Z","userId":"SdZmP36R37riQrHAw","user":{"__ref":"User:SdZmP36R37riQrHAw"},"contents":{"__ref":"Revision:oi873FWi6pHWxswSa_"},"gridImageId":"sequencesgrid/yp01lueog8rjaybsizux","bannerImageId":"sequences/l6y9o00lif4qenrdel5w","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":1,"userProfileOrder":null,"af":null,"title":"The Science of Winning at Life"},"Revision:bQgRsy23biR52poMf_":{"_id":"bQgRsy23biR52poMf_","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-11-22T02:58:02.903Z","userId":"SdZmP36R37riQrHAw","html":"<p>Years ago, I wrote an unfinished sequence of posts called &quot;<a href=\"https://wiki.lesswrong.com/wiki/No-Nonsense_Metaethics\">No-Nonsense Metaethics<\/a>.&quot; My last post, <a href=\"https://www.lesserwrong.com/posts/3zDX3f3QTepNeZHGc/pluralistic-moral-reductionism\">Pluralistic Moral Reductionism<\/a>, said I would next explore &quot;empathic metaethics,&quot; but I never got around to writing those posts. Recently, I wrote a high-level summary of some initial thoughts on &quot;empathic metaethics&quot; in <a href=\"https://www.openphilanthropy.org/2017-report-consciousness-and-moral-patienthood#ExtremeEffort\">section 6.1.2<\/a> of a report prepared for my employer, the <a href=\"https://www.openphilanthropy.org/\">Open Philanthropy Project<\/a>. With my employer&#x27;s permission, I&#x27;ve adapted that section for publication here, so that it can serve as the long-overdue concluding post in my sequence on metaethics.<\/p>","wordCount":87,"htmlHighlight":"<p>Years ago, I wrote an unfinished sequence of posts called &quot;<a href=\"https://wiki.lesswrong.com/wiki/No-Nonsense_Metaethics\">No-Nonsense Metaethics<\/a>.&quot; My last post, <a href=\"https://www.lesserwrong.com/posts/3zDX3f3QTepNeZHGc/pluralistic-moral-reductionism\">Pluralistic Moral Reductionism<\/a>, said I would next explore &quot;empathic metaethics,&quot; but I never got around to writing those posts. Recently, I wrote a high-level summary of some initial thoughts on &quot;empathic metaethics&quot; in <a href=\"https://www.openphilanthropy.org/2017-report-consciousness-and-moral-patienthood#ExtremeEffort\">section 6.1.2<\/a> of a report prepared for my employer, the <a href=\"https://www.openphilanthropy.org/\">Open Philanthropy Project<\/a>. With my employer&#x27;s permission, I&#x27;ve adapted that section for publication here, so that it can serve as the long-overdue concluding post in my sequence on metaethics.<\/p>","plaintextDescription":"Years ago, I wrote an unfinished sequence of posts called \"No-Nonsense\nMetaethics.\" My last post, Pluralistic Moral Reductionism, said I would next\nexplore \"empathic metaethics,\" but I never got around to writing those posts.\nRecently, I wrote a high-level summary of some initial thoughts on \"empathic\nmetaethics\" in section 6.1.2 of a report prepared for my employer, the Open\nPhilanthropy Project. With my employer's permission, I've adapted that section\nfor publication here, so that it can serve as the long-overdue concluding post\nin my sequence on metaethics."},"Sequence:bQgRsy23biR52poMf":{"_id":"bQgRsy23biR52poMf","__typename":"Sequence","createdAt":"2017-11-22T02:58:02.903Z","userId":"SdZmP36R37riQrHAw","user":{"__ref":"User:SdZmP36R37riQrHAw"},"contents":{"__ref":"Revision:bQgRsy23biR52poMf_"},"gridImageId":"sequencesgrid/kvoeqrfluqd0jv5fvwez","bannerImageId":"sequences/p5ywbc6j8355jbcptyrz","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":1,"userProfileOrder":null,"af":null,"title":"No-Nonsense Metaethics"},"Revision:oLGCcbnvabyibnG9d_":{"_id":"oLGCcbnvabyibnG9d_","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-11-07T03:42:59.852Z","userId":"nmk3nLpQE89dMRzzN","html":"<p>Inadequate Equilibria is a book about a generalized notion of efficient markets, and how we can use this notion to guess where society will or won’t be effective at pursuing some widely desired goal.<\/p>","wordCount":34,"htmlHighlight":"<p>Inadequate Equilibria is a book about a generalized notion of efficient markets, and how we can use this notion to guess where society will or won’t be effective at pursuing some widely desired goal.<\/p>","plaintextDescription":"Inadequate Equilibria is a book about a generalized notion of efficient markets,\nand how we can use this notion to guess where society will or won’t be effective\nat pursuing some widely desired goal."},"Sequence:oLGCcbnvabyibnG9d":{"_id":"oLGCcbnvabyibnG9d","__typename":"Sequence","createdAt":"2017-11-07T03:42:59.852Z","userId":"nmk3nLpQE89dMRzzN","user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"contents":{"__ref":"Revision:oLGCcbnvabyibnG9d_"},"gridImageId":"sequencesgrid/vbhv0s06jdmonk6garvf","bannerImageId":"sequences/gl1xzufmu65v6cn66wrm","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":1,"userProfileOrder":null,"af":null,"title":"Inadequate Equilibria"},"User:hbQoLoK5tpmFAJGr4":{"_id":"hbQoLoK5tpmFAJGr4","__typename":"User","slug":"scott-garrabrant","createdAt":"2017-09-22T02:21:16.385Z","username":"Scott Garrabrant","displayName":"Scott Garrabrant","fullName":null,"karma":5321,"afKarma":1208,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":58,"commentCount":299,"sequenceCount":2,"afPostCount":96,"afCommentCount":152,"spamRiskScore":1,"tagRevisionCount":0},"Revision:2A7rrZ4ySx6R8mfoT_":{"_id":"2A7rrZ4ySx6R8mfoT_","__typename":"Revision","version":"0.3.0","updateType":"minor","editedAt":"2021-01-19T23:18:25.404Z","userId":"XtphY3uYHwruKqDyG","html":"<p>Cartesian frames are a way to add a first-person perspective (with choices, uncertainty, and so on) on top of a set of possible worlds. This sequence introduces Cartesian frames and basic operations on frames.<\/p>","wordCount":34,"htmlHighlight":"<p>Cartesian frames are a way to add a first-person perspective (with choices, uncertainty, and so on) on top of a set of possible worlds. This sequence introduces Cartesian frames and basic operations on frames.<\/p>","plaintextDescription":"Cartesian frames are a way to add a first-person perspective (with choices,\nuncertainty, and so on) on top of a set of possible worlds. This sequence\nintroduces Cartesian frames and basic operations on frames."},"Sequence:2A7rrZ4ySx6R8mfoT":{"_id":"2A7rrZ4ySx6R8mfoT","__typename":"Sequence","createdAt":"2020-10-22T13:42:07.868Z","userId":"hbQoLoK5tpmFAJGr4","user":{"__ref":"User:hbQoLoK5tpmFAJGr4"},"contents":{"__ref":"Revision:2A7rrZ4ySx6R8mfoT_"},"gridImageId":"sequencesgrid/a9iwqgsxkqznfrtskanw","bannerImageId":"sequences/jtgjfl0vc1igtmdwambt","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":0,"userProfileOrder":null,"af":true,"title":"Cartesian Frames"},"User:iPdmf2tiNRtfJbvdQ":{"_id":"iPdmf2tiNRtfJbvdQ","__typename":"User","slug":"alicorn","createdAt":"2009-03-17T18:52:42.458Z","username":"Alicorn","displayName":"Alicorn","fullName":null,"karma":29536,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":81,"commentCount":5165,"sequenceCount":1,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":1},"Revision:ynMFrq9K5iNMfSZNg_":{"_id":"ynMFrq9K5iNMfSZNg_","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2019-05-02T19:07:37.622Z","userId":"XtphY3uYHwruKqDyG","html":"<p><u><a href=\"https://wiki.lesswrong.com/wiki/Luminosity\">Luminosity<\/a><\/u>, as used here, is self-awareness. A luminous mental state is one that you have and know that you have. It could be an <u><a href=\"https://wiki.lesswrong.com/wiki/Emotion\">emotion<\/a><\/u>, a <u><a href=\"https://wiki.lesswrong.com/wiki/Belief\">belief<\/a><\/u> or <u><a href=\"https://wiki.lesswrong.com/wiki/Alief\">alief<\/a><\/u>, a disposition, a <u><a href=\"https://wiki.lesswrong.com/index.php?title=Qualia&action=edit&redlink=1\">quale<\/a><\/u>, a memory - anything that might happen or be stored in your brain. What&#x27;s going on in your head?<\/p>","wordCount":52,"htmlHighlight":"<p><u><a href=\"https://wiki.lesswrong.com/wiki/Luminosity\">Luminosity<\/a><\/u>, as used here, is self-awareness. A luminous mental state is one that you have and know that you have. It could be an <u><a href=\"https://wiki.lesswrong.com/wiki/Emotion\">emotion<\/a><\/u>, a <u><a href=\"https://wiki.lesswrong.com/wiki/Belief\">belief<\/a><\/u> or <u><a href=\"https://wiki.lesswrong.com/wiki/Alief\">alief<\/a><\/u>, a disposition, a <u><a href=\"https://wiki.lesswrong.com/index.php?title=Qualia&action=edit&redlink=1\">quale<\/a><\/u>, a memory - anything that might happen or be stored in your brain. What&#x27;s going on in your head?<\/p>","plaintextDescription":"Luminosity, as used here, is self-awareness. A luminous mental state is one that\nyou have and know that you have. It could be an emotion, a belief or alief, a\ndisposition, a quale, a memory - anything that might happen or be stored in your\nbrain. What's going on in your head?"},"Sequence:ynMFrq9K5iNMfSZNg":{"_id":"ynMFrq9K5iNMfSZNg","__typename":"Sequence","createdAt":"2018-02-22T18:50:08.321Z","userId":"iPdmf2tiNRtfJbvdQ","user":{"__ref":"User:iPdmf2tiNRtfJbvdQ"},"contents":{"__ref":"Revision:ynMFrq9K5iNMfSZNg_"},"gridImageId":"sequencesgrid/ozdf0thhtehmpmbf9dys","bannerImageId":"sequences/pkhcwvrxma1bl0g4cuto","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":0,"userProfileOrder":null,"af":null,"title":"Living Luminously"},"Revision:uhrvYft2RYnhYbFmz_":{"_id":"uhrvYft2RYnhYbFmz_","__typename":"Revision","htmlHighlight":"<p>Effective Altruism Virtual Programs is excited to announce that we’re hosting <strong>Legal Topics in Effective Altruism<\/strong> from October 18th to December 12th. This is a great opportunity for law students, practitioners, and researchers to discuss subjects at the intersection of the law and EA.&nbsp;<\/p><p>Register <strong>by Sunday, October 12th<\/strong>: <a href=\"https://efctv.org/EA-VP-legaltopics\"><u>https://efctv.org/EA-VP-legaltopics<\/u><\/a><\/p><p><br>We’ll also be hosting our usual virtual programs from October 4th to November 28th!&nbsp;<\/p><ul><li><strong>The Introductory EA Program<\/strong> aims to introduce the core ideas of effective altruism.<\/li><li><strong>The In-Depth EA Program <\/strong>seeks to engage participants with more complex questions to help them figure out how they can best make an impact.&nbsp;<\/li><li><i><strong>The Precipice <\/strong><\/i><strong>Reading Group<\/strong> explores the science behind the existential risks we face.&nbsp;<\/li><\/ul><p>Register <strong>by Sunday, September 26th<\/strong>: <a href=\"https://efctv.org/virtual-programs\"><u>https://efctv.org/virtual-programs<\/u><\/a><\/p><p>If you know anyone who might benefit from participating in any of these programs, please share this opportunity with them.&nbsp;<\/p><p>&nbsp;<\/p><p>If you have participated in any fellowships, programs, or reading groups before, and are looking for ways to contribute to the EA community, please <strong>apply to be a facilitator<\/strong>! Getting more great facilitators allows us to accept more people into our program. You’re also likely to reinforce what you’ve learned previously by reengaging with the content as a facilitator.&nbsp;<\/p><p>Apply to be a facilitator by <strong>Sunday, September 19th<\/strong>: <a href=\"https://efctv.org/EA-VP-facilitator-app\"><u>https://efctv.org/EA-VP-facilitator-app<\/u><\/a><\/p>","wordCount":211,"version":"1.0.0"},"Revision:uhrvYft2RYnhYbFmz_moderationGuidelines":{"_id":"uhrvYft2RYnhYbFmz_moderationGuidelines","__typename":"Revision","html":null},"Revision:uhrvYft2RYnhYbFmz_customHighlight":{"_id":"uhrvYft2RYnhYbFmz_customHighlight","__typename":"Revision","html":null},"User:sh3jdn9qrraLZpBJe":{"_id":"sh3jdn9qrraLZpBJe","__typename":"User","moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"yiyang","createdAt":"2021-07-27T10:11:57.396Z","username":"yiyang","displayName":"yiyang","fullName":null,"karma":8,"afKarma":null,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":4,"commentCount":1,"sequenceCount":null,"afPostCount":null,"afCommentCount":0,"spamRiskScore":0.9,"tagRevisionCount":null},"Post:uhrvYft2RYnhYbFmz":{"_id":"uhrvYft2RYnhYbFmz","__typename":"Post","contents":{"__ref":"Revision:uhrvYft2RYnhYbFmz_"},"moderationGuidelines":{"__ref":"Revision:uhrvYft2RYnhYbFmz_moderationGuidelines"},"customHighlight":{"__ref":"Revision:uhrvYft2RYnhYbFmz_customHighlight"},"lastPromotedComment":null,"bestAnswer":null,"tags":[],"url":null,"postedAt":"2021-09-15T13:00:08.591Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"shareWithUsers":null,"commentCount":null,"voteCount":2,"baseScore":2,"unlisted":false,"score":0.000595327853174213,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2021-09-15T13:00:08.591Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"sh3jdn9qrraLZpBJe","location":null,"googleLocation":null,"onlineEvent":true,"startTime":"2021-10-03T16:00:00.000Z","endTime":"2021-11-27T16:00:00.000Z","localStartTime":null,"localEndTime":null,"facebookLink":null,"meetupLink":null,"website":"https://www.effectivealtruism.org/virtual-programs/","contactInfo":"virtualprograms@effectivealtruism.org","isEvent":true,"types":["EA"],"reviewedByUserId":"qgdGA4ZEyW7zNdK84","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":null,"afCommentCount":null,"afLastCommentedAt":"2021-09-15T13:00:08.597Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":false,"shortform":false,"onlyVisibleToLoggedIn":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"group":null,"user":{"__ref":"User:sh3jdn9qrraLZpBJe"},"coauthors":[],"slug":"effective-altruism-virtual-programs-oct-nov-2021","title":"Effective Altruism Virtual Programs Oct-Nov 2021\n","draft":null,"hideCommentKarma":false,"af":false},"Revision:87D8yZAS53rNKoRXW_":{"_id":"87D8yZAS53rNKoRXW_","__typename":"Revision","htmlHighlight":"<p>The deadline for the <strong>Legal Topics in Effective Altruism<\/strong> program is coming up very soon! Register <strong>by this coming Sunday (October 10th)<\/strong>: <a href=\"https://efctv.org/EA-VP-legaltopics\"><u>https://efctv.org/EA-VP-legaltopics<\/u><\/a><\/p><p>We’ll also be hosting our usual virtual programs from November 1st to December 26th!&nbsp;<\/p><ul><li><strong>The Introductory EA Program<\/strong> aims to introduce the core ideas of effective altruism.<\/li><li><strong>The In-Depth EA Program <\/strong>seeks to engage participants with more complex questions to help them figure out how they can best make an impact.&nbsp;<\/li><li><i><strong>The Precipice <\/strong><\/i><strong>Reading Group<\/strong> explores the science behind the existential risks we face.&nbsp;<\/li><\/ul><p>Register <strong>by Sunday, October 24th<\/strong>: <a href=\"https://efctv.org/virtual-programs\"><u>https://efctv.org/virtual-programs<\/u><\/a><\/p><p>If you know anyone who might benefit from participating in any of these programs, please share this opportunity with them.&nbsp;<\/p><p>If you have participated in any fellowships, programs, or reading groups before, and are looking for ways to contribute to the EA community, please <strong>apply to be a facilitator<\/strong>! Getting more great facilitators allows us to accept more people into our program. You’re also likely to reinforce what you’ve learned previously by reengaging with the content as a facilitator.&nbsp;<\/p><p>Apply to be a facilitator by <strong>Sunday, October 17th<\/strong>: <a href=\"https://efctv.org/EA-VP-facilitator-app\"><u>https://efctv.org/EA-VP-facilitator-app<\/u><\/a><\/p>","wordCount":183,"version":"1.0.0"},"Revision:87D8yZAS53rNKoRXW_moderationGuidelines":{"_id":"87D8yZAS53rNKoRXW_moderationGuidelines","__typename":"Revision","html":null},"Revision:87D8yZAS53rNKoRXW_customHighlight":{"_id":"87D8yZAS53rNKoRXW_customHighlight","__typename":"Revision","html":null},"Revision:izp6eeJJEg9v5zcur_description":{"_id":"izp6eeJJEg9v5zcur_description","__typename":"Revision","htmlHighlight":"<p>The <strong>LessWrong<\/strong> <strong>Community <\/strong>is the people who write on LessWrong and who contribute to its mission of refining the art of human rationality. This tag includes community events, analysis of the health, norms and direction of the community, and space to understand communities in general.<br><br>LessWrong also has many brothers and sisters like the Berkeley Rationality Community, <a href=\"https://www.reddit.com/r/slatestarcodex/\">SlateStarCodex<\/a>, <a href=\"https://www.reddit.com/r/rational/\">Rational Fiction<\/a>, <a href=\"https://forum.effectivealtruism.org/\">Effective Altruism<\/a>, <a href=\"https://www.alignmentforum.org/\">AI Alignment<\/a>, and more, who participate here. To see upcoming LessWrong events, go to the <a href=\"https://www.lesswrong.com/community\">community section<\/a>.<\/p><hr><h2><strong>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Community Sub-Topics<\/strong><\/h2><figure style=\"width:100%;\"><table style=\"border-bottom:20px solid hsl(0, 0%, 100%);border-left:20px solid hsl(0, 0%, 100%);border-right:20px solid hsl(0, 0%, 100%);border-top:20px solid hsl(0, 0%, 100%);\"><tbody><tr><td style=\"background-color:hsl(0,0%,100%);border-bottom:solid hsl(0, 0%, 100%);border-left:solid hsl(0, 0%, 100%);border-right:solid hsl(0, 0%, 100%);border-top:solid hsl(0, 0%, 100%);padding:0px;vertical-align:top;width:50%;\"><p><strong>All<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/bounties-active?showPostCount=true&amp;useTagName=true\">Bounties (active)<\/a><br><a href=\"https://www.lesswrong.com/tag/grants-and-fundraising-opportunities?showPostCount=true\">Grants &amp; Fundraising<\/a><br><a href=\"http://www.lesswrong.com/tag/growth-stories?showPostCount=true&amp;useTagName=true\">Growth Stories<\/a><br><a href=\"https://www.lesswrong.com/tag/online-socialization?showPostCount=true&amp;useTagName=true\">Online Socialization<\/a><br><a href=\"https://www.lesswrong.com/tag/petrov-day?showPostCount=true&amp;useTagName=true\">Petrov Day<\/a><br><a href=\"https://www.lesswrong.com/tag/public-discourse?showPostCount=true&amp;useTagName=true\">Public Discourse<\/a><br><a href=\"https://www.lesswrong.com/tag/research-agendas?showPostCount=true&amp;useTagName=true\">Research Agendas<\/a><br><a href=\"https://www.lesswrong.com/tag/ritual?showPostCount=true&amp;useTagName=true\">Ritual<\/a><br><a href=\"https://www.lesswrong.com/tag/solstice-celebration?showPostCount=true&amp;useTagName=true\">Solstice Celebration<\/a><br>&nbsp;<\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border-bottom:1px solid hsl(0, 0%, 100%);border-left:1px solid hsl(0, 0%, 100%);border-right:1px solid hsl(0, 0%, 100%);border-top:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top;width:50%;\"><p><strong>LessWrong<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/events-community?showPostCount=true&amp;useTagName=true\">Events (Community)<\/a><br><a href=\"https://www.lesswrong.com/tag/site-meta?showPostCount=true&amp;useTagName=true\">Site Meta<\/a><br><a href=\"https://www.lesswrong.com/tag/greaterwrong-meta?showPostCount=true&amp;useTagName=true\">GreaterWrong Meta<\/a><br><a href=\"https://www.lesswrong.com/tag/lesswrong-events?showPostCount=true&amp;useTagName=true\">LessWrong Events<\/a><br><a href=\"http://www.lesswrong.com/tag/lw-moderation?showPostCount=true&amp;useTagName=true\">LW Moderation<\/a><br><a href=\"http://www.lesswrong.com/tag/meetups-topic?showPostCount=true&amp;useTagName=true\">Meetups (topic)<\/a><br><a href=\"http://www.lesswrong.com/tag/moderation-topic?showPostCount=true&amp;useTagName=true\">Moderation (topic)<\/a><br><a href=\"http://www.lesswrong.com/tag/the-sf-bay-area?showPostCount=true&amp;useTagName=true\">The SF Bay Area<\/a><br><a href=\"http://www.lesswrong.com/tag/tagging?showPostCount=true\">Tagging<\/a><\/p><\/td><\/tr><\/tbody><\/table><\/figure><p><i>Not all Community posts are tagged with subtopics.<\/i><\/p><hr><p>This tag applies to any post about:<\/p><ul><li>Specific projects, orgs, and prizes [e.g. <a href=\"http://www.lesswrong.com/posts/xFGQdgJndLcthgWoE\"><u>1<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/KgFrtaajjfSnBSZoH\"><u>2<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/auL2gAGTb3MsYhCeN\"><u>3<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/cSzaxcmeYW6z7cgtc\"><u>4<\/u><\/a>, <a href=\"https://www.lesswrong.com/posts/nDHbgjdddG5EN6ocg\"><u>5<\/u><\/a>]<\/li><li>Requests and offers for help [<a href=\"http://www.lesswrong.com/posts/bSWavBThj6ebB62gD\"><u>1<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/LuL7LLqcdmM7TTYvW\"><u>2<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/x72ta8C3dKu2QRfPv\"><u>3<\/u><\/a>]<\/li><li>Announcements, retrospectives, funding requests, and AMAs from orgs [<a href=\"http://www.lesswrong.com/posts/XJiNtvxoiLCpBn6FH\"><u>1<\/u><\/a> <a href=\"https://www.lesswrong.com/posts/96N8BT9tJvybLbn5z/we-run-the-center-for-applied-rationality-ama\"><u>2<\/u><\/a> <a href=\"http://www.lesswrong.com/posts/KgFrtaajjfSnBSZoH\"><u>3<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/auL2gAGTb3MsYhCeN\"><u>4<\/u><\/a>, <a href=\"https://www.lesswrong.com/posts/tCHsm5ZyAca8HfJSG\"><u>5<\/u><\/a>]<\/li><li>Discussions of the orgs in the LessWrong, Rationalist cluster [<a href=\"http://www.lesswrong.com/posts/KpnyCT7CZy4Qe6kx6\"><u>1<\/u><\/a>, <a href=\"https://www.lesswrong.com/posts/6SGqkCgHuNr7d4yJm/thoughts-on-the-singularity-institute-si\"><u>2<\/u><\/a>]<\/li><li>Discussions about the LessWrong, Rationalist, and related communities [<a href=\"http://www.lesswrong.com/posts/2Ee5DPBxowTTXZ6zf\"><u>1<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/yGycR8tFA3JJbvApp\"><u>2<\/u><\/a>, <a href=\"https://www.lesswrong.com/posts/zAqoj79A7QuhJKKvi\"><u>3<\/u><\/a>]<\/li><\/ul><p>While the <a href=\"https://www.lesswrong.com/tag/world-optimization\">World Optimization<\/a><i> <\/i>core tag is for posts discussing how to do good in general, the Community tag is for the specific, concrete efforts of our community to execute plans.<\/p>"},"Tag:izp6eeJJEg9v5zcur":{"_id":"izp6eeJJEg9v5zcur","__typename":"Tag","description":{"__ref":"Revision:izp6eeJJEg9v5zcur_description"},"name":"Community","slug":"community","core":true,"postCount":873,"adminOnly":false,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":15,"createdAt":"2020-06-14T03:38:34.631Z","wikiOnly":false},"Post:87D8yZAS53rNKoRXW":{"_id":"87D8yZAS53rNKoRXW","__typename":"Post","contents":{"__ref":"Revision:87D8yZAS53rNKoRXW_"},"moderationGuidelines":{"__ref":"Revision:87D8yZAS53rNKoRXW_moderationGuidelines"},"customHighlight":{"__ref":"Revision:87D8yZAS53rNKoRXW_customHighlight"},"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:izp6eeJJEg9v5zcur"}],"url":null,"postedAt":"2021-10-07T10:37:53.367Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"shareWithUsers":null,"commentCount":2,"voteCount":3,"baseScore":3,"unlisted":false,"score":0.001409484247757144,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2021-11-11T15:47:48.044Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"sh3jdn9qrraLZpBJe","location":null,"googleLocation":null,"onlineEvent":true,"startTime":"2021-10-31T16:00:00.000Z","endTime":"2021-12-25T16:00:00.000Z","localStartTime":null,"localEndTime":null,"facebookLink":null,"meetupLink":null,"website":"https://www.effectivealtruism.org/virtual-programs/","contactInfo":"virtualprograms@effectivealtruism.org","isEvent":true,"types":["EA"],"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":1,"afCommentCount":null,"afLastCommentedAt":"2021-10-07T10:37:53.367Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":false,"shortform":false,"onlyVisibleToLoggedIn":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"group":null,"user":{"__ref":"User:sh3jdn9qrraLZpBJe"},"coauthors":[],"slug":"effective-altruism-virtual-programs-nov-dec-2021","title":"Effective Altruism Virtual Programs Nov-Dec 2021","draft":null,"hideCommentKarma":false,"af":false},"Revision:rjQLfbMYYu4mSL9Co_":{"_id":"rjQLfbMYYu4mSL9Co_","__typename":"Revision","htmlHighlight":"<p><strong>Effective Altruism Virtual Programs<\/strong> will be hosting a new round of virtual programs for 8 weeks, from December 6th to January 30th!&nbsp;<\/p><ul><li><strong>The Introductory EA Program<\/strong> aims to introduce the core ideas of effective altruism.<\/li><li><strong>The In-Depth EA Program <\/strong>seeks to engage participants with more complex questions to help them figure out how they can best make an impact.<\/li><li><i><strong>The Precipice <\/strong><\/i><strong>Reading Group<\/strong> explores the science behind the existential risks we face.<\/li><\/ul><p>Register <strong>by Sunday, November 28th<\/strong>: <a href=\"https://efctv.org/virtual-programs\"><u>https://efctv.org/virtual-programs<\/u><\/a><\/p><p>If you know anyone who might benefit from participating in any of these programs, please share this opportunity with them.&nbsp;<\/p><p>If you have participated in any fellowships, programs, or reading groups before, and are looking for ways to contribute to the EA community, please <strong>apply to be a facilitator<\/strong>! Getting more great facilitators allows us to accept more people into our program. You’re also likely to reinforce what you’ve learned previously by reengaging with the content as a facilitator.&nbsp;<\/p><p>Apply to be a facilitator by <strong>Sunday, November 21st<\/strong>: <a href=\"https://efctv.org/EA-VP-facilitator-app\"><u>https://efctv.org/EA-VP-facilitator-app<\/u><\/a><\/p>","wordCount":169,"version":"1.0.0"},"Revision:rjQLfbMYYu4mSL9Co_moderationGuidelines":{"_id":"rjQLfbMYYu4mSL9Co_moderationGuidelines","__typename":"Revision","html":null},"Revision:rjQLfbMYYu4mSL9Co_customHighlight":{"_id":"rjQLfbMYYu4mSL9Co_customHighlight","__typename":"Revision","html":null},"Post:rjQLfbMYYu4mSL9Co":{"_id":"rjQLfbMYYu4mSL9Co","__typename":"Post","contents":{"__ref":"Revision:rjQLfbMYYu4mSL9Co_"},"moderationGuidelines":{"__ref":"Revision:rjQLfbMYYu4mSL9Co_moderationGuidelines"},"customHighlight":{"__ref":"Revision:rjQLfbMYYu4mSL9Co_customHighlight"},"lastPromotedComment":null,"bestAnswer":null,"tags":[],"url":null,"postedAt":"2021-11-11T15:50:37.817Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"shareWithUsers":null,"commentCount":null,"voteCount":2,"baseScore":3,"unlisted":false,"score":0.004054779694088209,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2021-11-11T15:50:37.817Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"sh3jdn9qrraLZpBJe","location":null,"googleLocation":null,"onlineEvent":true,"startTime":"2021-12-06T00:00:00.000Z","endTime":"2022-01-30T00:00:00.000Z","localStartTime":null,"localEndTime":null,"facebookLink":null,"meetupLink":null,"website":"https://www.effectivealtruism.org/virtual-programs/","contactInfo":"virtualprograms@effectivealtruism.org","isEvent":true,"types":["EA"],"reviewedByUserId":"qgdGA4ZEyW7zNdK84","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":null,"afCommentCount":null,"afLastCommentedAt":"2021-11-11T15:50:37.821Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":false,"shortform":false,"onlyVisibleToLoggedIn":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"group":null,"user":{"__ref":"User:sh3jdn9qrraLZpBJe"},"coauthors":[],"slug":"effective-altruism-virtual-programs-dec-jan-2022","title":"Effective Altruism Virtual Programs Dec-Jan 2022","draft":null,"hideCommentKarma":false,"af":false},"Revision:SKkR7Hp6JJPnKH8xJ_":{"_id":"SKkR7Hp6JJPnKH8xJ_","__typename":"Revision","htmlHighlight":"<p>Copied from <a href=\"https://portlandear.wordpress.com/2021/11/02/monthly-mailer-for-november/.\">https://portlandear.wordpress.com/2021/11/02/monthly-mailer-for-november/.<\/a> This is a Monthly Update on the Status of the Portland Effective Altruism and Rationality (PEAR) group. Below you will find a Recap, Updates on Events, and a Calendar for upcoming events in November.<br>&nbsp;<\/p><figure class=\"image\"><img src=\"https://portlandear.files.wordpress.com/2021/11/20211010_182740.jpg?w=1024\"><\/figure><p>&nbsp;<\/p><figure class=\"image\"><img src=\"https://portlandear.files.wordpress.com/2021/11/20211012_181447.jpg?w=1024\"><\/figure><h1><br><strong>September Recap<\/strong><\/h1><p>This month was a little more relaxed with around 4 events, with Dinners and Bi-Weeklies populating the schedule mostly. There were discussions about circling, woo, more prediction markets, teaching calculus, the Evolution of Art from <a href=\"https://astralcodexten.substack.com/p/whither-tartaria\">Abstract to Concrete<\/a>, and the <a href=\"https://plato.stanford.edu/entries/repugnant-conclusion/\">Repugnant Conclusion.<\/a><\/p><p>Also our conversation about \"The Precipice\" by Toby Ord led directly into talking about the difficulty of making predictions while living in this Most Important Century. While not the only book on this topic, a few members and myself would love to explore this topic further through the lens of Philip E Tetlock's book, \"<a href=\"https://www.amazon.com/Superforecasting-Science-Prediction-Philip-Tetlock/dp/0804136718\">Superforecasting<\/a>\". Hence, we are starting a book club once a week to discuss it on <a href=\"https://discord.gg/WzQwywt9R7\">Discord<\/a>. Please feel free to come even if you've read it before, it would be great to hear your thoughts about how some of the specific claims have panned out in your experience.<\/p><figure class=\"image\"><img src=\"https://portlandear.files.wordpress.com/2021/11/41cuxk1umzs.jpg?w=326\"><\/figure><p>Another cool thing I can see in PEAR's future is a <a href=\"https://www.meetup.com/Portland-Effective-Altruists-and-Rationalists/events/281642840/\"><strong>Nuclear Reactor Tour at Reed University on November 14th.<\/strong><\/a> Woot! I am really excited to see the reactor and we will send out a couple possibly nuclear related articles beforehand. Unfortunately, the tour can only accommodate up to 12 people and we already have 6+, please sign up soon for a spot! We will have a meet-up afterwards that you can still attend, even if you don't get a spot on the reactor tour.<\/p><h1><strong>Updates for October<\/strong><\/h1><p>1. Catering for Bi-Weeklies<\/p><p>Almost All Bi-weekly Events will have a variety of free, vegan, and possibly gluten free food at them from now on. Thank you EAIF!<\/p><p>2. Social Media<\/p><p>We have a <a href=\"https://www.meetup.com/Portland-Effective-Altruists-and-Rationalists\">Meet-up,<\/a> <a href=\"https://www.facebook.com/groups/436579296507956\">Facebook<\/a>, <a href=\"https://calendar.google.com/calendar/u/0/embed?src=i851csculvjngbnlg39a3jpovg@group.calendar.google.com&amp;ctz=America/Los_Angeles\">Google Calendar, <\/a><a href=\"https://portlandear.wordpress.com/\">Wordpress<\/a>, and a <a href=\"https://discord.gg/WzQwywt9R7\">Discord<\/a>. You choose your own adventure for updates related to PEAR events.<\/p><p>3. Logo Tweak<\/p><p>We are working on a more definitive Banner, and Emblem for a variety of Purposes. Drafts and Feedback are welcome on the discord!<\/p><h1><strong>Upcoming Events<\/strong><\/h1><p><a href=\"https://calendar.google.com/calendar/u/0/embed?src=i851csculvjngbnlg39a3jpovg@group.calendar.google.com&amp;ctz=America/Los_Angeles\">(public calendar)<\/a><\/p><p><a href=\"https://calendar.google.com/event?action=TEMPLATE&amp;tmeid=YzVqM2VkcjFjOG8zNGI5bTZrcm1jYjlrNzRxajZiOXA2Z3MzaWI5bmNwaTY0ZHI1Y2RnbWFwYjRjZ18yMDIxMTEwMVQyMzAwMDBaIGk4NTFjc2N1bHZqbmdibmxnMzlhM2pwb3ZnQGc&amp;tmsrc=i851csculvjngbnlg39a3jpovg%40group.calendar.google.com&amp;scp=ALL\">11/04:<\/a> PEAR Book Club: Superforecasting Week 1 (Discord)<\/p><p><a href=\"https://calendar.google.com/event?action=TEMPLATE&amp;tmeid=YzVqM2VkcjFjOG8zNGI5bTZrcm1jYjlrNzRxajZiOXA2Z3MzaWI5bmNwaTY0ZHI1Y2RnbWFwYjRjZ18yMDIxMTEwOVQwMDAwMDBaIGk4NTFjc2N1bHZqbmdibmxnMzlhM2pwb3ZnQGc&amp;tmsrc=i851csculvjngbnlg39a3jpovg%40group.calendar.google.com&amp;scp=ALL\">11/09<\/a>: PEAR Book Club: Superforecasting Week 2 (Discord<\/p><p><a href=\"https://calendar.google.com/event?action=TEMPLATE&amp;tmeid=Y2RpM2NkMzI2c3JqOGI5cDZnb2o2YjlrY2dzNmNiYjJja3NqYWJiNWM0b20ybzlrY2txamFlOXBjZyBpODUxY3NjdWx2am5nYm5sZzM5YTNqcG92Z0Bn&amp;tmsrc=i851csculvjngbnlg39a3jpovg%40group.calendar.google.com\">11/11:<\/a> PEAR dinner social at Piedmont Station<\/p><p><a href=\"https://calendar.google.com/event?action=TEMPLATE&amp;tmeid=M201ZW5qNnFvZ3N0bTNnbWtoZ282cmg4OTYgaTg1MWNzY3VsdmpuZ2JubGczOWEzanBvdmdAZw&amp;tmsrc=i851csculvjngbnlg39a3jpovg%40group.calendar.google.com\">11/14<\/a>: Nuclear Reactor Tour with Bi-Weekly Afterwards<\/p><p><a href=\"https://calendar.google.com/event?action=TEMPLATE&amp;tmeid=YzVqM2VkcjFjOG8zNGI5bTZrcm1jYjlrNzRxajZiOXA2Z3MzaWI5bmNwaTY0ZHI1Y2RnbWFwYjRjZ18yMDIxMTExNlQwMDAwMDBaIGk4NTFjc2N1bHZqbmdibmxnMzlhM2pwb3ZnQGc&amp;tmsrc=i851csculvjngbnlg39a3jpovg%40group.calendar.google.com&amp;scp=ALL\">11/18:<\/a> PEAR Book Club: Superforecasting Week 3 (Disc... <\/p>","wordCount":428,"version":"1.1.0"},"Revision:SKkR7Hp6JJPnKH8xJ_moderationGuidelines":{"_id":"SKkR7Hp6JJPnKH8xJ_moderationGuidelines","__typename":"Revision","html":null},"Revision:SKkR7Hp6JJPnKH8xJ_customHighlight":{"_id":"SKkR7Hp6JJPnKH8xJ_customHighlight","__typename":"Revision","html":null},"Localgroup:EbZXGajoX36MqtYz6":{"_id":"EbZXGajoX36MqtYz6","__typename":"Localgroup","name":"PEAR (Portland Effective Altruists and Rationalists)"},"User:ErCZs3qyg2nwvFwoS":{"_id":"ErCZs3qyg2nwvFwoS","__typename":"User","moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"smokeandmirrors","createdAt":"2021-03-30T00:24:10.766Z","username":"SmokeAndMirrors","displayName":"SmokeAndMirrors","fullName":"Sam Celarek","karma":10,"afKarma":null,"deleted":null,"isAdmin":false,"htmlBio":"<p>Nurse who likes to read philosophy and rationalist literature<\/p>\n","postCount":8,"commentCount":1,"sequenceCount":null,"afPostCount":null,"afCommentCount":0,"spamRiskScore":0.9,"tagRevisionCount":0},"Post:SKkR7Hp6JJPnKH8xJ":{"_id":"SKkR7Hp6JJPnKH8xJ","__typename":"Post","contents":{"__ref":"Revision:SKkR7Hp6JJPnKH8xJ_"},"moderationGuidelines":{"__ref":"Revision:SKkR7Hp6JJPnKH8xJ_moderationGuidelines"},"customHighlight":{"__ref":"Revision:SKkR7Hp6JJPnKH8xJ_customHighlight"},"lastPromotedComment":null,"bestAnswer":null,"tags":[],"url":null,"postedAt":"2021-11-03T00:25:48.992Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"shareWithUsers":null,"commentCount":null,"voteCount":1,"baseScore":1,"unlisted":false,"score":0.0007874500715682785,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2021-11-03T00:25:48.992Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"ErCZs3qyg2nwvFwoS","location":"Portland, OR, USA","googleLocation":{"address_components":[{"long_name":"Portland","short_name":"Portland","types":["locality","political"]},{"long_name":"Multnomah County","short_name":"Multnomah County","types":["administrative_area_level_2","political"]},{"long_name":"Oregon","short_name":"OR","types":["administrative_area_level_1","political"]},{"long_name":"United States","short_name":"US","types":["country","political"]}],"adr_address":"<span class=\"locality\">Portland<\/span>, <span class=\"region\">OR<\/span>, <span class=\"country-name\">USA<\/span>","formatted_address":"Portland, OR, USA","geometry":{"location":{"lat":45.515232,"lng":-122.6783853},"viewport":{"south":45.43254193035538,"west":-122.8367637732032,"north":45.65288600558634,"east":-122.4720384476617}},"icon":"https://maps.gstatic.com/mapfiles/place_api/icons/v1/png_71/geocode-71.png","icon_background_color":"#7B9EB0","icon_mask_base_uri":"https://maps.gstatic.com/mapfiles/place_api/icons/v2/generic_pinlet","name":"Portland","photos":[{"height":1816,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/100136668867830692526\">Jorge Mdz<\/a>"],"width":4032},{"height":3464,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/104959747536832829679\">Jonathan Grasty<\/a>"],"width":4618},{"height":333,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/101761043167656710925\">nurul hoque<\/a>"],"width":500},{"height":3024,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/103750046613121855666\">Doug Gross<\/a>"],"width":4032},{"height":1067,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/116224472159724268125\">Rangel Alvarado<\/a>"],"width":1600},{"height":1632,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/109410936877412813418\">Jose Gomez<\/a>"],"width":918},{"height":3265,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/117861683685898218953\">Jiun Liu<\/a>"],"width":2539},{"height":3024,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/105509754407100234481\">Gopinath Ravichandran<\/a>"],"width":4032},{"height":555,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/110342364909552630380\">Grant gamez<\/a>"],"width":986},{"height":3000,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/101818177497229793141\">Lívia Vidal<\/a>"],"width":4000}],"place_id":"ChIJJ3SpfQsLlVQRkYXR9ua5Nhw","reference":"ChIJJ3SpfQsLlVQRkYXR9ua5Nhw","types":["locality","political"],"url":"https://maps.google.com/?q=Portland,+OR,+USA&ftid=0x54950b0b7da97427:0x1c36b9e6f6d18591","utc_offset":-420,"vicinity":"Portland","website":"http://www.portlandonline.com/","html_attributions":[],"utc_offset_minutes":-420},"onlineEvent":false,"startTime":"2021-11-04T07:00:00.000Z","endTime":"2021-12-02T08:00:00.000Z","localStartTime":"2021-11-04T00:00:00.000Z","localEndTime":"2021-12-02T00:00:00.000Z","facebookLink":"https://www.facebook.com/groups/436579296507956","meetupLink":null,"website":"https://wordpress.com/post/portlandear.wordpress.com/167","contactInfo":"scelarek@gmail.com","isEvent":true,"types":["LW","SSC","EA"],"reviewedByUserId":null,"suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":null,"afCommentCount":null,"afLastCommentedAt":"2021-11-03T00:25:49.084Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":false,"shortform":false,"onlyVisibleToLoggedIn":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"group":{"__ref":"Localgroup:EbZXGajoX36MqtYz6"},"user":{"__ref":"User:ErCZs3qyg2nwvFwoS"},"coauthors":[],"slug":"monthly-mailer-for-november","title":"Monthly Mailer for November","draft":null,"hideCommentKarma":false,"af":false},"Revision:dCtiP8MstaYXro6A9_":{"_id":"dCtiP8MstaYXro6A9_","__typename":"Revision","htmlHighlight":"<p>Come to the Astral Codex Ten / Slate Star Codex Montreal Meetup. Enjoy the company of people who read the same blogs as you.<\/p><p>RSVPing on this page is strongly recommended as I will have to make a reservation at the restaurant.<\/p>","wordCount":41,"version":"1.0.0"},"Revision:dCtiP8MstaYXro6A9_moderationGuidelines":{"_id":"dCtiP8MstaYXro6A9_moderationGuidelines","__typename":"Revision","html":null},"Revision:dCtiP8MstaYXro6A9_customHighlight":{"_id":"dCtiP8MstaYXro6A9_customHighlight","__typename":"Revision","html":null},"User:Fbpu5FXaEtCeetGmh":{"_id":"Fbpu5FXaEtCeetGmh","__typename":"User","moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"e","createdAt":"2021-10-22T00:43:09.563Z","username":"E","displayName":"E","fullName":null,"karma":14,"afKarma":null,"deleted":null,"isAdmin":false,"htmlBio":null,"postCount":2,"commentCount":null,"sequenceCount":null,"afPostCount":null,"afCommentCount":0,"spamRiskScore":0.9,"tagRevisionCount":null},"Post:dCtiP8MstaYXro6A9":{"_id":"dCtiP8MstaYXro6A9","__typename":"Post","contents":{"__ref":"Revision:dCtiP8MstaYXro6A9_"},"moderationGuidelines":{"__ref":"Revision:dCtiP8MstaYXro6A9_moderationGuidelines"},"customHighlight":{"__ref":"Revision:dCtiP8MstaYXro6A9_customHighlight"},"lastPromotedComment":null,"bestAnswer":null,"tags":[],"url":null,"postedAt":"2021-11-20T17:49:26.901Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"shareWithUsers":null,"commentCount":null,"voteCount":2,"baseScore":7,"unlisted":false,"score":0.037777837295676735,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2021-11-20T17:49:26.901Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"Fbpu5FXaEtCeetGmh","location":"Mckibbins Irish Pub, Saint Laurent Boulevard, Montreal, QC, Canada","googleLocation":{"address_components":[{"long_name":"3515","short_name":"3515","types":["street_number"]},{"long_name":"Boulevard Saint-Laurent","short_name":"Boul. Saint-Laurent","types":["route"]},{"long_name":"Le Plateau-Mont-Royal","short_name":"Le Plateau-Mont-Royal","types":["sublocality_level_1","sublocality","political"]},{"long_name":"Montréal","short_name":"Montréal","types":["locality","political"]},{"long_name":"Communauté-Urbaine-de-Montréal","short_name":"Communauté-Urbaine-de-Montréal","types":["administrative_area_level_2","political"]},{"long_name":"Québec","short_name":"QC","types":["administrative_area_level_1","political"]},{"long_name":"Canada","short_name":"CA","types":["country","political"]},{"long_name":"H2X 2T6","short_name":"H2X 2T6","types":["postal_code"]}],"adr_address":"<span class=\"street-address\">3515 Boul. Saint-Laurent<\/span>, <span class=\"locality\">Montréal<\/span>, <span class=\"region\">QC<\/span> <span class=\"postal-code\">H2X 2T6<\/span>, <span class=\"country-name\">Canada<\/span>","business_status":"OPERATIONAL","formatted_address":"3515 Boul. Saint-Laurent, Montréal, QC H2X 2T6, Canada","formatted_phone_number":"(514) 282-1580","geometry":{"location":{"lat":45.5134992,"lng":-73.571102},"viewport":{"south":45.51206586970849,"west":-73.5725427302915,"north":45.51476383029149,"east":-73.5698447697085}},"icon":"https://maps.gstatic.com/mapfiles/place_api/icons/v1/png_71/bar-71.png","icon_background_color":"#FF9E67","icon_mask_base_uri":"https://maps.gstatic.com/mapfiles/place_api/icons/v2/bar_pinlet","international_phone_number":"+1 514-282-1580","name":"Mckibbins Irish Pub","opening_hours":{"open_now":true,"periods":[{"close":{"day":1,"time":"0300","hours":3,"minutes":0,"nextDate":1637568000000},"open":{"day":0,"time":"1030","hours":10,"minutes":30,"nextDate":1637508600000}},{"close":{"day":2,"time":"0300","hours":3,"minutes":0,"nextDate":1637654400000},"open":{"day":1,"time":"1130","hours":11,"minutes":30,"nextDate":1637598600000}},{"close":{"day":3,"time":"0300","hours":3,"minutes":0,"nextDate":1637740800000},"open":{"day":2,"time":"1130","hours":11,"minutes":30,"nextDate":1637685000000}},{"close":{"day":4,"time":"0300","hours":3,"minutes":0,"nextDate":1637827200000},"open":{"day":3,"time":"1130","hours":11,"minutes":30,"nextDate":1637771400000}},{"close":{"day":5,"time":"0300","hours":3,"minutes":0,"nextDate":1637913600000},"open":{"day":4,"time":"1130","hours":11,"minutes":30,"nextDate":1637857800000}},{"close":{"day":6,"time":"0300","hours":3,"minutes":0,"nextDate":1638000000000},"open":{"day":5,"time":"1130","hours":11,"minutes":30,"nextDate":1637944200000}},{"close":{"day":0,"time":"0300","hours":3,"minutes":0,"nextDate":1637481600000},"open":{"day":6,"time":"1030","hours":10,"minutes":30,"nextDate":1638027000000}}],"weekday_text":["Monday: 11:30 AM – 3:00 AM","Tuesday: 11:30 AM – 3:00 AM","Wednesday: 11:30 AM – 3:00 AM","Thursday: 11:30 AM – 3:00 AM","Friday: 11:30 AM – 3:00 AM","Saturday: 10:30 AM – 3:00 AM","Sunday: 10:30 AM – 3:00 AM"]},"photos":[{"height":533,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/113858966503338137494\">Mckibbins Irish Pub<\/a>"],"width":800},{"height":3024,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/100748270987408139647\">Nidhi Gupta<\/a>"],"width":4032},{"height":3456,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/113858966503338137494\">Mckibbins Irish Pub<\/a>"],"width":5184},{"height":2268,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/105000149631032322974\">Pierre Bindet<\/a>"],"width":4032},{"height":2988,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/117821966960341617770\">Stephan Pelletier<\/a>"],"width":3984},{"height":3456,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/113858966503338137494\">Mckibbins Irish Pub<\/a>"],"width":5184},{"height":2160,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/103553997350384226930\">Andrew Wilcox<\/a>"],"width":3840},{"height":3024,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/102759386988364639553\">Brice<\/a>"],"width":4032},{"height":3024,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/105741361266774339208\">waiho jang<\/a>"],"width":4032},{"height":4032,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/103348777236518782990\">Sai Niranjan<\/a>"],"width":3024}],"place_id":"ChIJ42NXYEoayUwRK1yRnKff4ro","plus_code":{"compound_code":"GC7H+9H Montreal, QC, Canada","global_code":"87Q8GC7H+9H"},"price_level":2,"rating":4.3,"reference":"ChIJ42NXYEoayUwRK1yRnKff4ro","reviews":[{"author_name":"Nidhi Gupta","author_url":"https://www.google.com/maps/contrib/100748270987408139647/reviews","language":"en","profile_photo_url":"https://lh3.googleusercontent.com/a-/AOh14GjxjrsoyGaMuMxp3K5bgWAy4pBiVr2X2HPgjWKYKA=s128-c0x00000000-cc-rp-mo-ba3","rating":5,"relative_time_description":"2 weeks ago","text":"Very nice pub with a good selection of cocktails, beer, wine, whiskey. Absolutely loved the cocktails we ordered. Halloween night had great young crowd, with live music by a budding singer. He took song requests from the audience as well. Overall a very nice and chill environment.","time":1635829276},{"author_name":"Jake Elliott","author_url":"https://www.google.com/maps/contrib/105113601548694011996/reviews","language":"en","profile_photo_url":"https://lh3.googleusercontent.com/a/AATXAJyyPRr1PtM-pRJCrXYv-WmvSBfpKCHeiAx3qSaJ=s128-c0x00000000-cc-rp-mo-ba4","rating":4,"relative_time_description":"a month ago","text":"Good place for a beer. Lots of options for a good price. The food however is expensive. 6 small wings for 15$ is a pretty steep price to pay!\nIrish pub atmosphere where I wold recommend for a beer after work.","time":1634565766},{"author_name":"Anabel Strickland","author_url":"https://www.google.com/maps/contrib/117283723449852242483/reviews","language":"en","profile_photo_url":"https://lh3.googleusercontent.com/a-/AOh14GjcVgOuzNYnF6LwT-ohndq0W88Fi0KFzkcKHHrS=s128-c0x00000000-cc-rp-mo","rating":5,"relative_time_description":"a month ago","text":"A restaurant where you will feel great with a successful interior design.  The service is fast and the waiters are very polite.  Their food is delicious.","time":1634673806},{"author_name":"Frejya Storm","author_url":"https://www.google.com/maps/contrib/108901940395919038478/reviews","language":"en","profile_photo_url":"https://lh3.googleusercontent.com/a-/AOh14GjKZoJPVFI8wPt93xNSm191iYJBuD7OtCcHgSLq=s128-c0x00000000-cc-rp-mo","rating":5,"relative_time_description":"a year ago","text":"Very good good and Nice service !!","time":1599711233},{"author_name":"Bryan","author_url":"https://www.google.com/maps/contrib/117487134413600780815/reviews","language":"en","profile_photo_url":"https://lh3.googleusercontent.com/a/AATXAJxqCch_VhQ9oJdj2leTGcoRAqLIiMIYgOdjvGzc=s128-c0x00000000-cc-rp-mo-ba4","rating":4,"relative_time_description":"a month ago","text":"Solid pub for drinks and to watch sports. Nothing crazy good or bad to say about it, the foods like pub food so greasy and tasty but not out of this world. And they do have a good selection of beers which is awesome","time":1634751412}],"types":["bar","restaurant","food","point_of_interest","establishment"],"url":"https://maps.google.com/?cid=13466571746770508843","user_ratings_total":1991,"utc_offset":-300,"vicinity":"3515 Boulevard Saint-Laurent, Montréal","website":"http://www.mckibbinsirishpub.com/menu.asp","html_attributions":[],"utc_offset_minutes":-300},"onlineEvent":false,"startTime":"2021-12-04T19:00:00.000Z","endTime":null,"localStartTime":"2021-12-04T14:00:00.000Z","localEndTime":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":"90u610sye@relay.firefox.com","isEvent":true,"types":["SSC"],"reviewedByUserId":"qgdGA4ZEyW7zNdK84","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":null,"afCommentCount":null,"afLastCommentedAt":"2021-11-20T17:49:26.967Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":false,"shortform":false,"onlyVisibleToLoggedIn":false,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"group":null,"user":{"__ref":"User:Fbpu5FXaEtCeetGmh"},"coauthors":[],"slug":"acx-montreal-meetup-dec-4-2021","title":"ACX Montreal Meetup Dec 4 2021","draft":null,"hideCommentKarma":false,"af":false},"Revision:zgAaFcyrHn3PbxGh7_":{"_id":"zgAaFcyrHn3PbxGh7_","__typename":"Revision","htmlHighlight":"<p><i><strong>Potential Change of Location Notice:<\/strong> Location might change to nearby Ilmarin House. If that happens, I will announce it here by late morning of meetup day.<\/i><\/p><p>This is a relaxed Saturday afternoon gathering at Washington Park (if conditions are favorable) or Ilmarin House (if not).&nbsp;<\/p><p><strong>Location (verbose):&nbsp;<\/strong><br>On the roundish grassy area in the northeast corner of Washington Park, 840 W Washington Ave. We'll have a dark blue picnic blanket and a ACX/LW Meetup sign. – <a href=\"https://what3words.com////island.economies.coach\">///island.economies.coach<\/a>&nbsp;<\/p><p><strong>Things to maybe bring:<\/strong><br>It will likely be somewhat chilly so it probably makes sense to wear a sweater or jacket. As mentioned, there is a picnic blanket to sit down on but if you want to make sure you don't have to stand you might want to bring your own or a camping chair. Some snacks will be available but you're welcome to bring some, too.<\/p><p><strong>More:<\/strong><br>If you’re reading this, you’re invited! Bring friends if you think they’d enjoy the event. Kids are welcome! Please <a href=\"https://www.lesswrong.com/events/zgAaFcyrHn3PbxGh7/south-bay-acx-lw-meetup\">RSVP<\/a> if you haven’t already (but if you don’t manage to do that in time we’re happy to have you anyway).&nbsp;<br>If you have other questions/concerns, please let me know at <a href=\"mailto:svmeetup@protonmail.com\">svmeetup@protonmail.com<\/a> or leave a comment.<\/p>","wordCount":200,"version":"1.2.0"},"Revision:zgAaFcyrHn3PbxGh7_moderationGuidelines":{"_id":"zgAaFcyrHn3PbxGh7_moderationGuidelines","__typename":"Revision","html":null},"Revision:zgAaFcyrHn3PbxGh7_customHighlight":{"_id":"zgAaFcyrHn3PbxGh7_customHighlight","__typename":"Revision","html":null},"User:RgjQonH2h7P24FZx9":{"_id":"RgjQonH2h7P24FZx9","__typename":"User","moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"is","createdAt":"2021-08-23T08:51:37.689Z","username":"is","displayName":"IS","fullName":null,"karma":26,"afKarma":null,"deleted":null,"isAdmin":false,"htmlBio":null,"postCount":3,"commentCount":null,"sequenceCount":null,"afPostCount":null,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":null},"Post:zgAaFcyrHn3PbxGh7":{"_id":"zgAaFcyrHn3PbxGh7","__typename":"Post","contents":{"__ref":"Revision:zgAaFcyrHn3PbxGh7_"},"moderationGuidelines":{"__ref":"Revision:zgAaFcyrHn3PbxGh7_moderationGuidelines"},"customHighlight":{"__ref":"Revision:zgAaFcyrHn3PbxGh7_customHighlight"},"lastPromotedComment":null,"bestAnswer":null,"tags":[],"url":null,"postedAt":"2021-11-20T14:42:39.201Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"shareWithUsers":["sJv7yzCp5xfWBAPvG","7S6LWpQwJ25XWHJE8"],"commentCount":null,"voteCount":2,"baseScore":10,"unlisted":false,"score":0.051901818997517925,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2021-11-20T14:42:39.201Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"RgjQonH2h7P24FZx9","location":"840 West Washington Avenue, Sunnyvale, CA, USA","googleLocation":{"address_components":[{"long_name":"840","short_name":"840","types":["street_number"]},{"long_name":"West Washington Avenue","short_name":"W Washington Ave","types":["route"]},{"long_name":"Sunnyvale West","short_name":"Sunnyvale West","types":["neighborhood","political"]},{"long_name":"Sunnyvale","short_name":"Sunnyvale","types":["locality","political"]},{"long_name":"Santa Clara County","short_name":"Santa Clara County","types":["administrative_area_level_2","political"]},{"long_name":"California","short_name":"CA","types":["administrative_area_level_1","political"]},{"long_name":"United States","short_name":"US","types":["country","political"]},{"long_name":"94086","short_name":"94086","types":["postal_code"]}],"adr_address":"<span class=\"street-address\">840 W Washington Ave<\/span>, <span class=\"locality\">Sunnyvale<\/span>, <span class=\"region\">CA<\/span> <span class=\"postal-code\">94086<\/span>, <span class=\"country-name\">USA<\/span>","formatted_address":"840 W Washington Ave, Sunnyvale, CA 94086, USA","geometry":{"location":{"lat":37.3775726,"lng":-122.0394845},"viewport":{"south":37.3763869197085,"west":-122.0407790302915,"north":37.3790848802915,"east":-122.0380810697085}},"icon":"https://maps.gstatic.com/mapfiles/place_api/icons/v1/png_71/geocode-71.png","icon_background_color":"#7B9EB0","icon_mask_base_uri":"https://maps.gstatic.com/mapfiles/place_api/icons/v2/generic_pinlet","name":"840 W Washington Ave","place_id":"ChIJVxUUOfa2j4ARfUKKiIHjXIQ","reference":"ChIJVxUUOfa2j4ARfUKKiIHjXIQ","types":["premise"],"url":"https://maps.google.com/?q=840+W+Washington+Ave,+Sunnyvale,+CA+94086,+USA&ftid=0x808fb6f639141557:0x845ce381888a427d","utc_offset":-480,"vicinity":"Sunnyvale","html_attributions":[],"utc_offset_minutes":-480},"onlineEvent":false,"startTime":"2021-12-04T21:30:00.000Z","endTime":"2021-12-05T00:30:00.000Z","localStartTime":"2021-12-04T13:30:00.000Z","localEndTime":"2021-12-04T16:30:00.000Z","facebookLink":null,"meetupLink":null,"website":null,"contactInfo":"svmeetup@protonmail.com","isEvent":true,"types":["LW","SSC"],"reviewedByUserId":"qgdGA4ZEyW7zNdK84","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":2,"afCommentCount":null,"afLastCommentedAt":"2021-11-17T18:38:53.533Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":false,"shortform":false,"onlyVisibleToLoggedIn":false,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"group":null,"user":{"__ref":"User:RgjQonH2h7P24FZx9"},"coauthors":[],"slug":"south-bay-acx-lw-meetup","title":"South Bay ACX/LW Meetup","draft":null,"hideCommentKarma":false,"af":false},"User:2aoRX3ookcCozcb3m":{"_id":"2aoRX3ookcCozcb3m","__typename":"User","slug":"robbbb","createdAt":"2012-08-10T00:50:11.669Z","username":"RobbBB","displayName":"Rob Bensinger","fullName":null,"karma":13271,"afKarma":632,"deleted":false,"isAdmin":true,"htmlBio":"<p>Communications lead at MIRI. Unless otherwise indicated, my posts and comments here reflect my own views, and not necessarily my employer's.<\/p>\n","postCount":104,"commentCount":1627,"sequenceCount":3,"afPostCount":7,"afCommentCount":74,"spamRiskScore":1,"tagRevisionCount":110},"Revision:n945eovrA3oDueqtq_":{"_id":"n945eovrA3oDueqtq_","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2021-11-16T15:16:53.933Z","userId":"2aoRX3ookcCozcb3m","html":"<p>This sequence is a (chronological) series of chatroom conversation logs about artificial general intelligence (AGI). A large number of topics are covered, beginning with conversations related to alignment difficulty.<\/p><p>Rob Bensinger edited and posted this sequence, and Matthew Graves helped with much of the formatting.<\/p>","wordCount":44,"htmlHighlight":"<p>This sequence is a (chronological) series of chatroom conversation logs about artificial general intelligence (AGI). A large number of topics are covered, beginning with conversations related to alignment difficulty.<\/p><p>Rob Bensinger edited and posted this sequence, and Matthew Graves helped with much of the formatting.<\/p>","plaintextDescription":"This sequence is a (chronological) series of chatroom conversation logs about\nartificial general intelligence (AGI). A large number of topics are covered,\nbeginning with conversations related to alignment difficulty.\n\nRob Bensinger edited and posted this sequence, and Matthew Graves helped with\nmuch of the formatting."},"Sequence:n945eovrA3oDueqtq":{"_id":"n945eovrA3oDueqtq","__typename":"Sequence","createdAt":"2021-11-15T21:08:28.070Z","userId":"2aoRX3ookcCozcb3m","user":{"__ref":"User:2aoRX3ookcCozcb3m"},"contents":{"__ref":"Revision:n945eovrA3oDueqtq_"},"gridImageId":"sequencesgrid/gpk2pxurl1yymecllfoo","bannerImageId":"sequences/zenshq6ta1cmqiaisfka","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":null,"userProfileOrder":null,"af":true,"title":"Late 2021 MIRI Conversations"},"User:r38pkCm7wF4M44MDQ":{"_id":"r38pkCm7wF4M44MDQ","__typename":"User","slug":"raemon","createdAt":"2010-09-09T02:09:20.629Z","username":"Raemon","displayName":"Raemon","fullName":"Raymond Arnold","karma":31704,"afKarma":208,"deleted":false,"isAdmin":true,"htmlBio":"<p>I've been a LessWrong organizer since 2011, with roughly equal focus on the cultural, practical and intellectual aspects of the community. My first project was creating the Secular Solstice and helping groups across the world run their own version of it. More recently I've been interested in improving my own epistemic standards and helping others to do so as well.<\/p>\n","postCount":363,"commentCount":5682,"sequenceCount":20,"afPostCount":1,"afCommentCount":82,"spamRiskScore":1,"tagRevisionCount":141},"Revision:skRvz2mmvhLwhHbaN_":{"_id":"skRvz2mmvhLwhHbaN_","__typename":"Revision","version":null,"updateType":null,"editedAt":"2021-11-24T14:28:57.617Z","userId":null,"html":null,"wordCount":null,"htmlHighlight":"","plaintextDescription":null},"Sequence:skRvz2mmvhLwhHbaN":{"_id":"skRvz2mmvhLwhHbaN","__typename":"Sequence","createdAt":"2021-11-05T22:07:06.773Z","userId":"r38pkCm7wF4M44MDQ","user":{"__ref":"User:r38pkCm7wF4M44MDQ"},"contents":{"__ref":"Revision:skRvz2mmvhLwhHbaN_"},"gridImageId":"sequencesgrid/ok0a9errlxdskjjt9clx","bannerImageId":"sequences/l5eppu2udwa2s1u3b9nu","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":null,"userProfileOrder":null,"af":null,"title":"Curiosity"},"Revision:JdAfXBx4gS3DjN5s6_":{"_id":"JdAfXBx4gS3DjN5s6_","__typename":"Revision","version":null,"updateType":null,"editedAt":"2021-11-24T14:28:57.617Z","userId":null,"html":null,"wordCount":null,"htmlHighlight":"","plaintextDescription":null},"Sequence:JdAfXBx4gS3DjN5s6":{"_id":"JdAfXBx4gS3DjN5s6","__typename":"Sequence","createdAt":"2021-11-05T22:04:57.995Z","userId":"r38pkCm7wF4M44MDQ","user":{"__ref":"User:r38pkCm7wF4M44MDQ"},"contents":{"__ref":"Revision:JdAfXBx4gS3DjN5s6_"},"gridImageId":"sequencesgrid/jfe2adg6svmk60w9mrno","bannerImageId":"sequences/sh1n6yrk9gfw1qt6puyj","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":null,"userProfileOrder":null,"af":null,"title":"Coordination"},"Revision:bjewXnagXTjeGPtHx_":{"_id":"bjewXnagXTjeGPtHx_","__typename":"Revision","version":null,"updateType":null,"editedAt":"2021-11-24T14:28:57.617Z","userId":null,"html":null,"wordCount":null,"htmlHighlight":"","plaintextDescription":null},"Sequence:bjewXnagXTjeGPtHx":{"_id":"bjewXnagXTjeGPtHx","__typename":"Sequence","createdAt":"2021-11-05T22:02:34.307Z","userId":"r38pkCm7wF4M44MDQ","user":{"__ref":"User:r38pkCm7wF4M44MDQ"},"contents":{"__ref":"Revision:bjewXnagXTjeGPtHx_"},"gridImageId":"sequencesgrid/dtmq79bnplqvs2hwu8bz","bannerImageId":"sequences/mv4he1xhyzyw4ngd7xy5","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":null,"userProfileOrder":null,"af":null,"title":"Agency"},"Revision:Pavm47mqgjDAF7XYT_":{"_id":"Pavm47mqgjDAF7XYT_","__typename":"Revision","version":null,"updateType":null,"editedAt":"2021-11-24T14:28:57.617Z","userId":null,"html":null,"wordCount":null,"htmlHighlight":"","plaintextDescription":null},"Sequence:Pavm47mqgjDAF7XYT":{"_id":"Pavm47mqgjDAF7XYT","__typename":"Sequence","createdAt":"2021-11-05T22:01:18.790Z","userId":"r38pkCm7wF4M44MDQ","user":{"__ref":"User:r38pkCm7wF4M44MDQ"},"contents":{"__ref":"Revision:Pavm47mqgjDAF7XYT_"},"gridImageId":"sequencesgrid/g93xchw441hctqffduzf","bannerImageId":"sequences/kipnjsxdkeutlaawxpev","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":null,"userProfileOrder":null,"af":null,"title":"Epistemology"},"Revision:QyQcBpSur9SFyRuvB_":{"_id":"QyQcBpSur9SFyRuvB_","__typename":"Revision","version":null,"updateType":null,"editedAt":"2021-11-24T14:28:57.617Z","userId":null,"html":null,"wordCount":null,"htmlHighlight":"","plaintextDescription":null},"Sequence:QyQcBpSur9SFyRuvB":{"_id":"QyQcBpSur9SFyRuvB","__typename":"Sequence","createdAt":"2021-11-05T21:53:24.644Z","userId":"r38pkCm7wF4M44MDQ","user":{"__ref":"User:r38pkCm7wF4M44MDQ"},"contents":{"__ref":"Revision:QyQcBpSur9SFyRuvB_"},"gridImageId":"sequencesgrid/xrcvu7vroxuzezgy06xu","bannerImageId":"sequences/mzuxvjzylni34tydsdcw","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":null,"userProfileOrder":null,"af":null,"title":"Alignment"},"User:ypbkRWpFgPgzvNg3n":{"_id":"ypbkRWpFgPgzvNg3n","__typename":"User","slug":"adamshimi","createdAt":"2018-02-04T13:28:06.981Z","username":"adamShimi","displayName":"adamShimi","fullName":"Adam Shimi","karma":3197,"afKarma":1056,"deleted":null,"isAdmin":false,"htmlBio":"<p>Full time independent deconfusion researcher (<a href=\"https://www.alignmentforum.org/posts/5Nz4PJgvLCpJd6YTA/looking-deeper-at-deconfusion\">https://www.alignmentforum.org/posts/5Nz4PJgvLCpJd6YTA/looking-deeper-at-deconfusion<\/a>) in AI Alignment. (Also PhD in the theory of distributed computing).<\/p>\n<p>If you're interested by some research ideas that you see in my posts, know that I keep private docs with the most compressed version of my deconfusion ideas in the process of getting feedback. I can give you access if you PM me!<\/p>\n<p>A list of topics I'm currently doing deconfusion on:<\/p>\n<ul>\n<li>Goal-directedness for discussing AI Risk<\/li>\n<li>Myopic Decision Theories for dealing with deception (with Evan Hubinger)<\/li>\n<li>Universality for many alignment ideas of Paul Christiano<\/li>\n<li>Deconfusion itself to get better at it<\/li>\n<li>Models of Languages Models to clarify the alignment issues surrounding them.<\/li>\n<\/ul>\n","postCount":57,"commentCount":686,"sequenceCount":7,"afPostCount":40,"afCommentCount":339,"spamRiskScore":1,"tagRevisionCount":3},"Revision:LLEJJoaYpCoS5JYSY_":{"_id":"LLEJJoaYpCoS5JYSY_","__typename":"Revision","version":"1.0.0","updateType":"initial","editedAt":"2021-10-18T09:05:44.707Z","userId":"ypbkRWpFgPgzvNg3n","html":"<p>Sequence of post analyzing the <a href=\"https://www.alignmentforum.org/posts/FQqcejhNWGG8vHDch/on-solving-problems-before-they-appear-the-weird\">epistemic strategies<\/a> of specific alignment research results.<\/p>","wordCount":12,"htmlHighlight":"<p>Sequence of post analyzing the <a href=\"https://www.alignmentforum.org/posts/FQqcejhNWGG8vHDch/on-solving-problems-before-they-appear-the-weird\">epistemic strategies<\/a> of specific alignment research results.<\/p>","plaintextDescription":"Sequence of post analyzing the epistemic strategies of specific alignment\nresearch results."},"Sequence:LLEJJoaYpCoS5JYSY":{"_id":"LLEJJoaYpCoS5JYSY","__typename":"Sequence","createdAt":"2021-10-18T09:05:44.452Z","userId":"ypbkRWpFgPgzvNg3n","user":{"__ref":"User:ypbkRWpFgPgzvNg3n"},"contents":{"__ref":"Revision:LLEJJoaYpCoS5JYSY_"},"gridImageId":"sequencesgrid/j3kqlrz4cpyilodutaz0","bannerImageId":"sequences/iiod6pgfnzlfdgy9w3wt","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":null,"userProfileOrder":null,"af":true,"title":"Epistemic Cookbook for Alignment"},"User:PyrbjCRhwhh6LwQCZ":{"_id":"PyrbjCRhwhh6LwQCZ","__typename":"User","slug":"lennart","createdAt":"2021-07-21T16:12:50.604Z","username":"lennart","displayName":"lennart","fullName":"Lennart Heim","karma":46,"afKarma":null,"deleted":null,"isAdmin":false,"htmlBio":"<p>Lennart Heim | Zürich, Switzerland |\n<a href=\"https://heim.xyz\">Personal Website<\/a> |\n<a href=\"https://www.linkedin.com/in/lennartheim/\">LinkedIn<\/a> |\n<a href=\"https://twitter.com/ohlennart\">Twitter<\/a> |\n<a href=\"mailto:len+EA@heim.xyz\">len+EA@heim.xyz<\/a> |<\/p>\n","postCount":4,"commentCount":3,"sequenceCount":1,"afPostCount":null,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":null},"Revision:bJi3hd8E8qjBeHz9Z_":{"_id":"bJi3hd8E8qjBeHz9Z_","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2021-09-23T14:10:00.614Z","userId":"PyrbjCRhwhh6LwQCZ","html":"<p>Modern progress in AI systems has been driven and enabled mainly by acquiring more computational resources. AI systems rely on computation-intensive training runs — they require massive amounts of <em>compute<\/em>.<\/p>\n<p>Learning about the compute requirements for training existing AI systems and their capabilities allows us to get a more nuanced understanding and take appropriate action within the technical and governance domain to enable a safe development of potential transformative AI systems.<\/p>\n<p>To understand the role of compute, I decided to (a) do a literature review, (b) update existing work with new data, (c) investigate the role of compute for timelines, and lastly, (d) explore concepts to enhance our analysis and forecasting efforts.<\/p>\n<p>In this sequence, I present a brief analysis of AI systems’ compute requirements and capabilities, explore compute’s role for transformative AI timelines, and lastly, discuss the compute governance domain.<\/p>\n","wordCount":138,"htmlHighlight":"<p>Modern progress in AI systems has been driven and enabled mainly by acquiring more computational resources. AI systems rely on computation-intensive training runs — they require massive amounts of <em>compute<\/em>.<\/p>\n<p>Learning about the compute requirements for training existing AI systems and their capabilities allows us to get a more nuanced understanding and take appropriate action within the technical and governance domain to enable a safe development of potential transformative AI systems.<\/p>\n<p>To understand the role of compute, I decided to (a) do a literature review, (b) update existing work with new data, (c) investigate the role of compute for timelines, and lastly, (d) explore concepts to enhance our analysis and forecasting efforts.<\/p>\n<p>In this sequence, I present a brief analysis of AI systems’ compute requirements and capabilities, explore compute’s role for transformative AI timelines, and lastly, discuss the compute governance domain.<\/p>","plaintextDescription":"Modern progress in AI systems has been driven and enabled mainly by acquiring\nmore computational resources. AI systems rely on computation-intensive training\nruns — they require massive amounts of compute.\n\nLearning about the compute requirements for training existing AI systems and\ntheir capabilities allows us to get a more nuanced understanding and take\nappropriate action within the technical and governance domain to enable a safe\ndevelopment of potential transformative AI systems.\n\nTo understand the role of compute, I decided to (a) do a literature review, (b)\nupdate existing work with new data, (c) investigate the role of compute for\ntimelines, and lastly, (d) explore concepts to enhance our analysis and\nforecasting efforts.\n\nIn this sequence, I present a brief analysis of AI systems’ compute requirements\nand capabilities, explore compute’s role for transformative AI timelines, and\nlastly, discuss the compute governance domain."},"Sequence:bJi3hd8E8qjBeHz9Z":{"_id":"bJi3hd8E8qjBeHz9Z","__typename":"Sequence","createdAt":"2021-09-23T14:00:53.564Z","userId":"PyrbjCRhwhh6LwQCZ","user":{"__ref":"User:PyrbjCRhwhh6LwQCZ"},"contents":{"__ref":"Revision:bJi3hd8E8qjBeHz9Z_"},"gridImageId":"sequencesgrid/urllfotmjrjlirssmxvb","bannerImageId":"sequences/jqxdxjf0amcgylbnfkj7","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":null,"userProfileOrder":null,"af":null,"title":"Transformative AI and Compute"},"User:uCfjEXpnchoqDWNoL":{"_id":"uCfjEXpnchoqDWNoL","__typename":"User","slug":"stuart_armstrong","createdAt":"2009-03-26T10:25:39.189Z","username":"Stuart_Armstrong","displayName":"Stuart_Armstrong","fullName":"Stuart Armstrong","karma":16128,"afKarma":1336,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":654,"commentCount":3607,"sequenceCount":5,"afPostCount":334,"afCommentCount":371,"spamRiskScore":1,"tagRevisionCount":12},"Revision:xujLGRKFLKsPCTimd_":{"_id":"xujLGRKFLKsPCTimd_","__typename":"Revision","version":"1.0.0","updateType":"minor","editedAt":"2021-09-20T12:19:17.469Z","userId":"uCfjEXpnchoqDWNoL","html":"<p>There are the AI safety subprojects designed for elucidating \"model splintering\" and \"learning the preferences of irrational agents\".<\/p>\n","wordCount":18,"htmlHighlight":"<p>There are the AI safety subprojects designed for elucidating \"model splintering\" and \"learning the preferences of irrational agents\".<\/p>","plaintextDescription":"There are the AI safety subprojects designed for elucidating \"model splintering\"\nand \"learning the preferences of irrational agents\"."},"Sequence:xujLGRKFLKsPCTimd":{"_id":"xujLGRKFLKsPCTimd","__typename":"Sequence","createdAt":"2021-09-20T12:18:37.872Z","userId":"uCfjEXpnchoqDWNoL","user":{"__ref":"User:uCfjEXpnchoqDWNoL"},"contents":{"__ref":"Revision:xujLGRKFLKsPCTimd_"},"gridImageId":"sequencesgrid/kxuwii95ftf9rqlhh8u4","bannerImageId":"sequences/q8ognyityumvwrwnv7n4","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":null,"userProfileOrder":null,"af":true,"title":"AI Safety Subprojects"},"User:PP7az7eYwbRgLd99e":{"_id":"PP7az7eYwbRgLd99e","__typename":"User","slug":"abstractapplic","createdAt":"2018-01-02T00:11:42.904Z","username":"abstractapplic","displayName":"abstractapplic","fullName":null,"karma":600,"afKarma":0,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":23,"commentCount":56,"sequenceCount":1,"afPostCount":0,"afCommentCount":null,"spamRiskScore":1,"tagRevisionCount":0},"Revision:gDiScDuMrWNpzwNSJ_":{"_id":"gDiScDuMrWNpzwNSJ_","__typename":"Revision","version":"1.5.0","updateType":"minor","editedAt":"2021-09-11T20:23:52.394Z","userId":"PP7az7eYwbRgLd99e","html":"<p>A series of Data Science and Analysis challenges, presented as decision problems in a fantasy setting.<\/p><p>Note: This sequence collects all D&amp;D.Sci scenarios I made which both can and should be replayed. It <i>doesn't<\/i> include <a href=\"https://www.lesswrong.com/posts/ycG3mrtdqddCkK9et/d-and-d-sci-pathfinder-return-of-the-gray-swan\">Return of the Gray Swan<\/a> (because that was created by someone else), <a href=\"https://www.lesswrong.com/posts/kmZjtuo4Gzv5WhTTX/a-d-and-d-sci-may-2021-interdimensional-monster-carcass\">Interdimensional Monster Carcass Auction<\/a> (because that was a one-time event), or <a href=\"https://www.lesswrong.com/posts/pTB58QeNkDMKPjAiv/d-and-d-sci-iii-mancer-matchups\">Mancer Matchups<\/a> (because that wasn't up to my standards).<\/p>","wordCount":66,"htmlHighlight":"<p>A series of Data Science and Analysis challenges, presented as decision problems in a fantasy setting.<\/p><p>Note: This sequence collects all D&amp;D.Sci scenarios I made which both can and should be replayed. It <i>doesn't<\/i> include <a href=\"https://www.lesswrong.com/posts/ycG3mrtdqddCkK9et/d-and-d-sci-pathfinder-return-of-the-gray-swan\">Return of the Gray Swan<\/a> (because that was created by someone else), <a href=\"https://www.lesswrong.com/posts/kmZjtuo4Gzv5WhTTX/a-d-and-d-sci-may-2021-interdimensional-monster-carcass\">Interdimensional Monster Carcass Auction<\/a> (because that was a one-time event), or <a href=\"https://www.lesswrong.com/posts/pTB58QeNkDMKPjAiv/d-and-d-sci-iii-mancer-matchups\">Mancer Matchups<\/a> (because that wasn't up to my standards).<\/p>","plaintextDescription":"A series of Data Science and Analysis challenges, presented as decision problems\nin a fantasy setting.\n\nNote: This sequence collects all D&D.Sci scenarios I made which both can and\nshould be replayed. It doesn't include Return of the Gray Swan (because that was\ncreated by someone else), Interdimensional Monster Carcass Auction (because that\nwas a one-time event), or Mancer Matchups (because that wasn't up to my\nstandards)."},"Sequence:gDiScDuMrWNpzwNSJ":{"_id":"gDiScDuMrWNpzwNSJ","__typename":"Sequence","createdAt":"2021-09-11T20:02:21.540Z","userId":"PP7az7eYwbRgLd99e","user":{"__ref":"User:PP7az7eYwbRgLd99e"},"contents":{"__ref":"Revision:gDiScDuMrWNpzwNSJ_"},"gridImageId":"sequencesgrid/mckwcocoomsz3kav1rhe","bannerImageId":"sequences/nvxsjahz1ke0kscwpaw1","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":null,"userProfileOrder":null,"af":null,"title":"D&D.Sci"},"User:kdeMdATaSc2MZKmdH":{"_id":"kdeMdATaSc2MZKmdH","__typename":"User","slug":"holdenkarnofsky","createdAt":"2009-12-30T00:19:32.818Z","username":"HoldenKarnofsky","displayName":"HoldenKarnofsky","fullName":null,"karma":1080,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":10,"commentCount":18,"sequenceCount":1,"afPostCount":null,"afCommentCount":null,"spamRiskScore":1,"tagRevisionCount":0},"Revision:yYxggfHYRrqnJXuRx_":{"_id":"yYxggfHYRrqnJXuRx_","__typename":"Revision","version":"1.0.0","updateType":"minor","editedAt":"2021-09-03T20:20:26.489Z","userId":"qgdGA4ZEyW7zNdK84","html":"<p>I think we have good reason to believe that the <strong>21st century could be the most important century ever for humanity.<\/strong> I think the most likely way this would happen would be via the development of advanced AI systems that lead to explosive growth and scientific advancement, getting us more quickly than most people imagine to a deeply unfamiliar future.<\/p><p>A bit more specifically,<a href=\"https://www.lesswrong.com/posts/yHzDrTCum4rdNRDJJ/the-most-important-century-sequence-introduction?commentId=k7Fy2PF5z7kGxbxSP\"><strong><sup><u>1<\/u><\/sup><\/strong><\/a> I think there is a good chance that:<\/p><ol><li>During the century we're in right now, we will develop technologies that cause us to transition to a state in which humans as we know them are no longer the main force in world events. This is our last chance to shape how that transition happens.<\/li><li>Whatever the main force in world events is (perhaps digital people, misaligned AI, or something else) will create highly stable civilizations that populate our entire galaxy for billions of years to come. The transition taking place this century could shape all of that.<\/li><\/ol><p>I think it's very unclear whether this would be a good or bad thing. What matters is that it could go a lot of different ways, and we have a chance to affect that.<\/p><p>I believe the above possibility doesn't get enough attention, discussion, or investment, particularly from people whose goal is to make the world better. By writing about it, I'd like to either help change that, or gain more opportunities to get criticized and change my mind.<\/p>","wordCount":239,"htmlHighlight":"<p>I think we have good reason to believe that the <strong>21st century could be the most important century ever for humanity.<\/strong> I think the most likely way this would happen would be via the development of advanced AI systems that lead to explosive growth and scientific advancement, getting us more quickly than most people imagine to a deeply unfamiliar future.<\/p><p>A bit more specifically,<a href=\"https://www.lesswrong.com/posts/yHzDrTCum4rdNRDJJ/the-most-important-century-sequence-introduction?commentId=k7Fy2PF5z7kGxbxSP\"><strong><sup><u>1<\/u><\/sup><\/strong><\/a> I think there is a good chance that:<\/p><ol><li>During the century we're in right now, we will develop technologies that cause us to transition to a state in which humans as we know them are no longer the main force in world events. This is our last chance to shape how that transition happens.<\/li><li>Whatever the main force in world events is (perhaps digital people, misaligned AI, or something else) will create highly stable civilizations that populate our entire galaxy for billions of years to come. The transition taking place this century could shape all of that.<\/li><\/ol><p>I think it's very unclear whether this would be a good or bad thing. What matters is that it could go a lot of different ways, and we have a chance to affect that.<\/p><p>I believe the above possibility doesn't get enough attention, discussion, or investment, particularly from people whose goal is to make the world better. By writing about it, I'd like to either help change that, or gain more opportunities to get criticized and change my mind.<\/p>","plaintextDescription":"I think we have good reason to believe that the 21st century could be the most\nimportant century ever for humanity. I think the most likely way this would\nhappen would be via the development of advanced AI systems that lead to\nexplosive growth and scientific advancement, getting us more quickly than most\npeople imagine to a deeply unfamiliar future.\n\nA bit more specifically,1 I think there is a good chance that:\n\n 1. During the century we're in right now, we will develop technologies that\n    cause us to transition to a state in which humans as we know them are no\n    longer the main force in world events. This is our last chance to shape how\n    that transition happens.\n 2. Whatever the main force in world events is (perhaps digital people,\n    misaligned AI, or something else) will create highly stable civilizations\n    that populate our entire galaxy for billions of years to come. The\n    transition taking place this century could shape all of that.\n\nI think it's very unclear whether this would be a good or bad thing. What\nmatters is that it could go a lot of different ways, and we have a chance to\naffect that.\n\nI believe the above possibility doesn't get enough attention, discussion, or\ninvestment, particularly from people whose goal is to make the world better. By\nwriting about it, I'd like to either help change that, or gain more\nopportunities to get criticized and change my mind."},"Sequence:yYxggfHYRrqnJXuRx":{"_id":"yYxggfHYRrqnJXuRx","__typename":"Sequence","createdAt":"2021-08-30T21:41:37.485Z","userId":"kdeMdATaSc2MZKmdH","user":{"__ref":"User:kdeMdATaSc2MZKmdH"},"contents":{"__ref":"Revision:yYxggfHYRrqnJXuRx_"},"gridImageId":"sequencesgrid/nsphhanrutzgofgj5xvu","bannerImageId":"sequences/vb9fvlizrpmm56tajkmk","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"title":"The Most Important Century"},"User:MEu8MdhruX5jfGsFQ":{"_id":"MEu8MdhruX5jfGsFQ","__typename":"User","slug":"johnswentworth","createdAt":"2011-02-19T16:54:09.598Z","username":"johnswentworth","displayName":"johnswentworth","fullName":null,"karma":20274,"afKarma":2122,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":212,"commentCount":1731,"sequenceCount":5,"afPostCount":67,"afCommentCount":362,"spamRiskScore":1,"tagRevisionCount":0},"Revision:Fu7Euu3F96rKhFRWH_":{"_id":"Fu7Euu3F96rKhFRWH_","__typename":"Revision","version":"1.0.0","updateType":"minor","editedAt":"2021-08-09T15:11:57.093Z","userId":"MEu8MdhruX5jfGsFQ","html":"<p>Much of the value I get from math is not from detailed calculations or elaborate models, but rather from <i>framing tools<\/i>: tools which suggest useful questions to ask, approximations to make, what to pay attention to and what to ignore.<\/p><p>Each of these posts is meant to train/practice one mathematical framing tool.<\/p><p>The structure is like a <a href=\"https://www.lesswrong.com/tag/trigger-action-planning\"><u>trigger-action pattern<\/u><\/a>: the hard part is to notice a pattern, a place where a particular tool can apply (the “trigger”). Once we notice the pattern, it suggests certain questions or approximations (the “action”). Each of these posts contains a Challenge to ingrain the abstract trigger-pattern, and a Bonus Exercise to practice applying the actions.<\/p><p>The hope is that practicing these tools will help us notice useful frames for <a href=\"https://www.lesswrong.com/posts/CSZnj2YNMKGfsMbZA/specializing-in-problems-we-don-t-understand\"><u>problems we don’t understand<\/u><\/a> - i.e. problems where we don't already know the best framing.<\/p>","wordCount":137,"htmlHighlight":"<p>Much of the value I get from math is not from detailed calculations or elaborate models, but rather from <i>framing tools<\/i>: tools which suggest useful questions to ask, approximations to make, what to pay attention to and what to ignore.<\/p><p>Each of these posts is meant to train/practice one mathematical framing tool.<\/p><p>The structure is like a <a href=\"https://www.lesswrong.com/tag/trigger-action-planning\"><u>trigger-action pattern<\/u><\/a>: the hard part is to notice a pattern, a place where a particular tool can apply (the “trigger”). Once we notice the pattern, it suggests certain questions or approximations (the “action”). Each of these posts contains a Challenge to ingrain the abstract trigger-pattern, and a Bonus Exercise to practice applying the actions.<\/p><p>The hope is that practicing these tools will help us notice useful frames for <a href=\"https://www.lesswrong.com/posts/CSZnj2YNMKGfsMbZA/specializing-in-problems-we-don-t-understand\"><u>problems we don’t understand<\/u><\/a> - i.e. problems where we don't already know the best framing.<\/p>","plaintextDescription":"Much of the value I get from math is not from detailed calculations or elaborate\nmodels, but rather from framing tools: tools which suggest useful questions to\nask, approximations to make, what to pay attention to and what to ignore.\n\nEach of these posts is meant to train/practice one mathematical framing tool.\n\nThe structure is like a trigger-action pattern: the hard part is to notice a\npattern, a place where a particular tool can apply (the “trigger”). Once we\nnotice the pattern, it suggests certain questions or approximations (the\n“action”). Each of these posts contains a Challenge to ingrain the abstract\ntrigger-pattern, and a Bonus Exercise to practice applying the actions.\n\nThe hope is that practicing these tools will help us notice useful frames for \nproblems we don’t understand - i.e. problems where we don't already know the\nbest framing."},"Sequence:Fu7Euu3F96rKhFRWH":{"_id":"Fu7Euu3F96rKhFRWH","__typename":"Sequence","createdAt":"2021-08-08T21:26:43.596Z","userId":"MEu8MdhruX5jfGsFQ","user":{"__ref":"User:MEu8MdhruX5jfGsFQ"},"contents":{"__ref":"Revision:Fu7Euu3F96rKhFRWH_"},"gridImageId":"sequencesgrid/sulofl6pfuwna4z1kelm","bannerImageId":"sequences/vowmg5tnxfi8fbduuuji","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"curatedOrder":null,"userProfileOrder":null,"af":null,"title":"Framing Practicum"}}</script><script src="./The Library - LessWrong_files/api.js"></script><div><div class="grecaptcha-badge" data-style="bottomright" style="width: 256px; height: 60px; display: block; transition: right 0.3s ease 0s; position: fixed; bottom: 14px; right: -186px; box-shadow: gray 0px 0px 5px; border-radius: 2px; overflow: hidden;"><div class="grecaptcha-logo"><iframe title="reCAPTCHA" src="./The Library - LessWrong_files/anchor.html" width="256" height="60" role="presentation" name="a-4vhkuw77rvjr" frameborder="0" scrolling="no" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox"></iframe></div><div class="grecaptcha-error"></div><textarea id="g-recaptcha-response-100000" name="g-recaptcha-response" class="g-recaptcha-response" style="width: 250px; height: 40px; border: 1px solid rgb(193, 193, 193); margin: 10px 25px; padding: 0px; resize: none; display: none;"></textarea></div><iframe style="display: none;" src="./The Library - LessWrong_files/saved_resource.html"></iframe></div><iframe id="intercom-frame" style="position: absolute !important; opacity: 0 !important; width: 1px !important; height: 1px !important; top: 0 !important; left: 0 !important; border: none !important; display: block !important; z-index: -1 !important; pointer-events: none;" aria-hidden="true" tabindex="-1" title="Intercom" src="./The Library - LessWrong_files/saved_resource(1).html"></iframe><div class="intercom-lightweight-app"><div class="intercom-lightweight-app-launcher intercom-launcher" role="button" tabindex="0" aria-label="Open Intercom Messenger" aria-live="polite"><div class="intercom-lightweight-app-launcher-icon intercom-lightweight-app-launcher-icon-open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 28 32"><path d="M28 32s-4.714-1.855-8.527-3.34H3.437C1.54 28.66 0 27.026 0 25.013V3.644C0 1.633 1.54 0 3.437 0h21.125c1.898 0 3.437 1.632 3.437 3.645v18.404H28V32zm-4.139-11.982a.88.88 0 00-1.292-.105c-.03.026-3.015 2.681-8.57 2.681-5.486 0-8.517-2.636-8.571-2.684a.88.88 0 00-1.29.107 1.01 1.01 0 00-.219.708.992.992 0 00.318.664c.142.128 3.537 3.15 9.762 3.15 6.226 0 9.621-3.022 9.763-3.15a.992.992 0 00.317-.664 1.01 1.01 0 00-.218-.707z"></path></svg></div><div class="intercom-lightweight-app-launcher-icon intercom-lightweight-app-launcher-icon-minimize"><svg viewBox="0 0 16 14" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M.116 4.884l1.768-1.768L8 9.232l6.116-6.116 1.768 1.768L8 12.768.116 4.884z"></path></svg></div></div><style id="intercom-lightweight-app-style" type="text/css">
  @keyframes intercom-lightweight-app-launcher {
    from {
      opacity: 0;
      transform: scale(0.5);
    }
    to {
      opacity: 1;
      transform: scale(1);
    }
  }

  @keyframes intercom-lightweight-app-gradient {
    from {
      opacity: 0;
    }
    to {
      opacity: 1;
    }
  }

  @keyframes intercom-lightweight-app-messenger {
    from {
      opacity: 0;
      transform: translateY(20px);
    }
    to {
      opacity: 1;
      transform: translateY(0);
    }
  }

  .intercom-lightweight-app {
    position: fixed;
    z-index: 2147483001;
    width: 0;
    height: 0;
    font-family: intercom-font, "Helvetica Neue", "Apple Color Emoji", Helvetica, Arial, sans-serif;
  }

  .intercom-lightweight-app-gradient {
    position: fixed;
    z-index: 2147483002;
    width: 500px;
    height: 500px;
    bottom: 0;
    right: 0;
    pointer-events: none;
    background: radial-gradient(
      ellipse at bottom right,
      rgba(29, 39, 54, 0.16) 0%,
      rgba(29, 39, 54, 0) 72%);
    animation: intercom-lightweight-app-gradient 200ms ease-out;
  }

  .intercom-lightweight-app-launcher {
    position: fixed;
    z-index: 2147483003;
    bottom: 20px;
    right: 20px;
    width: 60px;
    height: 60px;
    border-radius: 50%;
    background: #f5f5f5;
    cursor: pointer;
    box-shadow: 0 1px 6px 0 rgba(0, 0, 0, 0.06), 0 2px 32px 0 rgba(0, 0, 0, 0.16);
    animation: intercom-lightweight-app-launcher 250ms ease;
  }

  .intercom-lightweight-app-launcher:focus {
    outline: none;
    
  }

  .intercom-lightweight-app-launcher-icon {
    display: flex;
    align-items: center;
    justify-content: center;
    position: absolute;
    top: 0;
    left: 0;
    width: 60px;
    height: 60px;
    transition: transform 100ms linear, opacity 80ms linear;
  }

  .intercom-lightweight-app-launcher-icon-open {
    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-open svg {
    width: 28px;
    height: 32px;
  }

  .intercom-lightweight-app-launcher-icon-open svg path {
    fill: rgba(0, 0, 0, 0.5);
  }

  .intercom-lightweight-app-launcher-icon-self-serve {
    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-self-serve svg {
    height: 56px;
  }

  .intercom-lightweight-app-launcher-icon-self-serve svg path {
    fill: rgba(0, 0, 0, 0.5);
  }

  .intercom-lightweight-app-launcher-custom-icon-open {
    max-height: 36px;
    max-width: 36px;
    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-minimize {
    
        opacity: 0;
        transform: rotate(-60deg) scale(0);
      
  }

  .intercom-lightweight-app-launcher-icon-minimize svg {
    width: 16px;
  }

  .intercom-lightweight-app-launcher-icon-minimize svg path {
    fill: rgba(0, 0, 0, 0.5);
  }

  .intercom-lightweight-app-messenger {
    position: fixed;
    z-index: 2147483003;
    overflow: hidden;
    background-color: white;
    animation: intercom-lightweight-app-messenger 250ms ease-out;
    
        width: 376px;
        height: calc(100% - 120px);
        max-height: 704px;
        min-height: 250px;
        right: 20px;
        bottom: 100px;
        box-shadow: 0 5px 40px rgba(0,0,0,0.16);
        border-radius: 8px;
      
  }

  .intercom-lightweight-app-messenger-header {
    height: 75px;
    background: linear-gradient(
      135deg,
      rgb(245, 245, 245) 0%,
      rgb(194, 194, 194) 100%
    );
  }

  @media print {
    .intercom-lightweight-app {
      display: none;
    }
  }
</style></div></body></html>